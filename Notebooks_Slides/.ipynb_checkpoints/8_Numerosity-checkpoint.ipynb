{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.9.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "from __future__ import print_function\n",
    "\n",
    "#Manejo de matrices y tablas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Estadistica y funciones matemáticas\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import fmin\n",
    "from scipy import integrate\n",
    "from scipy.stats.mstats import mquantiles\n",
    "import statistics \n",
    "import pyreadr\n",
    "import scipy.io as sio\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Probabilistic programs\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt #NOTA: theano va a cambiar a tensorflow en PyMC4\n",
    "import theano\n",
    "from theano.compile.ops import as_op\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "\n",
    "#Graficas\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import altair as alt\n",
    "from altair_saver import save #ademas instalar en terminal: brew cask install chromedriver\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, HBox, VBox, Layout\n",
    "from graphviz import Source, Digraph\n",
    "import dot2tex as d2t\n",
    "from latex import build_pdf\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import arviz as az\n",
    "import colorsys\n",
    "\n",
    "# Image processing stuff\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "#Funciones propias (tienen que estar en el mismo directorio)\n",
    "import my_fun as mf\n",
    "import my_fun_acta_psy as mf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numerosidad\n",
    "Santiago Alonso-Díaz, PhD <br>\n",
    "Universidad Javeriana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilidades y Numerosidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Imagine que alguien tiene al frente dos urnas con tiquetes doblados. La urna uno tiene 1 tiquete ganador y 9 en blanco. La urna dos tiene 10 tiquetes ganadores y 90 en blanco. La persona debe escoger una de las urnas para jugar.\n",
    "\n",
    "Es claro que las probabilidades son iguales. Sin embargo, investigación previa demuestra que la mayoría prefiere una. ¿Cuál cree que la mayoria escoje? ¿Urna 1 o Urna 2?\n",
    "\n",
    "Kirkpatrick & Epstein (1992)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Va a ver la probabilidad de dos eventos en formato de fracciones. Conteste con su intuición, es decir, sea rápido. ¿cuál es más probable?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\frac{211}{617} \\text{ vs.} \\frac{227}{691}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En diferentes versiones (simbolicas S, con imagenes NS, one-shot S,NS, many-shots PPP), alrededor de 2/3 de personas prefiere loterias con mayor número de ganadores \n",
    "<br> <br><br>\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso1.jpg\" width = \"401\" height = '400'></center>\n",
    "\n",
    "Alonso-Diaz, Piantadosi, Hayden, & Cantlon (2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Qué procesos cognitivos explican el sesgo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Pensamiento rápido**\n",
    "<center><img src=\"img/8_CB/FastSlow.png\" width = \"201\" height = '200'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Baja numerosidad/educación**\n",
    "<center><img src=\"img/8_CB/OECD.png\" width = \"251\" height = '250'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Desarrollo conceptual indebido**\n",
    "\n",
    "$$\\frac{1}{2} + \\frac{1}{4} = \\frac{2}{6}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Notación deficiente**\n",
    "\n",
    "Mismo valor diferentes simbolos\n",
    "$$\\frac{1}{2} = \\frac{33}{66}$$\n",
    "\n",
    "Mismo valor iguales simbolos\n",
    "$$\\frac{3}{3} = \\frac{3}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Costos metabólicos de computar ratios**\n",
    "\n",
    "$$Posterior = \\frac{Likelihood \\times Prior}{Marginal}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> Una Hipótesis Bayesiana </center>\n",
    "\n",
    "Los humanos deciden con toda la información (numeradores y ratios). Esto es adaptativo, depronto óptimo, si hay una probabilidad a priori considerable de que las fracciones grandes tengan numeradores grandes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Hay evidencia de la primera parte?\n",
    "\n",
    "**Los humanos deciden con toda la información (numeradores y ratios)**. Esto es adaptativo, depronto óptimo, si hay una probabilidad a priori considerable de que las fracciones grandes tengan numeradores grandes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>Los humanos deciden con toda la información (numeradores y ratios)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Si escojen la de blanco y negro es necesariamente cierto que ustedes no usan color en su decisión?\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso3.png\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Si escojen la de la derecha es necesariamente cierto que ustedes no usan ratio en su decisión?\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso2.jpg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/alonso5.png\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Experimento 2\n",
    "\n",
    "* Contenido de dos bolsas. Naranja gana. ¿Cuál prefiere?\n",
    "* 10 distancias de probabilidad entre las bolsas\n",
    "* 816 turnos\n",
    "* 21 participantes (el efecto aparece en todos, por eso el n no tiene que ser grande)\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso4.jpg\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/alonso7.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Prob. distance effects sugieren representación de ratios\n",
    "* Congruency effects confirman whole-number bias\n",
    "<center><img src=\"img/8_CB/alonso6.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ahora el modelo descriptivo Bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/model_WNB.svg\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supuesto 1:\n",
    "La decisión depende de una combinación lineal de perceptos de numerosidad ($W_{ir}$:winners, $L_{ir}$: losers) y ratios ($\\frac{W_{ir}}{W_{ir}+L_{ir}}$).\n",
    "\n",
    "$$\\beta_1 \\Phi(W_{ir}) + \\beta_2 \\Phi(L_{ir}) + \\beta_3 Ratio_{ir}$$\n",
    "\n",
    "Hipótesis Nula: Si posterior de $\\beta_3$ centrado en cero, la gente en promedio no usa/computa ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supuesto 2:\n",
    "La percepción de numerosidad sigue la ley de Weber\n",
    "\n",
    "$$ \\Phi(\\#_{ir}) \\sim N(\\#_{ir}, Weber \\times \\#_{ir})$$\n",
    "\n",
    "\n",
    "<center><img src=\"img/8_CB/Whalen.png\" width = \"651\" height = '650'></center>\n",
    "Whalen, et al, (1999)\n",
    "\n",
    "Video de [Weber's law](https://www.youtube.com/watch?v=hHG8io5qIU8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supuesto 3:\n",
    "La decisión es estocástica con probabilidad softmax:\n",
    "\n",
    "$$\\frac{e^A}{e^A+e^B}$$\n",
    "\n",
    "Donde A es la combinación lineal de perceptos para opción correcta y B para la opción incorrecta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ahora implementemos en PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = WNB_all['ProbSide1']>=WNB_all['ProbSide2']\n",
    "WNB_all['WinSmallRatio'] = float('nan')\n",
    "WNB_all['DenSmallRatio'] = float('nan')\n",
    "WNB_all['WinBigRatio'] = float('nan')\n",
    "WNB_all['DenBigRatio'] = float('nan')\n",
    "for i in range(WNB_all.shape[0]):\n",
    "    if idx1[i]:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "    else:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "        \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "#Performance: 0 wrong, 1 correct\n",
    "#RT: response time in secs\n",
    "#ProbRatio: small ratio / large ratio\n",
    "#NumRatio: small numerator / large numerator\n",
    "#DenRatio: small denominator / large denominator\n",
    "#AreaCtl: dots across bags have 1: equal dot size, 2: equal cumulative area\n",
    "#WinSide1: number of winners left bag\n",
    "#WinSide2: number of winners right bag\n",
    "#DenSide1: total balls left bag\n",
    "#DenSide2: total balls right bag\n",
    "#ProbSide1: probability of win left bag\n",
    "#ProbSide2: probability of win right bag\n",
    "#sideR: side of response; 1 left, 2 right, 0 no response.\n",
    "#subID: subject identifier\n",
    "\n",
    "WNB_all = pd.read_csv('data/8_CB/WNB.csv')\n",
    "WNB_all['ProbDistance'] = np.abs(WNB_all['ProbSide1']-WNB_all['ProbSide2'])\n",
    "WNB_all = WNB_all.loc[WNB_all['sideR']>0,:].reset_index(drop=True)\n",
    "\n",
    "idx1 = WNB_all['ProbSide1']>=WNB_all['ProbSide2']\n",
    "WNB_all['WinSmallRatio'] = int(0)\n",
    "WNB_all['DenSmallRatio'] = int(0)\n",
    "WNB_all['WinBigRatio'] = int(0)\n",
    "WNB_all['DenBigRatio'] = int(0)\n",
    "for i in range(WNB_all.shape[0]):\n",
    "    if idx1[i]:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "    else:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "sID = WNB_all['subID'].unique()\n",
    "subj_to_model = -1 #0 to 20; -1 for all\n",
    "WNB = WNB_all\n",
    "if subj_to_model>=0:\n",
    "    WNB = WNB_all.loc[WNB_all['subID']==sID[subj_to_model],:].reset_index(drop=True) \n",
    "weber = 0.286679553540291 #mean value of participants (see paper)\n",
    "winners_s = np.sort(WNB['WinSmallRatio'].unique())\n",
    "winners_b = np.sort(WNB['WinBigRatio'].unique())\n",
    "winners = np.sort(pd.concat([pd.Series(winners_s), pd.Series(winners_b)]).unique())\n",
    "losers_s = np.sort((WNB['DenSmallRatio']-WNB['WinSmallRatio']).unique())\n",
    "losers_b = np.sort((WNB['DenBigRatio']-WNB['WinBigRatio']).unique())\n",
    "losers = np.sort(pd.concat([pd.Series(losers_s), pd.Series(losers_b)]).unique())\n",
    "sn = np.array(WNB['WinSmallRatio'], dtype = str)\n",
    "sd = np.array(WNB['DenSmallRatio'], dtype = str)\n",
    "r = []\n",
    "for idx, ele in enumerate(sn):\n",
    "    r.append(ele + \"_\" + sd[idx])\n",
    "bn = np.array(WNB['WinBigRatio'], dtype = str)\n",
    "bd = np.array(WNB['DenBigRatio'], dtype = str)\n",
    "for idx, ele in enumerate(bn):\n",
    "    r.append(ele + \"_\" + bd[idx])\n",
    "r = pd.Series(r).unique()\n",
    "ratios = np.zeros((r.shape[0],3))\n",
    "for idx, ele in enumerate(r):\n",
    "    temp = np.array(ele.split(\"_\"), dtype = int)\n",
    "    ratios[idx,0] = temp[0] #num\n",
    "    ratios[idx,1] = temp[1] #den\n",
    "    ratios[idx,2] = temp[0]/temp[1] #ratio\n",
    "print(winners.shape, losers.shape, ratios.shape)\n",
    "\n",
    "#Indices (for vectors with unique values)\n",
    "side1 = np.zeros((WNB.shape[0],3)) #column order: index for winners, losers, ratios\n",
    "side2 = np.zeros((WNB.shape[0],3))\n",
    "for i in range(WNB.shape[0]):\n",
    "    #side 1\n",
    "    w = WNB.loc[i, 'WinSmallRatio'] \n",
    "    den = WNB.loc[i, 'DenSmallRatio'] \n",
    "    l = den - w\n",
    "    side1[i,0] = np.where(winners == w)[0][0]\n",
    "    side1[i,1] = np.where(losers == l)[0][0]\n",
    "    side1[i,2] = np.where((ratios[:,0] == w) & (ratios[:,1] == den))[0][0]\n",
    "    \n",
    "    #side 2\n",
    "    w = WNB.loc[i, 'WinBigRatio'] \n",
    "    den = WNB.loc[i, 'DenBigRatio'] \n",
    "    l = den - w\n",
    "    side2[i,0] = np.where(winners == w)[0][0]\n",
    "    side2[i,1] = np.where(losers == l)[0][0]\n",
    "    side2[i,2] = np.where((ratios[:,0] == w) & (ratios[:,1] == den))[0][0]\n",
    "side1 = side1.astype(int)\n",
    "side2 = side2.astype(int)\n",
    "\n",
    "#choice data\n",
    "idx1 = WNB['ProbSide1']>=WNB_all['ProbSide2']\n",
    "idx2 = WNB['sideR'] == 1\n",
    "WNB['correct'] = np.array((idx1 & idx2) | (~idx1 & ~idx2), dtype = int)\n",
    "choice = WNB['correct'] #0: incorrect; 1: correct\n",
    "#WNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as WNB_model:\n",
    "    \n",
    "    #priors\n",
    "    #percepts of winners and losers assumed different e.g. due to lose aversion\n",
    "    Winners = pm.Normal('percept_winners', \n",
    "                        mu = winners, sd = weber*winners, shape = winners.shape)\n",
    "    Losers = pm.Normal('percept_losers', \n",
    "                       mu = losers, sd = weber*losers, shape = losers.shape) \n",
    "    Ratios = pm.Beta('percept_ratios', \n",
    "                     alpha = ratios[:,0] + 1, \n",
    "                     beta = ratios[:,1] - ratios[:,0] + 1, shape = ratios.shape[0])\n",
    "    Weight_win = pm.Uniform('weight_win', lower = -5, upper = 5)\n",
    "    Weight_lose = pm.Uniform('weight_lose', lower = -5, upper = 5)\n",
    "    Weight_ratio = pm.Uniform('weight_ratio', lower = 0, upper = 5)\n",
    "    \n",
    "    print(Winners.tag.test_value.shape, \n",
    "          Losers.tag.test_value.shape,\n",
    "          Ratios.tag.test_value.shape)\n",
    "\n",
    "    \n",
    "    #likelihood\n",
    "    f_side1 = Weight_ratio*Ratios[side1[:,2]] + Weight_win*Winners[side1[:,0]] + Weight_lose*Losers[side1[:,1]]\n",
    "    f_side2 = Weight_ratio*Ratios[side2[:,2]] + Weight_win*Winners[side2[:,0]] + Weight_lose*Losers[side2[:,1]]\n",
    "    #f_side1 = Weight_win*Winners[side1[:,0]] \n",
    "    #f_side2 = Weight_win*Winners[side2[:,0]]\n",
    "    softmax = tt.exp(f_side2)/(tt.exp(f_side1) + tt.exp(f_side2)) #prob. of picking side 2\n",
    "    #a = tt.exp(np.random.rand(side1.shape[0]))\n",
    "    #b = tt.exp(np.random.rand(side2.shape[0]))\n",
    "    #softmax = a/(a + b) #prob. of picking side 2\n",
    "    choice_LH = pm.Bernoulli('choice', p = softmax, observed = choice)\n",
    "\n",
    "    print(f_side1.tag.test_value.shape, f_side2.tag.test_value.shape,\n",
    "          softmax.tag.test_value.shape, choice_LH.tag.test_value.shape)\n",
    "    \n",
    "    #sampling\n",
    "    trace = pm.sample(1000, init = 'adapt_diag', tune=1500)\n",
    "    ppc = pm.sample_posterior_predictive(trace, samples=5000)\n",
    "    data = az.from_pymc3(trace=trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_trace(data, var_names=['weight_win', 'weight_lose', 'weight_ratio', \n",
    "                               'percept_winners', 'percept_losers', 'percept_ratios'], compact=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = [15,6])\n",
    "az.plot_density(\n",
    "    [trace['weight_win'], trace['weight_lose']],\n",
    "    data_labels=[\"$winners$\", \n",
    "                 \"$losers$\"],\n",
    "    shade=.1, ax = ax[0], hdi_prob=.95, \n",
    ")\n",
    "az.plot_density(\n",
    "    [trace['weight_ratio']], hdi_prob=.95,\n",
    "    data_labels=[\"$\\\\beta_{ratio}$\"], outline=True,\n",
    "    shade=.25, ax = ax[1], colors = 'purple', \n",
    ")\n",
    "ax[0].set_title('$\\\\beta$', fontsize = 20)\n",
    "ax[1].set_title('$\\\\beta_{ratios}$', fontsize = 20)\n",
    "ax[0].legend(loc='upper right');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "idx_cong = WNB['WinBigRatio']>WNB['WinSmallRatio'] #Congruent trial\n",
    "idx_incong = ~idx_cong #Incongruent trial\n",
    "ppc_cong = pd.concat([pd.DataFrame(ppc['choice'].mean(axis=0)[idx_cong], columns = ['choice_model']), \n",
    "                      WNB.loc[idx_cong,:].reset_index(drop=True)], axis = 1)\n",
    "ppc_incong = pd.concat([pd.DataFrame(ppc['choice'].mean(axis=0)[idx_incong], columns = ['choice_model']), \n",
    "                        WNB.loc[idx_incong,:].reset_index(drop=True)], axis = 1)\n",
    "\n",
    "toplot_cong = ppc_cong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "toplot_incong = ppc_incong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "idx1 = toplot_cong['ProbDistance']==0\n",
    "idx2 = toplot_incong['ProbDistance']==0\n",
    "mean0 = (toplot_cong.loc[idx1,'correct'] + toplot_incong.loc[idx2,'correct'])/2\n",
    "toplot_cong.loc[idx1,'correct'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'correct'] = mean0\n",
    "mean0 = (toplot_cong.loc[idx1,'choice_model'] + toplot_incong.loc[idx2,'choice_model'])/2\n",
    "toplot_cong.loc[idx1,'choice_model'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'choice_model'] = mean0\n",
    "\n",
    "fig = plt.figure(figsize=[9,7])\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red');\n",
    "\n",
    "plt.ylim([0.25,1])\n",
    "plt.xlabel('Prob. distance between the bags', fontsize = 20)\n",
    "plt.ylabel('Accuracy\\n%correct ', fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ejercicio\n",
    "\n",
    "* Haga el diagrama de un modelo con un prior uniforme entre 0 y 1 para la fracción Weber por sujeto. \n",
    "    * Implemente el modelo en PyMC y compare el posterior del Weber con el valor fijo de 0.28. ¿Es mayor o menor? ¿Qué significa la diferencia?\n",
    "* Haga el diagrama de un modelo jerárquico con un prior Normal para la fracción de Weber por sujeto. Haga el prior con hiperparametros mu y sigma uniforme entre 0 y 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una hipótesis alternativa es que la gente es estratégica. \n",
    "\n",
    "Si el denominador es igual (o casi igual), se comparan los numeradores. De lo contrario, se comparan los ratios.\n",
    "\n",
    "Implementemos esta idea en PyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usemos un soft threshold para usar o no ratio\n",
    "\n",
    "$$pUseRatio_i = \\frac{1}{1+e^{-k(Thr-rDen_i)}}$$\n",
    "\n",
    "$pUseRatio_i$: Probabilidad de usar ratio en el turno i <br>\n",
    "$k, \\ Thr$: Sensibilidad y umbral, respectivamente. Parametros libres de la sigmoide <br>\n",
    "$rDen_i$: ratio entre los denominadores de ambas bolsa ($Small_{ratio}/Big_{ratio}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "k = 3.2\n",
    "Thr = 0.99\n",
    "rDen = np.linspace(0,1,100)\n",
    "pUseRatio = 1/(1+np.exp(-k*(Thr - rDen)))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(rDen, pUseRatio);\n",
    "plt.ylabel('Prob. use ratio', fontsize = 20)\n",
    "plt.xlabel('Ratio between denominators (S/B)', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as WNB_strategic_model:\n",
    "    \n",
    "    #priors\n",
    "    k = pm.Uniform('k', lower=0, upper=20)\n",
    "    Thr = pm.Uniform('Thr', lower=0, upper=1)\n",
    "    #percepts of winners and losers assumed different e.g. due to lose aversion\n",
    "    Winners = pm.Normal('percept_winners', \n",
    "                        mu = winners, sd = weber*winners, shape = winners.shape)\n",
    "    Losers = pm.Normal('percept_losers', \n",
    "                       mu = losers, sd = weber*losers, shape = losers.shape) \n",
    "    Ratios = pm.Beta('percept_ratios', \n",
    "                     alpha = ratios[:,0] + 1, \n",
    "                     beta = ratios[:,1] - ratios[:,0] + 1, shape = ratios.shape[0])\n",
    "    \n",
    "    #likelihood \n",
    "    w_1 = Winners[side1[:,0]]\n",
    "    w_2 = Winners[side2[:,0]]\n",
    "    l_1 = Losers[side1[:,0]]\n",
    "    l_2 = Losers[side2[:,0]]\n",
    "    d_1 = w_1 + l_1\n",
    "    d_2 = w_2 + l_2\n",
    "    rDen = tt.switch( d_1>=d_2, d_2/d_1, d_1/d_2)\n",
    "    pUseRatio = 1/(1+tt.exp(-k*(Thr-rDen)))  \n",
    "    f_side1 = pUseRatio*Ratios[side1[:,2]] + (1-pUseRatio)*Winners[side1[:,0]] \n",
    "    f_side2 = pUseRatio*Ratios[side2[:,2]] + (1-pUseRatio)*Winners[side2[:,0]] \n",
    "    softmax = tt.exp(f_side2)/(tt.exp(f_side1) + tt.exp(f_side2)) #prob. of picking side 2\n",
    "   \n",
    "    choice_LH = pm.Bernoulli( 'choice', p = softmax, observed=choice)\n",
    "    \n",
    "    \n",
    "    print(f_side1.tag.test_value.shape, f_side2.tag.test_value.shape,\n",
    "          softmax.tag.test_value.shape, choice_LH.tag.test_value.shape)\n",
    "    \n",
    "    #sampling\n",
    "    trace_s = pm.sample(1000, init = 'adapt_diag', tune=1500, target_accept = 0.9)\n",
    "    ppc_s = pm.sample_posterior_predictive(trace_s, samples=5000)\n",
    "    data_s = az.from_pymc3(trace=trace_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "az.plot_trace(data_s, var_names=['k', 'Thr', \n",
    "                               'percept_winners', 'percept_losers', 'percept_ratios'], compact=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y = trace['percept_winners'].mean(axis=0)\n",
    "x = winners\n",
    "plt.plot(x,y, label = 'intrinsic WNB')\n",
    "\n",
    "y = trace_s['percept_winners'].mean(axis=0)\n",
    "plt.plot(x,y, label = 'strategic')\n",
    "plt.legend()\n",
    "plt.title('Mean Percept Winners')\n",
    "\n",
    "plt.figure()\n",
    "y = trace['percept_losers'].mean(axis=0)\n",
    "x = losers\n",
    "plt.plot(x,y, label = 'intrinsic WNB')\n",
    "\n",
    "y = trace_s['percept_losers'].mean(axis=0)\n",
    "plt.plot(x,y, label = 'strategic')\n",
    "plt.title('Mean Percept Losers')\n",
    "plt.legend();\n",
    "\n",
    "plt.figure()\n",
    "y = trace['percept_ratios'].mean(axis=0)\n",
    "x = ratios[:,2]\n",
    "plt.scatter(x,y, label = 'intrinsic WNB')\n",
    "\n",
    "y = trace_s['percept_ratios'].mean(axis=0)\n",
    "plt.scatter(x,y, label = 'strategic')\n",
    "plt.title('Mean Percept Ratios')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "idx_cong = WNB['WinBigRatio']>WNB['WinSmallRatio'] #Congruent trial\n",
    "idx_incong = ~idx_cong #Incongruent trial\n",
    "ppc_cong = pd.concat([pd.DataFrame(ppc_s['choice'].mean(axis=0)[idx_cong], \n",
    "                                   columns = ['choice_model']), \n",
    "                      WNB.loc[idx_cong,:].reset_index(drop=True)], axis = 1)\n",
    "ppc_incong = pd.concat([pd.DataFrame(ppc_s['choice'].mean(axis=0)[idx_incong], columns = ['choice_model']), \n",
    "                        WNB.loc[idx_incong,:].reset_index(drop=True)], axis = 1)\n",
    "\n",
    "toplot_cong = ppc_cong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "toplot_incong = ppc_incong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "idx1 = toplot_cong['ProbDistance']==0\n",
    "idx2 = toplot_incong['ProbDistance']==0\n",
    "mean0 = (toplot_cong.loc[idx1,'correct'] + toplot_incong.loc[idx2,'correct'])/2\n",
    "toplot_cong.loc[idx1,'correct'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'correct'] = mean0\n",
    "mean0 = (toplot_cong.loc[idx1,'choice_model'] + toplot_incong.loc[idx2,'choice_model'])/2\n",
    "toplot_cong.loc[idx1,'choice_model'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'choice_model'] = mean0\n",
    "\n",
    "fig = plt.figure(figsize=[9,7])\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red');\n",
    "\n",
    "plt.ylim([0.25,1])\n",
    "plt.xlabel('Prob. distance between the bags', fontsize = 20)\n",
    "plt.ylabel('Accuracy\\n%correct ', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Model comparison \n",
    "with WNB_strategic_model:\n",
    "    strategic_waic = pm.waic(trace_s, var_name = 'choice')\n",
    "with WNB_model:\n",
    "    intrinsic_waic = pm.waic(trace) #This calculates the elpd_waic (-2 times is the waic in deviance scale) \n",
    "\n",
    "#lower is better\n",
    "print('Strategy WAIC (deviance scale):      ', -2*strategic_waic.waic) \n",
    "print('Intrinsic WNB WAIC (deviance scale): ', -2*intrinsic_waic.waic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ejercicio\n",
    "\n",
    "* Haga el diagrama del modelo estratégico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos estimar perceptos de numerosidad y ratio latentes con técnicas bayesianas ... \n",
    "\n",
    "... pero ¿es cognición de fracciones Bayesiana? Depronto. Dos argumentos y datos:\n",
    "\n",
    "* Confianza sigue un sesgo bayesiano\n",
    "* Hay un prior de fracciones altas con numeradores altas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Confianza sigue un sesgo bayesiano\n",
    "<center><img src=\"img/8_CB/alonso15.png\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una percepción de ratios tipo Beta es más precisa con números mayores. \n",
    "\n",
    "Hipótesis (Beta) Bayesiana: la gente debe tener mayor confianza en el mismo ratio pero con números grandes.\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso9.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Experimento: \n",
    "* Escoja la bolsa con mejor probabilidad de sacar una bola naranja. 232 turnos\n",
    "* 100 mTurkers (final n = 82)\n",
    "* 3 distancias de prob. entre las bolsas\n",
    "* 2 condiciones: cardinalidad (alta y baja) y congruencia (cong. e incong)\n",
    "* Confianza post decision \n",
    "\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso10.png\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/alonso11.png\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bolsas con alta cardinalidad reducian calificaciones bajas de confianza (2)\n",
    "\n",
    "Bolsas con baja cardinalidad aumentaban calificaciones bajas de confianza (2)\n",
    "\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso12.png\" width = \"400\" height = '400'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Podrá ser un artefacto de preguntar explícitamente? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La misma tarea pero ahora se escoge moviendo el dedo a una pantalla (grabación de infrarojos en la punta del dedo).   \n",
    "\n",
    "Supuesto: trayectoria como proxy de confianza implícita (i.e. el sujeto luego de varios turnos se mueve rápido)\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso13.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La trayectoria era más confiada con ratios con numeros altos (dificultad constante de 0.1)\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso14.svg\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Los datos son consistentes con la hipótesis bayesiana para fracciones.\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso9.png\" width = \"351\" height = '350'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Otra pista bayesiana es la existencia de un prior fuerte en la realidad.\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso16.svg\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Por qué el gap? ¿Óptimo? Sí, si comparo más rápido numeradores y estos son un proxi del valor fraccional.\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso6.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Segun Bayes,\n",
    "\n",
    "$$p(RL|NL) = \\frac{p(NL|RL)p(RL)}{p(NL)}$$\n",
    "\n",
    "donde R: ratio, N: numerador, D: denominador, L: larger, S: smaller.\n",
    "\n",
    "Para sugerir pseudo-optimalidad bayesiana, p(RL|NL) deber ser mayor a todos los demás posteriors\n",
    "\n",
    "$$p(RL|NL) > p(RL|NS) > p(RL|DL) > p(RL|DS)$$\n",
    "\n",
    "De hecho, si la magnitud del ratio y el denominador son independientes se puede mostrar que es muy probable ese ordenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Generate counts for a specific category\n",
    "folder_name = 'Warhol' #We included 4 folders as examples (go to Kaggle or Caltech256 website for others)\n",
    "dirr = 'data/8_CB/Distribution-of-fractions/Example_Images/' + folder_name + '/'\n",
    "name_files = [name for name in os.listdir(dirr) if (os.path.isfile(dirr+name)) & (name != '.DS_Store')]\n",
    "n_files = len(name_files)\n",
    "\n",
    "# Counts\n",
    "results = mf2.img_counts(dirr, name_files, progress = False) #This takes a while\n",
    "hue_bands = 4 #total number of hue bands (see img_counts)\n",
    "NUM = [[], [], [], []]  # pixels of hue\n",
    "DEN = [[], [], [], []]\n",
    "NUM_B = [[], [], [], []]  # brightness of hue\n",
    "DEN_B = [[], [], [], []]\n",
    "NUM_S = [[], [], [], []]  # saturation of hue\n",
    "DEN_S = [[], [], [], []]\n",
    "for hb in range(hue_bands):\n",
    "    NUM[hb].append(results[0][hb])\n",
    "    DEN[hb].append(results[1][hb])\n",
    "    \n",
    "    NUM_B[hb].append(results[2][hb])\n",
    "    DEN_B[hb].append(results[3][hb])\n",
    "    \n",
    "    NUM_S[hb].append(results[4][hb])\n",
    "    DEN_S[hb].append(results[5][hb])\n",
    "\n",
    "\n",
    "# Posteriors for all categories by HSV dimensions. \n",
    "# In \"Example of one image category\"  we show how we calculated\n",
    "# posteriors. Specifically, see the function dropdown_callback \n",
    "# and the call to my_posterior in my_fun.py.\n",
    "\n",
    "caltech256_h = pd.read_csv('data/8_CB/Distribution-of-fractions/tableCaltech_hue.csv')\n",
    "caltech256_s = pd.read_csv('data/8_CB/Distribution-of-fractions/tableCaltech_sat.csv')\n",
    "caltech256_v = pd.read_csv('data/8_CB/Distribution-of-fractions/tableCaltech_bright.csv')\n",
    "paints_h = pd.read_csv('data/8_CB/Distribution-of-fractions/tablePaints_hue.csv')\n",
    "paints_s = pd.read_csv('data/8_CB/Distribution-of-fractions/tablePaints_sat.csv')\n",
    "paints_v = pd.read_csv('data/8_CB/Distribution-of-fractions/tablePaints_bright.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51950b7ed79d46c28ebdc746ac132f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Hue band: ', index=3, options=(('Red-yellow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random images to initialize (changeable in the widget below)\n",
    "rnd1 = np.random.randint(n_files)\n",
    "rnd2 = np.random.randint(n_files)\n",
    "name_files.sort()\n",
    "NUMS = [NUM, NUM_B, NUM_S]\n",
    "DENS = [DEN, DEN_B, DEN_S]\n",
    "\n",
    "wHue = widgets.Dropdown(options=[('Red-yellow', 0), ('Yellow-green', 1), ('Green-blue', 2), ('Blue-purple',3)],\n",
    "                        value=3,\n",
    "                        description='Hue band: ')\n",
    "wDim = widgets.Dropdown(options=[('Hue', 'hue'), ('Saturation', 'saturation'), ('Brightness', 'brightness')],\n",
    "                        value='hue',\n",
    "                        description='HSV dimension: ')\n",
    "wImg1 = widgets.Dropdown(options= name_files, value=name_files[rnd1], description='Image 1: ')\n",
    "wImg2 = widgets.Dropdown(options= name_files,value=name_files[rnd2],description='Image 2: ')\n",
    "\n",
    "out = widgets.interactive_output(mf2.dropdown_callback, \n",
    "                                 {'hue': wHue, 'hsv_dim': wDim, \n",
    "                                  'img1': wImg1, 'img2': wImg2, \n",
    "                                  'dirr': fixed(dirr), 'NUMS': fixed(NUMS), 'DENS': fixed(DENS)})\n",
    "\n",
    "left_widgets = VBox([wHue, wDim])\n",
    "right_widgets = VBox([wImg1, wImg2])\n",
    "top = HBox([left_widgets, right_widgets])\n",
    "VBox([top, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En imagenes ratio y denominador son independientes ($p(RL|DL=p(RL|DS)=0.5$). \n",
    "\n",
    "Dada esta condición, p(RL|NL) es muy alto en millones de comparaciones binarias de imagenes naturales y pinturas.\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso17.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sólo en imagenes, también en muchos dominios p(RL|NL) es mayor (aunque la razón no es 100% clara pues $p(RL|DL\\ne p(RL|DS)\\ne 0.5$)\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso18.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Con herramientas y conceptos bayesianos pudimos demostrar:\n",
    "\n",
    "* Usar numeradores no implica no usar ratios.\n",
    "* Sesgo bayesiano en confiar en ratios con cardinalidad alta.\n",
    "* Prior p(RL|NL) alto en imagenes y otros dominios como libros de texto, videojuegos, economía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cambiemos de tema un poco\n",
    "\n",
    "<center><img src=\"img/8_CB/LeeSarnecka1.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Teoría de number-knower. Los primeros numerales (1 a aprox. 4) se aprenden por ensayo y error (N-knower). Si se le pide un número mayor al nivel number-knower, el niño/niña es aleatorio.  \n",
    "\n",
    "A partir de cierta edad se pasa a ser cardinal-principle knower (CP-knower) donde numerales sucesivos indican mayor numerosidad. Hay un salto/inferencia en la mente de la niña/niño. \n",
    "\n",
    "<center><img src=\"img/8_CB/LeeSarnecka2.svg\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/LeeSarnecka3.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUIR CON:\n",
    "\n",
    "* Wagenmakers chapter + Piantadosi article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intrinsic whole number bias\n",
    "dot_text = 'digraph G {rankdir=TB; compound=true; newrank=true; labelloc=\"t\";\\\n",
    "           label=\"Whole Number Bias\";\\\n",
    "           /* general properties*/\\\n",
    "           node [margin=0, fixedsize=true, shape=plaintext,\\\n",
    "                 height=0.25, width=0.25, lblstyle=\"font=\\\\small\"];\\\n",
    "           /* links */\\\n",
    "           w -> pw;\\\n",
    "           l -> pl;\\\n",
    "           w -> pratio;\\\n",
    "           l -> pratio;\\\n",
    "           pw -> choice;\\\n",
    "           pl -> choice;\\\n",
    "           pratio -> choice;\\\n",
    "           subgraph cluster0 {\\\n",
    "               margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "               style = rounded;\\\n",
    "               label = \"$i trial$\";\\\n",
    "               choice;\\\n",
    "               subgraph cluster1 {\\\n",
    "                   margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "                   style = rounded;\\\n",
    "                   label = \"$r ratio = [Small, Big]$\";\\\n",
    "                   w;\\\n",
    "                   pw;\\\n",
    "                   l;\\\n",
    "                   pl;\\\n",
    "                   pratio;\\\n",
    "               }\\\n",
    "           }\\\n",
    "           /* nodes */\\\n",
    "           w [label = \"$W_{ir}$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           l [label = \"$L_{ir}$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           pw [label = \"$\\Phi(W_{ir})$\", shape = circle];\\\n",
    "           pl [label = \"$\\Phi(L_{ir})$\", shape = circle];\\\n",
    "           pratio [label = \"$Ratio_{ir}$\", shape = circle];\\\n",
    "           choice [label = \"$Choice_i$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           }' #warning: use single quote at start and end; double quotes for labels\n",
    "s = Source(dot_text, filename=\"img/8_CB/model_WNB.gv\", format=\"svg\") #THIS IS NOT THE FINAL ONE\n",
    "s.view()\n",
    "\n",
    "#distributions:\n",
    "# \\Phi(W_{ir}) \\sim N(W_{ir}, Weber \\times W_{ir})\n",
    "# \\Phi(L_{ir}) \\sim N(L_{ir}, Weber \\times L_{ir})\n",
    "# Ratio_{ir} \\sim Beta(W_{ir} + 1, L_{ir} + 1)\n",
    "# Choice_i \\sim Bernoulli(pSM_i)\n",
    "# pSM_i = \\frac{e^{f_{iB}}}{e^{f_{iB}}+e^{f_{iS}}}\n",
    "# f_{ir} = \\beta_1 \\Phi(W_{ir}) + \\beta_2 \\Phi(L_{ir}) + \\beta_3 Ratio_{ir}\n",
    "# \\beta_{num cues} \\Uniform(-5,5)\n",
    "# \\beta_{ratio cue} \\Uniform(0,5)\n",
    "\n",
    "#To typeset latex stuff on the image: \n",
    "#1) open svg in inkscape and write latex formulas. Export as pdf (click the one that says latex)\n",
    "#   to change fontsize of latex in inkscape write before the expression: \n",
    "#        \\fontsize{34pt}{1em} $latex expression$ ... change #pt for size\n",
    "#2) go to overleaf or latex editor of choice and do this (https://castel.dev/post/lecture-notes-2/):\n",
    "#   2.1) In the preamble:\n",
    "#  \\usepackage{import}\n",
    "#  \\usepackage{xifthen}\n",
    "#  \\usepackage{pdfpages}\n",
    "#  \\usepackage{transparent}\n",
    "#  \\usepackage{graphics} \n",
    "\n",
    "#  \\newcommand{\\incfig}[1]{%\n",
    "#      \\def\\svgwidth{\\columnwidth}\n",
    "#      \\import{./figures/}{#1.pdf_tex} %PUT the inkscape .pdf_tex AND .pdf in a local folder called figures\n",
    "#  }\n",
    "#   2.2)In the body:\n",
    "#  \\begin{figure}[ht]\n",
    "#      \\centering\n",
    "#      \\scalebox{.65}{\\incfig{your_inkscape.pdf_tex}} #change scalebox proportion to rescale\n",
    "#      \\caption{Riemmans theorem}\n",
    "#      \\label{fig:riemmans-theorem}\n",
    "#  \\end{figure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
