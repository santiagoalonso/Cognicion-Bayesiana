{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Tables and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Stats \n",
    "import scipy.stats as st\n",
    "\n",
    "#Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, HBox, VBox, Layout\n",
    "from graphviz import Source\n",
    "from graphviz import Digraph\n",
    "import altair as alt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Meeting Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Santiago Alonso-Díaz, PhD\n",
    "\n",
    "Universidad Javeriana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/2_CB/Thomas_Bayes.gif\" width = \"300\" height = '300'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The theorem:\n",
    "\n",
    "$$ p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)}$$\n",
    "\n",
    "Think of `p` as a distribution (continuous or discrete; there are many types):\n",
    "\n",
    "<center><img src=\"img/2_CB/normal_poisson.svg\" width = \"800\" height = '700'></center>\n",
    "\n",
    "\n",
    "$\\theta$: hipotheses; $y$: data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El teorema:\n",
    "\n",
    "$$ p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)}$$\n",
    "\n",
    "Expandamos el denominador, que es la probabilidad de los datos bajo TODAS las hipótesis:\n",
    "\n",
    "$$ p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{\\int{p(y|\\theta)p(\\theta)d\\theta}}$$\n",
    "\n",
    "Al denominador se le llama `marginal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El marginal es una constante que nos asegura que el posterior esté entre 0 y 1. Usualmente es difícil de calcular y se usa la versión proporcional del teorema:\n",
    "$$ p(\\theta|y) \\propto p(y|\\theta)p(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Qué es probabilidad? Definición formal\n",
    "\n",
    "* Medida positiva (+) de eventos (E) en un espacio (H)\n",
    "* La probabilidad de todo el espacio (H) es 1\n",
    "* La probabilidad de eventos mutuamente excluyentes se puede sumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Qué es probabilidad? Interpretaciones \n",
    "<center> <p style = 'font-size = 20px'> Frecuentista vs. Creencias</p> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Cuál es la probabilidad de que caiga cara? \n",
    "<center><img src=\"img/2_CB/Coin_cara.png\" width = \"150\" height = '150'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Cuál es la probabilidad de que caiga cara? Lanzamos la moneda 7 veces\n",
    "<center><img src=\"img/2_CB/Coin_cara_sello.png\" width = \"340\" height = '340'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Cuál es la probabilidad de ganarse un premio Nobel?\n",
    "<center><img src=\"img/2_CB/Nobel_Prize.png\" width = \"240\" height = '240'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Cuál es la probabilidad de ganarse un premio Nobel? ¿Podemos usar frecuencias? Población mundial aprox. 7800 millones.\n",
    "\n",
    "|Nobel|Ganadores|\n",
    "|:-----:|:---------:|\n",
    "|Física|213|\n",
    "|Química|184|\n",
    "|Medicina|219|\n",
    "|Literatura|116|\n",
    "|Paz|134|\n",
    "|Economía|84|\n",
    "|**Total**|950|\n",
    "\n",
    "Fuente: nobelprize.org (2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Probabilidad frecuentista: frecuencia de eventos; hay un estimativo puntual\n",
    "\n",
    "|Problema|Datos|$\\theta$|\n",
    "|:-------:|:-------:|:-------:|\n",
    "|<img src=\"img/2_CB/Coin_cara.png\" width = \"175\" height = '175'>|1 cara, 6 sellos|$\\frac{1}{7}$|\n",
    "\n",
    "Probabilidad bayesiana: creencias; hay una distribución sobre el estimativo\n",
    "\n",
    "|Problema|Datos|$\\theta$|\n",
    "|:-------:|:-------:|:-------:|\n",
    "|<img src=\"img/2_CB/Coin_cara.png\" width = \"175\" height = '175'>|1 cara, 6 sellos|<img src=\"img/2_CB/beta.svg\" width = \"200\" height = '200'>|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El poder de Bayes: \n",
    "\n",
    "Nos dice cómo creencias a priori sobre una hipótesis ($p(\\theta))$ se actualizan con datos para obtener una nueva creencia a posteriori ($p(\\theta|data)$).\n",
    "\n",
    "$$ p(\\theta|data) = \\frac{p(data|\\theta)p(\\theta)}{p(data)}$$\n",
    "\n",
    "El prior del futuro es el posterior de hoy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Prior: cae cara 50% de las veces. <br>\n",
    "Posterior: una vez cara de diez, la probabilidad debe ser menor.\n",
    "\n",
    "Prior: 30% en Colombia tiene COVID-19. <br>\n",
    "Posterior: test positivo, 70% sí tiene el virus (hay falsos positivos)\n",
    "\n",
    "Prior: el código es enorme, 80% debe haber un bug. <br>\n",
    "Posterior: una semana sin errores, 33.781% hay un bug \n",
    "\n",
    "Prior: todo número par es la suma de dos primos (conjetura de Goldbach) <br>\n",
    "Posterior: no se ha encontrado contraejemplo, puede ser cierto (pero no 100% seguro).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Visualicemos el ejemplo de una moneda.\n",
    "\n",
    "Objetivo: inferir la probabilidad de que caiga cara dado unos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot interactivo. Actualización de creencias con datos (ejemplo moneda)\n",
    "# Ver plot interactivo en el notebook\n",
    "\n",
    "theta_real = 0.375 #probabilidad de cara (la que queremos inferir)\n",
    "def posterior_beta(lanzamientos, a, b):\n",
    "    #Likelihood: caras se distribuye Bernoulli\n",
    "    #Prior: Beta con parametros a, b \n",
    "    #NOTA: más adelante en el curso derivaremos el posterior\n",
    "    #para saber de donde viene, y por qué termina siendo beta, \n",
    "    #como el prior (no siempre es el caso que el posterior sea \n",
    "    #de la familia del prior)\n",
    "    \n",
    "    #Experimento (data)\n",
    "    np.random.seed(seed=1144)\n",
    "    caras = st.bernoulli.rvs(theta_real, size=lanzamientos).sum()\n",
    "    \n",
    "    #Prior (creencia)\n",
    "    prior_par = np.array([a,b]) \n",
    "    \n",
    "    #Posterior (creencia actualizada)\n",
    "    nsims = 10000\n",
    "    a = caras + prior_par[0]\n",
    "    b = lanzamientos - caras + prior_par[1]\n",
    "    posterior_samples = np.sort(st.beta.rvs(a = a, b = b, size = nsims)) \n",
    "    posterior_pdf = st.beta.pdf(x = posterior_samples, a = a, b = b)\n",
    "    \n",
    "    #Gráfica\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "    idx1 = np.where(posterior_samples>=np.percentile(posterior_samples,q=2.5))[0][0]\n",
    "    idx2 = np.where(posterior_samples>=np.percentile(posterior_samples,q=97.5))[0][0]\n",
    "    text = \"[\" + str(np.round(posterior_samples[idx1],3)) +\\\n",
    "    \",\" + str(np.round(a/(a+b),3)) +\\\n",
    "    \",\" + str(np.round(posterior_samples[idx2],3)) + \"]\"\n",
    "    ax.plot(posterior_samples, posterior_pdf,'r-', lw=5, alpha=0.8, \n",
    "            label = '[2.5%, mean, 97.5%]  = ' + text)\n",
    "    ax.set_title('Posterior (creencia de cara) \\n Prob. real: ' + str(theta_real))\n",
    "    ax.set_xlabel('Probabilidad cara')\n",
    "    ax.set_ylabel('Densidad')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1.2*np.max(posterior_pdf)])\n",
    "    ax.legend(loc = 'upper right')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae610a219aa4dc5822434e2afd52cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(BoundedIntText(value=3, description='Lanzadas: ', max=1000000, mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_experimento = widgets.BoundedIntText(value = 3, description = 'Lanzadas: ',\n",
    "                                      min = 1, max = 1000000)\n",
    "#Beta(1,1) es uniforme. Busque en internet la distribucion Beta; conozcola.\n",
    "w_prior_par_a = widgets.BoundedIntText(value = 1, description = 'Prior par a: ',\n",
    "                        min = 1, max = 1000000)\n",
    "w_prior_par_b = widgets.BoundedIntText(value = 1, description = 'Prior par b: ',\n",
    "                        min = 1, max = 1000000)\n",
    "out = widgets.interactive_output(posterior_beta, \n",
    "                                 {'lanzamientos': w_experimento, \n",
    "                                  'a': w_prior_par_a, 'b': w_prior_par_b})\n",
    "left_widgets = VBox([w_experimento])\n",
    "right_widgets = VBox([w_prior_par_a, w_prior_par_b])\n",
    "top = HBox([left_widgets, right_widgets])\n",
    "VBox([top, out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Otro ejemplo basado en Kahneman, 2011, Thinking, Fast, and Slow.\n",
    "\n",
    "Objetivo: adivinar la profesión.\n",
    "\n",
    "Carlos es tímido, amable, pero con poco interés por socializar. Le gusta el orden y es preciso en su trabajo.\n",
    "\n",
    "¿Ingeniero electrónico o administrador de empresas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La mayoría dice ingeniero electrónico. ¿Por qué? ¿Reporte del likelihood? ¿Obviar el prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Otro ejemplo: Ingeniero electrónico o administrador.\n",
    "#Basado en: Davidson-Pilon (2015).\n",
    "def posterior_beta_carlos(a_prior, b_prior, data_experimento):\n",
    "    #Bayes\n",
    "    prior_par = np.array([a_prior,b_prior])\n",
    "    prior_mean = [a_prior/(a_prior+b_prior), 1 - a_prior/(a_prior+b_prior)]\n",
    "    nsims = 10000\n",
    "    juicio_ing = data_experimento[0]\n",
    "    juicio_todos = data_experimento.sum() \n",
    "    a =  juicio_ing + prior_par[0]\n",
    "    b = juicio_todos - juicio_ing + prior_par[1]\n",
    "    posterior_mean = [a/(a+b), 1 - a/(a+b)] #Con prior uniforme\n",
    "    \n",
    "    a =  juicio_ing + prior_real[0]\n",
    "    b = juicio_todos - juicio_ing + prior_real[1]\n",
    "    posterior_real_mean = [a/(a+b), 1 - a/(a+b)]#Con prior real\n",
    "    \n",
    "    #Gráfica\n",
    "    #Con prior uniforme\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12, 3))\n",
    "    colors = [\"#348ABD\", \"#A60628\"]\n",
    "    fig.suptitle('Prior y posteriors de las profesiones de Carlos')\n",
    "    ax[0].bar([0, .7], prior_real, alpha=0.70, width=0.25, color=colors[0], label=\"Prior real\",\n",
    "            lw=\"3\", edgecolor=\"#348ABD\")\n",
    "    ax[0].bar([0+0.25, .7+0.25], posterior_mean, alpha=0.7,\n",
    "            width=0.25, color=colors[1], label=\"Posterior con prior uniforme\",\n",
    "            lw=\"3\", edgecolor=\"#A60628\")\n",
    "    ax[0].set_xticks([0.20, 0.95])\n",
    "    ax[0].set_xticklabels([\"Ingeniero\", \"Admin.\"])\n",
    "    #ax[0].set_title(\"Prior real y posterior de las profesiones de Carlos\")\n",
    "    ax[0].set_ylabel(\"Probabilidad\")\n",
    "    ax[0].set_ylim([0,1.1])\n",
    "    ax[0].legend(loc=\"upper right\");\n",
    "    \n",
    "    #Con prior real\n",
    "    ax[1].bar([0, .7], prior_real, alpha=0.70, width=0.25, color=colors[0], label=\"Prior real\",\n",
    "            lw=\"3\", edgecolor=\"#348ABD\")\n",
    "    ax[1].bar([0+0.25, .7+0.25], posterior_real_mean, alpha=0.7,\n",
    "            width=0.25, color=colors[1], label=\"Posterior con prior real\",\n",
    "            lw=\"3\", edgecolor=\"#A60628\")\n",
    "    ax[1].set_xticks([0.20, 0.95])\n",
    "    ax[1].set_xticklabels([\"Ingeniero\", \"Admin.\"])\n",
    "    #ax[1].set_title(\"Prior real y posterior de las profesiones de Carlos\")\n",
    "    ax[1].set_ylabel(\"Probabilidad\")\n",
    "    ax[1].set_ylim([0,1.1])\n",
    "    ax[1].legend(loc=\"upper right\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Datos reales: Colombia, asumamos 2 carreras, datos min. educacion 2001-2018.\n",
    "grad = np.array([24763, 153635]) #graduados [electrónica, administración]\n",
    "prior_real = [grad[0]/grad.sum(), grad[1]/grad.sum()] \n",
    "\n",
    "#Experimento. Asumamos que le preguntamos a todos los graduados y \n",
    "# encontramos estos juicios de Carlos: [ingeniero electrónico, administrador]\n",
    "data_experimento = np.array([round(grad.sum()*3/4), round(grad.sum()*1/4)]) \n",
    "print('Data experimento: \\nElectrónico: ' + str(data_experimento[0]) + \"\\nAdministrador: \"  + str(data_experimento[1]))\n",
    "\n",
    "#El prior real (azul) se ve diferente a las creencias (posterior, rojo). \n",
    "#No importa cual prior se use, la creencia esta sesgada. La gente no usa \n",
    "#la probabilidad real apriori de ser ingeniero electrónico.\n",
    "#Usan el likelihood: La probabilidad de la descripción de Carlos, dada \n",
    "#la hipótesis de ser ingeniero, es alta. \n",
    "posterior_beta_carlos(1, 1, data_experimento) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Qué hipótesis $\\theta$ pueden interesarnos en ciencia cognitiva e inteligencia artificial? \n",
    "\n",
    "* Aversión al riesgo\n",
    "* Impulsividad (e.g. tasa de descuento intertemporal)\n",
    "* Utilidad subjetiva\n",
    "* Confianza institucional\n",
    "* Egoismo\n",
    "* Altruismo\n",
    "* Empatía \n",
    "* Psicopatía\n",
    "* Sensibilidad perceptual\n",
    "* Habilidad matemática\n",
    "* Capacidad en bits de un aprendiz\n",
    "* Interpretación pragmática de una oración\n",
    "* Identidad de un objeto en el campo visual\n",
    "* Creatividad\n",
    "* Nivel de incertidumbre\n",
    "* Otras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Derivación matemática de una posterior beta.\n",
    "### Likelihood: Bernoulli\n",
    "### Prior: Beta\n",
    "### Posterior: Beta (a demostrar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Datos: binarios independientes (e.g. cara-sello; cesta-no cesta; pasar-perder; feliz-infeliz)\n",
    "\n",
    "Objetivo: estimar probabilidad latente de éxito\n",
    "\n",
    "Solución: modelo Beta (Prior) - Bernoulli (LH)\n",
    "\n",
    "<center><img src=\"img/2_CB/beta_bernoulli.svg\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿A dónde vamos?\n",
    "\n",
    "Vamos a mostrar que el posterior, al igual que el prior, también es beta. Cuando ocurre esto, decimos que tenemos un `conjugate prior` del likelihood. \n",
    "\n",
    "Es decir, el conjugate prior de una Bernoulli es una Beta (ver otros en: https://en.wikipedia.org/wiki/Conjugate_prior).\n",
    "\n",
    "Esto es útil si queremos obtener una expresión matemática. A continuación vamos a demostrar la conjugación para nuestro ejemplo Bernoulli-Beta.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bernoulli (pmf); Dominio: n = 0 o 1; Parámetros: p = [0,1] \n",
    "$$P(n) = p^n(1-p)^{1-n}$$\n",
    "\n",
    "Beta (pdf); Dominio: x = [0,1]; Parámetros: $\\alpha$ y $\\beta$ > 0; Otros: B = Función Beta\n",
    "\n",
    "$$P(x) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9b63d7ce4d4493bf8b95e6a85bce02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(BoundedIntText(value=1, description='a (num): ', max=1000000, min…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def beta_bernoulli(p, a, b):\n",
    "    fig, ax = plt.subplots(1,2,figsize = (10.5,4))\n",
    "    x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "    ax[0].plot(x, st.beta.pdf(x, a, b), 'r-', lw=5, alpha=0.6, label='beta pdf')\n",
    "    ax[0].set_xlim([0,1]);\n",
    "    ax[0].set_title('Prior')\n",
    "    ax[0].legend()\n",
    "\n",
    "    x = np.linspace(st.bernoulli.ppf(0.001, p), st.bernoulli.ppf(0.999, p),2)\n",
    "    ax[1].plot(x, st.bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')\n",
    "    ax[1].vlines(x, 0, st.bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)\n",
    "    ax[1].set_xlim([-0.5,1.5]);\n",
    "    ax[1].set_ylim([0,1.05]);\n",
    "    ax[1].set_title('Likelihood')\n",
    "    ax[1].legend();\n",
    "    ax[1].set_xticks([0, 1])\n",
    "    ax[1].set_xticklabels([\"0\", \"1.\"]);\n",
    "    \n",
    "\n",
    "#Bernoulli\n",
    "w_par_p = widgets.FloatSlider(value = 0.5, description = 'p: ', step = 0.01, min = 0, max = 1)\n",
    "\n",
    "#Beta(1,1) es uniforme. Busque en internet la distribucion Beta; conozcala.\n",
    "w_par_a = widgets.BoundedIntText(value = 1, description = 'a (num): ',\n",
    "                                 min = 1, max = 1000000)\n",
    "w_par_b = widgets.BoundedIntText(value = 1, description = 'b (den-num): ',\n",
    "                                 min = 1, max = 1000000)\n",
    "out = widgets.interactive_output(beta_bernoulli, \n",
    "                                 {'p': w_par_p, \n",
    "                                  'a': w_par_a, 'b': w_par_b})\n",
    "right_widgets = VBox([w_par_p])\n",
    "left_widgets = VBox([w_par_a, w_par_b])\n",
    "top = HBox([left_widgets, right_widgets])\n",
    "VBox([top, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El problema bayesiano es (sin la constante de propocionalidad): \n",
    "<center><img src=\"img/2_CB/bayes_framework.gv.svg\" width = \"550\" height = '350'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El problema bayesiano es (sin la constante de propocionalidad):\n",
    "\n",
    "$$posterior \\propto prior \\times likelihood$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prior (modelo de creencias) y likelihood (modelo para los datos) ya los escogimos:\n",
    "\n",
    "$$posterior \\propto Beta \\times Bernoulli$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ahora pongamos las formulas\n",
    "\n",
    "$$P(\\theta|exitos,intentos,\\alpha,\\beta,p) \\propto \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)} \\times p^{exitos}(1-p)^{intentos-exitos}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Algebra:<br>\n",
    "pars = $\\alpha,\\beta,p$ <br>\n",
    "N = intentos<br>\n",
    "z = exitos\n",
    "\n",
    "El posterior es proporcional a la multiplicación de una beta y una Bernoulli\n",
    "\\begin{align*}\n",
    "  p(\\theta|z,N,pars) &\\propto \\theta^z(1-\\theta)^{N-z}\\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sumamos exponentes\n",
    "\\begin{align*}\n",
    "  p(\\theta|z,N,pars) &\\propto ... \\\\\n",
    "  &\\propto \\frac{\\theta^{z+\\alpha-1}(1-\\theta)^{N-z+\\beta-1}}{B(\\alpha,\\beta)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "  p(\\theta|z,N,pars) \\propto \\frac{\\theta^{z+\\alpha-1}(1-\\theta)^{N-z+\\beta-1}}{B(\\alpha,\\beta)}\n",
    "\\end{equation}\n",
    "\n",
    "Seguimos con la versión proporcional. Pero note que el numerador es el de una distribución beta con parámetros: \n",
    "\n",
    "$$\\alpha_{posterior} = z + \\alpha$$\n",
    "$$\\beta_{posterior} = N - z + \\beta$$\n",
    "\n",
    "¡Y ya conocemos como se ve estandarizada! Solo toca cambiar el denominador y poner un igual: \n",
    "\\begin{equation}\n",
    "  p(\\theta|z,N,pars) = \\frac{\\theta^{\\alpha_{posterior}-1}(1-\\theta)^{N-z+\\beta_{posterior}-1}}{B(\\alpha_{posterior},\\beta_{posterior})}\n",
    "\\end{equation} \n",
    "\n",
    "Es decir, el posterior es una beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Apreciemos el resultado.\n",
    "$$ p(\\theta|z,N,\\alpha,\\beta) \\sim beta(z+\\alpha, N-z+\\beta) $$ \n",
    "\n",
    "El posterior incluye datos (N,z) y creencias previas ($\\alpha$, $\\beta$).\n",
    "\n",
    "Empezamos con un prior beta y un likelihood Bernoulli. Terminamos con un posterior beta. ¡Encontramos un conjugate prior del likelihood! (ver más en https://en.wikipedia.org/wiki/Conjugate_prior) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lección importante de Bayes:\n",
    "\n",
    "Si hay buenos datos y el prior es débil, los parámetros de mis creencias $\\theta$ los domina la evidencia. Por ejemplo:\n",
    "\n",
    "$$ p(\\theta|z=3750, N=10.000,\\alpha=5,\\beta=9) \\sim beta(3750+5, 10.000-z+9) $$ \n",
    "\n",
    "O si el prior es fuerte y hay datos inconclusos, los parámetros de mis creencias $\\theta$ los domina el prior.\n",
    "\n",
    "$$ p(\\theta|z=11, N=44,\\alpha=5.000,\\beta=9.000) \\sim beta(11+5.000, 44-11+9.000) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lección importante de Bayes (visualmente):\n",
    "\n",
    "Hay una \"lucha\" entre prior (creencias) y likelihood (evidencia) para influir en las nuevas creencias (posterior)\n",
    "\n",
    "<center><img src=\"img/2_CB/Prior_vs_LH.svg\" width = \"551\" height = '550'></center>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Derivación matemática de una posterior normal\n",
    "### Likelihood: Normal\n",
    "### Prior: Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Likelihood (normal)\n",
    "$$ p(y|\\theta) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2\\sigma^2}(y-\\theta)^2}$$\n",
    "\n",
    "Prior (normal)\n",
    "$$ p(\\theta) = \\frac{1}{\\sqrt{2\\pi}\\tau_0}e^{-\\frac{1}{2\\tau_0^2}(\\theta-\\mu_0)^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El problema bayesiano es (sin la constante de propocionalidad): \n",
    "<center><img src=\"img/2_CB/bayes_framework.gv.svg\" width = \"550\" height = '350'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El problema bayesiano es (sin la constante de propocionalidad):\n",
    "\n",
    "$$posterior \\propto prior \\times likelihood$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prior (modelo de creencias) y likelihood (modelo para los datos) ya los escogimos:\n",
    "\n",
    "$$posterior \\propto Normal (\\mu_0,\\tau_0^2) \\times Normal(\\theta,\\sigma^2)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ahora pongamos las formulas\n",
    "\n",
    "$$P(\\theta|y, \\sigma,\\tau_0,\\mu_0) \\propto \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2\\sigma^2}(y-\\theta)^2}\\times \\frac{1}{\\sqrt{2\\pi}\\tau_0}e^{-\\frac{1}{2\\tau_0^2}(\\theta-\\mu_0)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Algebra!! Primero, quitemos constantes (no cambia la proporcionalidad)\n",
    "\\begin{align}\n",
    " &\\propto e^{-\\frac{1}{2\\sigma^2}(y-\\theta)^2}\\times e^{-\\frac{1}{2\\tau_0^2}(\\theta-\\mu_0)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sumemos exponentes\n",
    "\\begin{align}\n",
    "     &\\propto e^{-\\frac{1}{2}\\left(\\frac{(y-\\theta)^2}{\\sigma^2} + \\frac{(\\theta-\\mu_0)^2}{\\tau_0^2}\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left(\\tau_0^2(y-\\theta)^2 + \\sigma^2(\\theta-\\mu_0)^2\\right)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Expandimos cuadrados\n",
    "\\begin{align}\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left(\\tau_0^2(y^2-2\\theta y + \\theta^2) + \\sigma^2(\\theta^2-2\\theta\\mu_0+\\mu_0^2)\\right)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Agrupamos términos con $\\theta$ y sacamos constantes\n",
    "\\begin{align}\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\tau_0^2\\theta^2 + \\sigma^2\\theta^2-\\sigma^22\\theta\\mu_0-\\tau_0^22\\theta y + \\sigma^2\\mu_0^2 + \\tau_0^2y^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\theta^2(\\tau_0^2 + \\sigma^2) - 2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)  + \\sigma^2\\mu_0^2 + \\tau_0^2y^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\theta^2(\\tau_0^2 + \\sigma^2) - 2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)\\right)}e^{\\frac{\\sigma^2\\mu_0^2 + \\tau_0^2y^2}{2\\sigma^2\\tau_0^2}}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\theta^2(\\tau_0^2 + \\sigma^2) - 2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left( \\theta^2 - \\frac{2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Completemos cuadrados. <br>\n",
    "Si tenemos: $\\theta^2 + b\\theta$; <br> \n",
    "Completar con: $\\theta^2 + b\\theta + \\left(\\frac{b}{2}\\right)^2 -\\left(\\frac{b}{2}\\right)^2 = \\left(x+\\frac{b}{2}\\right)^2 - \\left(\\frac{b}{2}\\right)^2 $\n",
    "\n",
    "\\begin{align}\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left( \\theta^2 - \\frac{2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left( \\theta^2 - \\frac{2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2} + \\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2 -\\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2 -\\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2\\right)}e^{-\\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2\\right)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Encontramos una $Normal(\\mu_1,\\sigma_1^2)$\n",
    "\n",
    "\\begin{align}\n",
    "P(\\theta|y, \\sigma,\\tau_0,\\mu_0) &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2\\right)}\n",
    "\\end{align}\n",
    "\n",
    "$\\mu_1 = \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2} = \\frac{\\tau_0^{-2}\\mu_0 + \\sigma^{-2} y}{\\tau_0^{-2} + \\sigma^{-2}}$ \n",
    "\n",
    "$\\sigma_1 = \\frac{\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2} = \\frac{1}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau_0^2}}$\n",
    "\n",
    "Nota: el 2do igual en $\\mu_1$ y $\\sigma_1$ se obtiene dividiendo arriba y abajo por $\\frac{1}{\\sigma^2\\tau_0^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Apreciemos el resultado:\n",
    "\n",
    "$\\mu_1 = \\frac{\\tau_0^{-2}\\mu_0 + \\sigma^{-2} y}{\\tau_0^{-2} + \\sigma^{-2}}$ \n",
    "\n",
    "$\\sigma_1^2 = \\frac{1}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau_0^2}}$\n",
    "\n",
    "El promedio del posterior es una ponderación entre datos ($y$) y el promedio del prior ($\\mu_0$). La ponderación depende de la varianza del likelihood y el prior.\n",
    "\n",
    "La varianza del posterior depende de la suma de las varianzas (invertidas) del likelihood y el prior. La varianza del posterior siempre es menor a la del likelihood y prior.\n",
    "\n",
    "Nota: si $y$ son n datos, cambiar $y$ por el promedio. $\\sigma^2$ se divide por n (busque la prueba en internet). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lección importante de Bayes:\n",
    "\n",
    "El posterior es un compromiso entre información en los datos y creencias (prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lección importante de Bayes (visualización):\n",
    "\n",
    "El posterior es un compromiso entre información en los datos y creencias (prior) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3e12dbf15244cd9918105c0d1cdfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=10, description='N datos: ', min=1), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normal_normal(muestras):\n",
    "    #Objetivo: averiguar el promedio de un proceso (e.g. prejuicios) \n",
    "    #          dada una evidencia\n",
    "    #Modelo: Normal-Normal\n",
    "    np.random.seed(seed=1144)\n",
    "    #muestras = 20\n",
    "    datos_par = [0,1]#mu, sd\n",
    "    evidencia = np.sort(st.norm.rvs(size = muestras, \n",
    "                                    loc = datos_par[0], \n",
    "                                    scale = datos_par[1])) #asumamos data normal, pero en la vida real puede que no\n",
    "    prior_par = [-10, 1] #mu, sd\n",
    "    likelihood_par = [3] #sd\n",
    "    hipotesis = np.linspace(-20,20,200)\n",
    "    likelihood = []\n",
    "    for i in range(len(hipotesis)):\n",
    "        lh = np.sum(st.norm.pdf(evidencia,\n",
    "                                loc = hipotesis[i],\n",
    "                                scale = likelihood_par[0]))\n",
    "        likelihood.append(lh) #Likelihood no estandarizada\n",
    "    prior = st.norm.pdf(hipotesis,\n",
    "                        loc = prior_par[0],\n",
    "                        scale = prior_par[1])\n",
    "    A = prior_par[0]/(prior_par[1]**2)\n",
    "    B = evidencia.mean()/(likelihood_par[0]**2/muestras)                  \n",
    "    C = 1/(prior_par[1]**2)\n",
    "    D = 1/(likelihood_par[0]**2/muestras)\n",
    "    post_par = [round((A + B)/(C + D),2),\n",
    "               round(np.sqrt(1/(C+D)),2)]\n",
    "    posterior = st.norm.pdf(hipotesis,\n",
    "                        loc = post_par[0],\n",
    "                        scale = post_par[1])\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize = (10,5))\n",
    "    #Prior\n",
    "    y = prior/np.max(prior)\n",
    "    idx = y>0.001\n",
    "    ax.plot(hipotesis[idx], y[idx], 'r-', lw=2, alpha=0.6, \n",
    "            label='Prior normal('+ str(prior_par[0]) + ','+ str(prior_par[1]) +')')\n",
    "    #Likelihood\n",
    "    y = likelihood/np.max(likelihood)\n",
    "    idx = y>0.001\n",
    "    ax.plot(hipotesis[idx], y[idx], 'b-', lw=2, alpha=0.6, \n",
    "            label='Likelihood normal('+ 'hipotesis' + ','+ str(likelihood_par[0]) +')')\n",
    "    #Posterior\n",
    "    y = posterior/np.max(posterior)\n",
    "    idx = y>0.00001\n",
    "    ax.plot(hipotesis[idx], y[idx], 'g-', lw=2, alpha=0.6, \n",
    "            label='Posterior normal('+ str(post_par[0]) + ','+ str(post_par[1]) +')')\n",
    "    #Realidad\n",
    "    ax.plot(np.repeat(datos_par[0],100),\n",
    "           np.linspace(0,1,100),'k--',lw=2,\n",
    "           label = 'Real')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([np.min(hipotesis), np.max(hipotesis)])\n",
    "    ax.set_xlabel('Hipótesis')\n",
    "    ax.set_ylabel('Probabilidad \\n (densidad relativa al max)');\n",
    "    #fig.savefig('img/2_CB/norm_norm.svg')\n",
    "\n",
    "wN = widgets.IntSlider(value=10, min = 1, max = 100,\n",
    "                       description='N datos: ')\n",
    "\n",
    "out = widgets.interactive_output(normal_normal, \n",
    "                                 {'muestras': wN})\n",
    "\n",
    "VBox([wN, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algunos resultados y definiciones útiles de teoría de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Definiciones\n",
    "* Densidad condicional: $p(u|v)$\n",
    "* Densidad marginal: $p(u) = \\int p(u,v) dv$\n",
    "* Densidad conjunta: $p(u,v) = p(u|v)p(v)$\n",
    "* Posterior predictive distribution (de $\\tilde{obs}$): $p(\\tilde{obs}|obs) = \\int p(\\tilde{obs}|\\theta)p(\\theta|obs)d\\theta$\n",
    "* $E(u)$ es valor esperado: $\\int up(u)du$\n",
    "* $var(u)$ es varianza: $\\int (u - E(u))(u - E(u))^Tp(u)du$\n",
    "\n",
    "Resultados \n",
    "* Regla de la cadena (aplicación densidad conjunta; ejemplo con 3 variables): $p(u,v,w) = p(u|v,w)p(v,w) = p(u|v,w)p(v|w)p(w)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusión\n",
    "Bayes nos dio una forma de actualizar creencias con datos\n",
    "\n",
    "Las nuevas creencias son un compromiso entre datos y creencias a priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='none' --SlidesExporter.reveal_scroll=True 2_Conociendo_Bayes.ipynb #Saves slide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Para salvar las diapositivas a PDF (en Chrome), correr nbconvert para que abra las diapositivas en un servidor local (la transition y el theme son opcionales):\n",
    "\n",
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='convex' nombre_de_mi_notebook.ipynb --post serve\n",
    "\n",
    "Luego, a la dirección añadirle ?print-pdf después del .html:\n",
    "\n",
    "http://127.0.0.1:8000/nombre_de_mi_notebook.slides.html?print-pdf\n",
    "\n",
    "Y luego, imprimir y darle salvar como pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Para salvar a pdf\n",
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='convex' 2_Conociendo_Bayes.ipynb --post serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Anexos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "x = np.linspace(st.norm.ppf(0.01),st.norm.ppf(0.99), 100)\n",
    "\n",
    "ax[0].plot(x, st.norm.pdf(x),'r-', lw=5, alpha=0.8, label='norm pdf')\n",
    "ax[0].set_xlabel('Hipótesis (e.g. riesgo relativo)')\n",
    "ax[0].set_ylabel('Densidad')\n",
    "ax[0].set_title('Normal')\n",
    "mu = 10\n",
    "x = np.arange(st.poisson.ppf(0.01, mu), st.poisson.ppf(0.99, mu))\n",
    "ax[1].plot(x, st.poisson.pmf(x, mu), 'bo', ms=8, label='poisson pmf')\n",
    "ax[1].vlines(x, 0, st.poisson.pmf(x, mu), colors='b', lw=5, alpha=0.5)\n",
    "ax[1].set_xlabel('Hipótesis (e.g. ataques de ansiedad por día)')\n",
    "ax[1].set_ylabel('Densidad')\n",
    "ax[1].set_title('Poisson')\n",
    "fig.savefig('img/2_CB/normal_poisson.svg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "a, b = 2, 4\n",
    "x = np.linspace(st.beta.ppf(0.001,a,b),st.beta.ppf(0.999,a,b), 100)\n",
    "\n",
    "ax.plot(x, st.beta.pdf(x,a,b),'r-', lw=5, alpha=0.8, label='beta pdf')\n",
    "ax.set_xlabel('Hipótesis')\n",
    "ax.set_ylabel('Densidad')\n",
    "ax.set_title('Beta')\n",
    "ax.set_frame_on(False)\n",
    "fig.savefig('img/2_CB/beta.svg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Visualización Bernoulli y Beta\n",
    "fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "a, b = 2, 3\n",
    "x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "ax[0].plot(x, st.beta.pdf(x, a, b), 'r-', lw=5, alpha=0.6, label='beta pdf')\n",
    "ax[0].set_title('Prior')\n",
    "ax[0].legend()\n",
    "\n",
    "p = 0.3 #prob. de éxito\n",
    "x = np.linspace(st.bernoulli.ppf(0.001, p), st.bernoulli.ppf(0.999, p),2)\n",
    "ax[1].plot(x, st.bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')\n",
    "ax[1].vlines(x, 0, st.bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)\n",
    "ax[1].set_xlim([-0.5,1.5]);\n",
    "ax[1].set_title('Likelihood')\n",
    "ax[1].legend();\n",
    "ax[1].set_xticks([0, 1])\n",
    "ax[1].set_xticklabels([\"0\", \"1.\"]);\n",
    "fig.savefig('img/2_CB/beta_bernoulli.svg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Graphical models with graphviz (http://www.graphviz.org/pdf/dotguide.pdf)\n",
    "\n",
    "#Example 1 (graph with different shapes)\n",
    "dot_text = 'digraph G {a -> b -> c;\\\n",
    "                       b -> d;\\\n",
    "                       a [shape=circle,peripheries=2,color=gray,style=filled];\\\n",
    "                       c [shape=polygon,sides=4,skew=.4,label=\"recuado bogota\"];\\\n",
    "                       d [shape=invtriangle];\\\n",
    "                       e [shape=polygon,sides=4,distortion=.7];\\\n",
    "                       }' #warning: use single quote at start and end; double quotes for labels\n",
    "src = Source(dot_text)\n",
    "src.render('img/2_CB/test.gv', format ='svg', view=False)\n",
    "#display(src)\n",
    "\n",
    "\n",
    "#Example 2 (graph with edges on clusters)\n",
    "dot_text = 'digraph G {compound=true;\\\n",
    "                       subgraph cluster0 {a -> b;a -> c;b -> d;c -> d;\\\n",
    "                                          subgraph cluster1 {a; b; c}\\\n",
    "                                          }\\\n",
    "                       subgraph cluster2 {e -> g;e -> f;}\\\n",
    "                       b -> f [lhead=cluster2];\\\n",
    "                       d -> e;\\\n",
    "                       c -> g [ltail=cluster0,lhead=cluster2];\\\n",
    "                       c -> e [ltail=cluster0];\\\n",
    "                       d -> h;\\\n",
    "                       b[shape=circle,peripheries=2,color=gray,style=filled];\\\n",
    "                       }' #warning: use single quote at start and end; double quotes for labels\n",
    "src = Source(dot_text)\n",
    "src.render('img/2_CB/test2.gv', format ='svg', view=False);\n",
    "#display(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dot_text = 'digraph G {rankdir=LR;\\\n",
    "                       a -> c;\\\n",
    "                       b -> c;\\\n",
    "                       a [shape=polygon,sides=4,label=\"Prior\\n(creencias)\"];\\\n",
    "                       b [shape=polygon,sides=4,label=\"Likelihood\\n(evidencia)\"];\\\n",
    "                       c [shape=polygon,sides=4,label=\"Posterior\\n(nuevas creencias)\"];\\\n",
    "                       }' #warning: use single quote at start and end; double quotes for labels\n",
    "src = Source(dot_text)\n",
    "src.render('img/2_CB/bayes_framework.gv', format ='svg', view=False)\n",
    "display(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Visualización lucha likelihood vs prior para dominar posterior\n",
    "fig, ax = plt.subplots(1,1,figsize = (10,5))\n",
    "#Prior\n",
    "a, b = 10, 40\n",
    "x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "y = st.beta.pdf(x, a, b)\n",
    "ax.plot(x, y/np.max(y), 'r-', lw=2, alpha=0.6, \n",
    "        label='Prior beta('+ str(a) + ','+ str(b) +')')\n",
    "\n",
    "#Likelihood\n",
    "N = 40 #Intentos\n",
    "z = 32 #Exitos\n",
    "p = np.linspace(0.6,1,100) #hipótesis prob. de éxito\n",
    "bernoulli_pmf = p**z*(1-p)**(N-z) #likelihood \n",
    "y = bernoulli_pmf\n",
    "ax.plot(p, y/np.max(y), 'b-', lw=2, \n",
    "        label='Likelihood Bernoulli.\\nExitos: ' + str(z) + ', ' + 'Intentos: ' + str(N))\n",
    "ax.legend();\n",
    "\n",
    "#Posterior\n",
    "a, b = z+a, N-z+b\n",
    "x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "y = st.beta.pdf(x, a, b)\n",
    "ax.plot(x, y/np.max(y), 'g-', lw=2, alpha=0.6, \n",
    "        label='Posterior beta('+ str(a) + ','+ str(b) +')')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title('Posterior: Prior vs. Likelihood', fontsize = 20)\n",
    "ax.set_ylabel('Probabilidad \\n (relativo al max)', fontsize = 20)\n",
    "ax.set_xlabel('Hipótesis (prob. de exito)', fontsize = 20)\n",
    "ax.set_xlim([-0.05,1.05]);\n",
    "ax.set_ylim([0,1.5]);\n",
    "ax.legend(loc = 'upper right', fontsize = 12)\n",
    "plt.tight_layout\n",
    "fig.savefig('img/2_CB/Prior_vs_LH.svg');"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "chalkboard": {
    "color": [
     "rgb(250, 0, 0)",
     "rgb(0, 250, 250)"
    ]
   },
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
