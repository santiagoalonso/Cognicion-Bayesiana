{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.11.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Manejo de matrices y tablas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Estadistica y funciones matemáticas\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import fmin\n",
    "from scipy import integrate\n",
    "from scipy.stats.mstats import mquantiles\n",
    "import statistics \n",
    "\n",
    "#Probabilistic programs\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt #NOTA: theano va a cambiar a tensorflow en PyMC4\n",
    "import theano\n",
    "from theano.compile.ops import as_op\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "\n",
    "#Graficas\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import altair as alt\n",
    "from altair_saver import save #ademas instalar en terminal: brew cask install chromedriver\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, HBox, VBox, Layout\n",
    "from graphviz import Source, Digraph\n",
    "import dot2tex as d2t\n",
    "from latex import build_pdf\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import arviz as az\n",
    "\n",
    "#Funciones propias (tienen que estar en el mismo directorio)\n",
    "import my_fun as mf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decisiones de riesgo\n",
    "\n",
    "Santiago Alonso-Díaz, PhD <br>\n",
    "Universidad Javeriana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Empecemos con un ejercicio.\n",
    "\n",
    "Hombre de 95 años con tumor  \n",
    "- 0.9 de probabilidad es maligno \n",
    "- Si no es maligno, tiene 34.8 meses de vida\n",
    "- Si es maligno:\n",
    "    - Con radioterapia,  16.7 meses de vida\n",
    "    - Con cirugia, 0.35 prob. de morir, 0.65 de vivir 20.3 meses\n",
    "    - Sin tratamiento, 5.6 meses de vida\n",
    "    - Radioterapia o cirugia reduce tiempo de vida en 1 mes adicional\n",
    "\n",
    "Muestre que la radioterapia es el tratamiento preferido (valor esperado: 17.5 meses de vida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un marco general en teoría de la decisión es la idea de utilidad esperada\n",
    "\n",
    "$$ U(x) = p(x) v(x)$$\n",
    "\n",
    "Pregunta: ¿Es probabilidad lo mismo que riesgo? No, es un elemento.\n",
    "\n",
    "Pregunta 2: ¿Es riesgo lo mismo que incertidumbre? No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ha aumentado el uso de la palabra riesgo (Li & Hertwig, 2020)\n",
    "<center><img src=\"img/6_CB/Li1.svg\" width = \"400\" height = '400'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Principales asociaciones con riesgo (Li & Hertwig, 2020)\n",
    "<center><img src=\"img/6_CB/Li2.svg\" width = \"400\" height = '400'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Preferencias de riesgo se relacionan en varios dominios (Dohmen, et al, 2011)\n",
    "<center><img src=\"img/6_CB/Dohmen1.png\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\" style = \"font-size: 70px\"> ¿Qué es riesgo? </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# En riesgo CONOCEMOS la distribución de probabilidad del evento.\n",
    "# Riesgo puede obtenerse de las distribuciones de prob. (e.g. varianza)\n",
    "wD = widgets.Dropdown(options=[('Normal', 0), \n",
    "                               ('Uniform', 1), \n",
    "                               ('Log-Normal', 2)],\n",
    "                        value=0, description='Distr.: ')\n",
    "out = widgets.interactive_output(mf.dropdown_callback,{'distr': wD})\n",
    "VBox([wD, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\" style = \"font-size: 70px\"> ¿Actitudes al riesgo en economía? </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Actitudes al riesgo como concavidad de la función de utilidad\n",
    "# Alto valor baja probabilidad alto riesgo\n",
    "wD = widgets.FloatSlider(min = 0, max = 2, step = 0.01, value=1,\n",
    "                        description = 'Actitud')\n",
    "out = widgets.interactive_output(mf.slider_econ_risk,{'alpha': wD})\n",
    "VBox([wD, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\" style = \"font-size: 70px\"> ¿Actitudes al riesgo en ciencias cognitivas y del comportamiento? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hay muchas alternativas:\n",
    "* Regret and disappointment theory (Bell, 1982, 1985; Loomes & Sugden, 1982)\n",
    "* Priority heuristic (Brandstätter, Gigerenzer, & Hertwig, 2006)\n",
    "* Transfer-of-attention exchange model (Birnbaum, 2008; Birnbaum & Chavez, 1997)\n",
    "* Decision field theory (Busemeyer & Townsend, 1993; Roe, Busemeyer, & Townsend, 2001) \n",
    "* Weighted utility theory (e.g. Fishburn, 1983)\n",
    "* Proportional difference model (González-Vallejo, 2002) \n",
    "* Decision affect theory (Mellers, 2000) \n",
    "* Dual system model of preference under risk (Mukherjee, 2010) \n",
    "* Rank-dependent expected utility theories (e.g., Quiggin, 1982)\n",
    "* Decisions by sampling (Stewart, Chater, & Brown, 2006)\n",
    "* Prospect theory (Kahneman & Tversky, 1979)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\" style = \"font-size: 70px\"> ¿Cómo medirlo? </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hay varias alternativas:\n",
    "* Auto-reportes\n",
    "    * Busqueda de sensaciones (Zuckerman, Eysenck, & Eysenck, 1978)\n",
    "    * Busqueda de aventuras (Eysenck, Pearson, Easting, & Allsopp, 1985)\n",
    "    * Impulsividad (Barratt, 1985; Eysenck et al., 1985)\n",
    "    * Otras (Frey, et al, 2017)\n",
    "* Mediciones comportamentales\n",
    "    * The Balloon Analogue Risk Task (Lejuez, et al, 2002)\n",
    "    * Loterías (Kahneman & Tversky, 1979)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelos Bayesianos Descriptivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# BART\n",
    "<center><img src=\"img/6_CB/Lejuez1.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/6_CB/Lejuez2.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Varios turnos. Diferentes colores del globo indican riesgo (no se le dice al sujeto). Cada inflada subía en una constante los dolares ganados y el riesgo de explotar.\n",
    "<center><img src=\"img/6_CB/Lejuez3.png\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ¿Qué riesgo mide BART?\n",
    "\n",
    "Lejuez, et al, 2002 tomaron otras medidas para correlacionarlas con BART\n",
    "\n",
    "* Auto reportes en otros dominios (busqueda de sensaciones, impulsividad, empatía, depresión, personalidad, adicciones a drogas, adicciones a juegos, uso de preservativos, entre otros)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pumps óptimos (centro) \n",
    "<center><img src=\"img/6_CB/Lejuez4.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Resultados\n",
    "\n",
    "* Aversión al riesgo ($pumps < pumps_{optimo}$)\n",
    "* Poca variablidad en naranja y amarillo\n",
    "\n",
    "<center><img src=\"img/6_CB/Lejuez5.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BART se correlaciona con autoreportes. Lejuez, et al, 2002 primero redujeron los autoreportes con PCA.\n",
    "\n",
    "PCA (ejemplo hipotético con dos medidas)\n",
    "<center><img src=\"img/6_CB/GaussianScatterPCA.svg\" width = \"200\" height = '200'></center>\n",
    "\n",
    "PCA (Lejuez)\n",
    "\n",
    "<center><img src=\"img/6_CB/Lejuez6.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BART se correlacionó con las dimensiones de riesgo obtenidas con PCA\n",
    "\n",
    "<center><img src=\"img/6_CB/Lejuez7.png\" width = \"500\" height = '500'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discusión\n",
    "* BART mide preferencias de riesgo que no se capturan con autoreportes.\n",
    "* Hubo aversión al riesgo en promedio (menos pumps de lo óptimo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Aplicación del BART: Contrafactuales\n",
    "\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon1.png\" width = \"600\" height = '600'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Existencialismo ¿Qué tal si hubiera hecho esto?\n",
    "* ¿pagar para saber que hubiera pasado aún si lleva a \"dolor\"? e.g. confirmar infidelidad de su pareja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Información no siempre es instrumental (i.e. no trae beneficios), pero satisface curiosidad.\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon2.png\" width = \"500\" height = '520'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Información no instrumental incluso activa areas del cerebro de recompensa (Fitzgibbon, et al, 2020)\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon3.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Predicción: \n",
    "* Curiosidad contrafactual es un motivador así tenga costos como arrepentimiento.\n",
    "* La curiosidad contrafactual satisfecha induce cambios de comportamientos (e.g. preferir más riesgo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos usar BART para estudiar curiosidad contra-factual\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon4.png\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/6_CB/FitzGibbon5.png\" width = \"700\" height = '700'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Los 5 experimentos fueron similares exceptuando costo info. pues esa era la intervención.\n",
    "<center><img src=\"img/6_CB/FitzGibbon6.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Los turnos con información aumentaban el arrepentimiento (within-subject). Missed opportunity es el numero de pumps adicionales que aguantaba el globo.\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon7.png\" width = \"600\" height = '600'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modelación de riesgo en BART (BART chapter, Lee & Wagenmakers, 2013, textbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Task description: The probability of the balloon bursting is constant, and the expected gain of every decision to pump is zero.\n",
    "<center><img src=\"img/6_CB/LeeWag1.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\gamma^{+}: \\text{risk taking}, \\ \\beta: \\text{consistency}, \\ p: \\text{belief of burst prob.}, \\ d_{jk}: \\text{observed choice}, \\ Choice_k: \\text{k pumps}, \\\\ \\omega: \\text{# of pumps considered optimal}, \\theta_{jk}:\\text{cashing prob.}$\n",
    "<center><img src=\"img/6_CB/model_BART.svg\" width = \"451\" height = '450'></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Understanding/visualizing the parameters\n",
    "p = 0.15 #(belief) prob. of bursting. Assumed by lee and wagenmakers\n",
    "gammap = np.linspace(0,10,100)\n",
    "beta = np.linspace(0,10,100)\n",
    "omega = - (gammap)/(np.log(1-p))\n",
    "\n",
    "#why omega is npumps_optimal conditional on a risk parameter gammap?\n",
    "#let's rename omega to npumps_optim and do some basic algebra\n",
    "#npumps_optim*np.log(1-p) = - gammap\n",
    "#e^(npumps_optim*np.log(1-p)) = (e^-gammap)\n",
    "#e^(np.log((prob_noburst)^npumps_optim)) = (e^-gammap)\n",
    "#prob_noburst^npumps_optim = (e^-gammap) #important one\n",
    "#Conditional on a gammap, the equality means that\n",
    "#above is not tolerable, below is still tolerable. \n",
    "#npumps_optim fullfils the equality \n",
    "\n",
    "k = 9 #observed number of pumps\n",
    "thetajk = 1/(1+np.exp(beta*(k-omega))) #beta is a temperature parameter\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = [10,4])\n",
    "ax[0].plot(gammap, omega)\n",
    "ax[0].set_xlabel('Risk attitudes ($\\\\gamma^{+}$)')\n",
    "ax[0].set_ylabel('Optimal number of pumps ($\\\\omega$)')\n",
    "\n",
    "ax[1].plot(beta, thetajk)\n",
    "ax[1].set_xlabel('Consistency or temperature ($\\\\beta$)')\n",
    "ax[1].set_ylabel('Prob. of choosing to cash');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#The following implementation in PyMC3 was done by Junpeng Lao: \n",
    "# https://github.com/junpenglao/Bayesian-Cognitive-Modeling-in-Pymc3\n",
    "\n",
    "#First: data setup\n",
    "p = 0.15  # (Belief of) bursting probability\n",
    "ntrials = 90  # Number of trials for the BART\n",
    "extreme_npumps = 30 #some unlikely large number\n",
    "\n",
    "Data = pd.read_csv(\"data/6_CB/GeorgeSober.txt\", sep=\"\\t\") #subject named George (he can be sober, tipsy, or drunk; change the filename)\n",
    "print(Data.groupby(['pres.bl']).mean())\n",
    "#gr.fact: I think it is the visual growth of balloon i.e. a cue for the subject\n",
    "#'prob': (real) of bursting; \n",
    "#'pumps': on that trial; \n",
    "#'cash': won on the trial; 'total': cash so far\n",
    "\n",
    "cash = np.asarray(Data[\"cash\"] != 0, dtype=int)\n",
    "npumps = np.asarray(Data[\"pumps\"], dtype=int)\n",
    "options = cash + npumps #type of choices experienced i.e. receiving some cash and pumping n times\n",
    "d = np.full([ntrials, extreme_npumps], np.nan) \n",
    "k = np.full([ntrials, extreme_npumps], np.nan) \n",
    "# response vector\n",
    "for j, ipumps in enumerate(npumps): \n",
    "    inds = np.arange(options[j], dtype=int) \n",
    "    k[j, inds] = inds + 1 #+1 because arange starts at 0\n",
    "    if ipumps > 0:\n",
    "        d[j, 0:ipumps] = 0\n",
    "    if cash[j] == 1:\n",
    "        d[j, ipumps] = 1\n",
    "\n",
    "indexmask = np.isfinite(d) #to clean nans\n",
    "d = d[indexmask] #vector with cashing decisions (0:no, 1: yes); a 0 along a reset of k below means a burst \n",
    "k = k[indexmask] #vector with number of pumps at each decision point in d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npumps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    #Priors\n",
    "    gammap = pm.Uniform(\"gammap\", lower=0, upper=10, testval=1.2)\n",
    "    beta = pm.Uniform(\"beta\", lower=0, upper=10, testval=0.5)\n",
    "    omega = pm.Deterministic(\"omega\", -gammap / np.log(1 - p))\n",
    "    \n",
    "    #Likelihood\n",
    "    thetajk = 1 - pm.math.invlogit(-beta * (k - omega))\n",
    "\n",
    "    djk = pm.Bernoulli(\"djk\", p=thetajk, observed=d)\n",
    "\n",
    "    trace = pm.sample(tune=2000, cores=4, chains = 4)\n",
    "    data = az.from_pymc3(trace=trace)\n",
    "\n",
    "\n",
    "az.plot_trace(data, var_names=[\"gammap\", \"beta\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_trace(data, var_names=[\"omega\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#This plots the fig. 16.3 of lee, wagenmakers, 2013, textbook\n",
    "gammaplus = trace[\"gammap\"]\n",
    "beta = trace[\"beta\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(npumps, bins=range(1, 9), rwidth=0.8, align=\"left\")\n",
    "axes[0].set_xlabel(\"Number of Pumps\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Frequency\", fontsize=12)\n",
    "  \n",
    "my_pdf1 = st.kde.gaussian_kde(gammaplus)\n",
    "x1 = np.linspace(0.5, 1, 200)\n",
    "axes[1].plot(x1, my_pdf1(x1), \"k\", lw=2.5, alpha=0.6)  # distribution function\n",
    "axes[1].set_xlim((0.5, 1))\n",
    "axes[1].set_xlabel(r\"$\\gamma^+$\", fontsize=15)\n",
    "axes[1].set_ylabel(\"Posterior Density\", fontsize=12)\n",
    "\n",
    "my_pdf2 = st.kde.gaussian_kde(beta)\n",
    "x2 = np.linspace(0.3, 1.3, 200)\n",
    "axes[2].plot(\n",
    "    x2, my_pdf2(x2), \"k\", lw=2.5, alpha=0.6,\n",
    ")  # distribution function\n",
    "axes[2].set_xlim((0.3, 1.3))\n",
    "axes[2].set_xlabel(r\"$\\beta$\", fontsize=15)\n",
    "axes[2].set_ylabel(\"Posterior Density\", fontsize=12)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1) Apply the model to data from a different subject, Bill, provided in the file BillSober.txt. Compare the estimated parameters for George and Bill. Who has the greater propensity for risk?\n",
    "\n",
    "2) What happens if two pumps are added to each trial for George’s data? Make this change to the npumps variable (i.e. duplicate npumps). Which of the two parameters changed the most?\n",
    "\n",
    "3) Modify George’s data in a different way to affect the behavioral consistency parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But what does it mean? \n",
    "\n",
    "We have data from the same subject with different alcohol levels. We can estimate parameters for each level or do a hierarchical model. Let's do the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Alcohol and risk.\n",
    "\n",
    "Example 1 (driving) (Burian, Liguori, & Robinson,2002).\n",
    "\n",
    "Penalty severity decreases risky driving in those without alcohol (top panel).\n",
    "\n",
    "In the most extreme penalty, alcohol increases risky driving (inverted u-shape) (bottom panel) \n",
    "<center><img src=\"img/6_CB/Risk_drive_alcohol.png\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2 (unsafe sex)\n",
    "\n",
    "Similar to driving, there seems to be an inverse-u shaped effect of alcohol in risky behavior\n",
    "\n",
    "<center><img src=\"img/6_CB/Risk_sex_preservatives.png\" width = \"500\" height = '500'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A hierarchical extension of the BART model\n",
    "  \n",
    "  \n",
    "$$ \\mu_{\\gamma^{+}} \\sim \\text{Uniform}(0,10) $$\n",
    "$$ \\sigma_{\\gamma^{+}} \\sim \\text{Uniform}(0,10) $$\n",
    "$$ \\mu_{\\beta} \\sim \\text{Uniform}(0,10) $$\n",
    "$$ \\sigma_{\\beta} \\sim \\text{Uniform}(0,10) $$\n",
    "$$ \\gamma^{+}_i \\sim \\text{Gaussian}(\\mu_{\\gamma^{+}}, 1/\\sigma_{\\gamma^{+}}^2) $$\n",
    "$$ \\beta_i \\sim \\text{Gaussian}(\\mu_{\\beta}, 1/\\sigma_{\\beta}^2) $$\n",
    "$$ \\omega_i = -\\gamma^{+}_i \\,/\\,\\text{log}(1-p) $$\n",
    "$$ \\theta_{ijk} = \\frac{1} {1+e^{\\beta_i(k-\\omega_i)}} $$\n",
    "$$ d_{ijk} \\sim \\text{Bernoulli}(\\theta_{ijk}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Discusión en clase\n",
    "¿Cómo cambiaría el modelo gráfico de abajo para hacerlo jerárquico y siga las formulas anteriores?\n",
    "<center><img src=\"img/6_CB/model_BART.svg\" width = \"451\" height = '450'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hierarchical means we assume a common source for the parameters risk and consistency. The common source is the subject (e.g. George). The parameters change according to the alcohol level conditions\n",
    "<center><img src=\"img/6_CB/model_BART_hierarchical.svg\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "p = 0.15  # (Belief of) bursting probability\n",
    "ntrials = 90  # Number of trials for the BART\n",
    "Ncond = 3\n",
    "extreme_npumps = 30 #some unlikely large number\n",
    "\n",
    "dall = np.full([Ncond, ntrials, extreme_npumps], np.nan)\n",
    "options = np.zeros((Ncond, ntrials))\n",
    "kall = np.full([Ncond, ntrials, extreme_npumps], np.nan)\n",
    "npumps_ = np.zeros((Ncond, ntrials))\n",
    "\n",
    "for icondi in range(Ncond):\n",
    "    if icondi == 0:\n",
    "        Data = pd.read_csv(\"data/6_CB/GeorgeSober.txt\", sep=\"\\t\")\n",
    "    elif icondi == 1:\n",
    "        Data = pd.read_csv(\"data/6_CB/GeorgeTipsy.txt\", sep=\"\\t\")\n",
    "    elif icondi == 2:\n",
    "        Data = pd.read_csv(\"data/6_CB/GeorgeDrunk.txt\", sep=\"\\t\")\n",
    "    # Data.head()\n",
    "    cash = np.asarray(Data[\"cash\"] != 0, dtype=int)\n",
    "    npumps = np.asarray(Data[\"pumps\"], dtype=int)\n",
    "    npumps_[icondi, :] = npumps\n",
    "    options[icondi, :] = cash + npumps\n",
    "    # response vector\n",
    "    for j, ipumps in enumerate(npumps):\n",
    "        inds = np.arange(options[icondi, j], dtype=int)\n",
    "        kall[icondi, j, inds] = inds + 1\n",
    "        if ipumps > 0:\n",
    "            dall[icondi, j, 0:ipumps] = 0\n",
    "        if cash[j] == 1:\n",
    "            dall[icondi, j, ipumps] = 1\n",
    "\n",
    "indexmask = np.isfinite(dall)\n",
    "dij = dall[indexmask]\n",
    "kij = kall[indexmask]\n",
    "condall = np.tile(np.arange(Ncond, dtype=int), (30, ntrials, 1))\n",
    "condall = np.swapaxes(condall, 0, 2)\n",
    "cij = condall[indexmask] #condition index (for dij and kij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "chains = 4\n",
    "with pm.Model() as model2:\n",
    "    #Hyperparameters for hierarchical priors\n",
    "    mu_g = pm.Uniform(\"mu_g\", lower=0, upper=10)\n",
    "    sigma_g = pm.Uniform(\"sigma_g\", lower=0, upper=10)\n",
    "    mu_b = pm.Uniform(\"mu_b\", lower=0, upper=10)\n",
    "    sigma_b = pm.Uniform(\"sigma_b\", lower=0, upper=10)\n",
    "    \n",
    "    #Priors (lower level)\n",
    "    gammap = pm.Normal(\"gammap\", mu=mu_g, sd=sigma_g, shape=Ncond)\n",
    "    beta = pm.Normal(\"beta\", mu=mu_b, sd=sigma_b, shape=Ncond)\n",
    "\n",
    "    #Likelihood\n",
    "    omega = -gammap[cij] / np.log(1 - p)\n",
    "    thetajk = 1 - pm.math.invlogit(-beta[cij] * (kij - omega))\n",
    "    \n",
    "    djk = pm.Bernoulli(\"djk\", p=thetajk, observed=dij)\n",
    "    \n",
    "    #get starting values with variational inference\n",
    "    approx = pm.fit(\n",
    "        n=100000, method=\"advi\", obj_optimizer=pm.adagrad_window\n",
    "    )  # type: pm.MeanField\n",
    "    start = approx.sample(draws=chains, include_transformed=True)\n",
    "    #sample\n",
    "    trace2 = pm.sample(\n",
    "         tune=2000, target_accept=0.95, chains=chains, \n",
    "        cores = 10, init=\"adapt_diag\", start=list(start)\n",
    "    )\n",
    "    data = az.from_pymc3(trace=trace2)\n",
    "\n",
    "\n",
    "\n",
    "az.plot_trace(data, var_names=[\"gammap\", \"beta\"], compact=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "gammaplus = trace2[\"gammap\"]\n",
    "beta = trace2[\"beta\"]\n",
    "ylabels = [\"Sober\", \"Tipsy\", \"Drunk\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "for ic in range(Ncond):\n",
    "    ax0 = axes[ic, 0]\n",
    "    ax0.hist(npumps_[ic], bins=range(1, 10), rwidth=0.8, align=\"left\")\n",
    "    ax0.set_xlabel(\"Number of Pumps\", fontsize=12)\n",
    "    ax0.set_ylabel(ylabels[ic], fontsize=12)\n",
    "\n",
    "    ax1 = axes[ic, 1]\n",
    "    my_pdf1 = st.kde.gaussian_kde(gammaplus[:, ic])\n",
    "    x1 = np.linspace(0.5, 1.8, 200)\n",
    "    ax1.plot(x1, my_pdf1(x1), \"k\", lw=2.5, alpha=0.6)  # distribution function\n",
    "    ax1.set_xlim((0.5, 1.8))\n",
    "    ax1.set_xlabel(r\"$\\gamma^+$\", fontsize=15)\n",
    "    ax1.set_ylabel(\"Posterior Density\", fontsize=12)\n",
    "\n",
    "    ax2 = axes[ic, 2]\n",
    "    my_pdf2 = st.kde.gaussian_kde(beta[:, ic])\n",
    "    x2 = np.linspace(0.1, 1.5, 200)\n",
    "    ax2.plot(x2, my_pdf2(x2), \"k\", lw=2.5, alpha=0.6)  # distribution function\n",
    "    ax2.set_xlim((0.1, 1.5))\n",
    "    ax2.set_xlabel(r\"$\\beta$\", fontsize=15)\n",
    "    ax2.set_ylabel(\"Posterior Density\", fontsize=12)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1) Apply the model to the data from the other subject, Bill. Does alcohol have the same effect on Bill as it did on George?\n",
    "\n",
    "2) Apply the non-hierarchical model to each of the six data files independently. Compare the results for the two parameters to those obtained from the hierarchical model, and explain any differences.\n",
    "\n",
    "3) The hierarchical model provides a structured relationship between the drinking conditions, but is still applied independently to each subject. Many of the applications of hierarchical modeling considered in our case studies, however, involve structured relationships between subjects, to capture individual differences. Develop a graphical model that extends the hierarchical model above to incorporate hierarchical structure both for drinking conditions and subjects. How could interactions between these two factors be modeled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's apply a BART model to the counterfactual paper by FitzGibbon, et al (2021, Psych. Science). \n",
    "\n",
    "Let's model their hypothesis/finding that seeking counterfactual information affects emotions and behavior:\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon9.png\" width = \"800\" height = '800'></center>\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon8.png\" width = \"800\" height = '800'></center>\n",
    "\n",
    "Discussion/exercise\n",
    "\n",
    "How would you extend the non-hierarchical BART diagram to measure FitzGibbon hypothesis/finding? What does behavior adjustment mean? Risk $\\gamma^+$ or consistency $\\beta$? Both? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fitzgibbon suggest changes in risk: \"The worse participants felt, the riskier they became on the next trial\" pp. 9. \n",
    "\n",
    "Let's focus on that possibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Diagram done  in https://app.diagrams.net/. We model change in emotion in trial t and number of pumps in the trial t + 1.\n",
    "\n",
    "$\\delta \\ lim$ is missed opportunity i.e. n_pumps - balloon limit. \n",
    "\n",
    "$\\delta \\ emo$ is change in emotion\n",
    "\n",
    "$\\zeta$ will tell us how much risk attitudes ($\\gamma^+$) change with changes in emotion.\n",
    "\n",
    "<center><img src=\"img/6_CB/model_BART_counterfactuals.svg\" width = \"800\" height = '800'></center>\n",
    "\n",
    "# Class exercise \n",
    "Expand the non-hierarchical pymc code to reflect this diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"data/6_CB/Counterfactual_Curiosity/E1.csv\")\n",
    "sID = Data['subject'].unique() \n",
    "for s in sID: #standardize emotion_change_rating by subject\n",
    "    idx = Data['subject'] == s\n",
    "    zscore = st.zscore(Data.loc[idx,'emotion_change_rating'])\n",
    "    Data.loc[idx,'emotion_change_rating'] = zscore\n",
    "s = 29 #subject to run or write 'all' for all subjects\n",
    "#representative subjects E1: \n",
    "#1,6,11,12,13,18,19,20,21,22,24,27 (negative slope emotion-risk on avg parameters), \n",
    "#2,3,4,5,7,14,17,23,25,26,28,29 (positive slope)\n",
    "# subject 27 E1 risk was highly affected by emotion according to the model\n",
    "if s == 'all':\n",
    "    idx = (Data['outcome'] == 'bank') &  (~Data['next_trial_n_pumps'].isna()) \n",
    "else:\n",
    "    idx = (Data['subject'] == sID[s]) & (Data['outcome'] == 'bank') &  (~Data['next_trial_n_pumps'].isna())\n",
    "Data = Data.loc[idx,:]\n",
    "print(Data.columns)\n",
    "#pump_value: how many points EACH pump gives\n",
    "#n_pumps: # of pumps participant asked the rabbit to do\n",
    "#limit: if n_pumps>limit then burst, else bank\n",
    "#information columns: if sought, participants saw the limit of the balloon\n",
    "#next_trial_points: pump_value_{trial+1}*n_pumps_{trial+1}\n",
    "Data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Non-hierarchical BART for FitzGibbon, et al, 2021 (see appendix for hierarchical version)\n",
    "p = 0.5\n",
    "npump_max = 12 #from the Fitzgibbon experimental design\n",
    "#emo_change_scale = [-200,200] #from the Fitzgibbon paper\n",
    "emo_change_scale = [-3,3] #standardized (zscore; see cell above)\n",
    "delta_emo_data = np.array(Data['emotion_change_rating'])\n",
    "info = np.array(Data['information_sought'])\n",
    "no_info = np.array(~np.array(Data['information_sought'], dtype = 'bool'), dtype = 'int')\n",
    "diff_limit = np.array(Data['diff_pumps_limit'])\n",
    "pump_value = np.array(Data['pump_value']) #including this does not make too much difference, it is uniform\n",
    "npumps_next_trial = np.array(Data['next_trial_n_pumps'])\n",
    "with pm.Model() as BART_CF:\n",
    "    #priors\n",
    "    kappas = pm.Uniform('kappas', \n",
    "                        lower = emo_change_scale[0], \n",
    "                        upper = emo_change_scale[1], shape = 4)\n",
    "    sigma_emo = pm.Uniform('sigma_emo', lower = 0 , upper = 50 )\n",
    "    maxgammap = pm.Uniform('maxgammap', lower = 0 , upper = 10)\n",
    "    zeta = pm.Uniform('zeta', lower = -1, upper = 1) #it worked with -1,1 \n",
    "    gammap = (maxgammap)/(1+tt.exp(-zeta*(delta_emo_data)))\n",
    "    #gammap = (maxgammap)/(1+tt.exp(-zeta*(delta_emo_data*pump_value)))\n",
    "    beta = pm.Normal(\"beta\", mu = 0.8, sd = 0.2) #Based on the previous BART\n",
    "    omega = pm.Deterministic(\"omega\", -gammap / np.log(1 - p))\n",
    "    \n",
    "    \n",
    "    #likelihood\n",
    "    mu_emo = (kappas[0] + kappas[1]*diff_limit)*no_info + (kappas[2] + kappas[3]*diff_limit)*info\n",
    "    delta_emoj = pm.Normal('delta_emo', mu = mu_emo, sigma = sigma_emo, \n",
    "                           observed = delta_emo_data)\n",
    "\n",
    "    \n",
    "    thetaj = 1 - pm.math.invlogit(-beta * (npumps_next_trial - omega)) \n",
    "    \n",
    "    dj = pm.Binomial(\"dj\", p=thetaj, n=npump_max, observed=npumps_next_trial)\n",
    "    \n",
    "    \n",
    "    trace = pm.sample(tune=2000, target_accept = 0.99, cores = 4, chains = 4)\n",
    "    \n",
    "    data = az.from_pymc3(trace=trace)\n",
    "    ppc = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(s)\n",
    "az.plot_trace(data, var_names=[\"maxgammap\", 'zeta', 'kappas', \"beta\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Posterior plots\n",
    "gammaplus = trace[\"maxgammap\"]\n",
    "beta = trace[\"beta\"]\n",
    "zeta = trace[\"zeta\"]\n",
    "kappas = trace[\"kappas\"]\n",
    "\n",
    "def myplot_cf(posterior, ax, xlim, xlab):\n",
    "    my_pdf1 = st.kde.gaussian_kde(posterior)\n",
    "    x1 = np.linspace(xlim[0], xlim[1], 1000)\n",
    "    ax.plot(x1, my_pdf1(x1), \"k\", lw=2.5, alpha=0.6)  # distribution function\n",
    "    ax.set_xlabel(xlab, fontsize=15)\n",
    "    ax.set_ylabel(\"Posterior Density\", fontsize=12)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "myplot_cf(gammaplus, axes[0,0], [7.8,8.5], r\"$Max_{\\gamma^+}$\")\n",
    "myplot_cf(beta, axes[0,1], [0.38,0.45], r\"$\\beta$\")\n",
    "myplot_cf(zeta, axes[0,2], [-.05,.05], r\"$\\zeta$\")\n",
    "myplot_cf(kappas[:,0], axes[0,3], [0.3,0.8], r\"$\\kappa_0$ (intercept no info)\")\n",
    "myplot_cf(kappas[:,1], axes[1,0], [-.08,.04], r\"$\\kappa_1$ (slope no info)\")\n",
    "myplot_cf(kappas[:,2], axes[1,1], [0.9,1.35], r\"$\\kappa_2$ (intercept info)\")\n",
    "myplot_cf(kappas[:,3], axes[1,2], [-0.35,-0.23], r\"$\\kappa_3$ (slope  info)\")\n",
    "\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior predictive checks\n",
    "#The model seems to qualitatively predict the data fairly well with some caveats.\n",
    "#The two peaks on observed delta_emo seem to be only on no info trials (see appendix, hierarchical)\n",
    "#Human subjects seem to overselect n pumps on the middle range (see dj observed)\n",
    "az.plot_ppc(az.from_pymc3(posterior_predictive=ppc, model=BART_CF));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model seems to qualitatively predict the data fairly well\n",
    "plt.figure(figsize=(5, 5)); \n",
    "idx = Data['information_sought']==1\n",
    "plt.plot(diff_limit[idx], delta_emo_data[idx], '.b',  label = 'Info')\n",
    "hdi_intercept = az.hdi(trace['kappas'][:,2]) #high density interval\n",
    "hdi_slope = az.hdi(trace['kappas'][:,3])\n",
    "x = np.linspace(-1,12)\n",
    "y = trace['kappas'][:,3].mean()*x + trace['kappas'][:,2].mean()\n",
    "plt.plot(x,y, color='blue')\n",
    "plt.fill_between(y1=hdi_slope[0]*x + hdi_intercept[0], \n",
    "                 y2= hdi_slope[1]*x + hdi_intercept[1],\n",
    "                 x=x, alpha=0.15, color='blue');\n",
    "plt.ylabel(\"Emotion-Change Rating\", fontsize=16); \n",
    "plt.xlabel(\"Missed Oppotunity\", fontsize=16);\n",
    "\n",
    "\n",
    "idx = Data['information_sought']==0\n",
    "plt.plot(diff_limit[idx], delta_emo_data[idx], '.r',  label = 'No info')\n",
    "hdi_intercept = az.hdi(trace['kappas'][:,0]) #high density interval\n",
    "hdi_slope = az.hdi(trace['kappas'][:,1])\n",
    "x = np.linspace(-1,12)\n",
    "y = trace['kappas'][:,1].mean()*x + trace['kappas'][:,0].mean()\n",
    "plt.plot(x,y, color='red')\n",
    "plt.fill_between(y1=hdi_slope[0]*x + hdi_intercept[0], \n",
    "                 y2= hdi_slope[1]*x + hdi_intercept[1],\n",
    "                 x=x, alpha=0.15, color='red');\n",
    "#plt.ylim(-250,250)\n",
    "plt.ylabel(\"Emotion-Change Rating\", fontsize=16); \n",
    "plt.xlabel(\"Missed Oppotunity\", fontsize=16);\n",
    "plt.legend(loc = 'upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On average parameters, risk attitudes change with \n",
    "# changes in emotion. But the effect size is tiny due to small zeta (see y scale).\n",
    "# The model suggests that risk attitudes don't change dramatically.\n",
    "# See appendix, for similar results with a hierarchical version (i.e. without logistics for gamma).\n",
    "# The hierarchical version didn't find dramatic consistency differences (beta).\n",
    "# In brief, either small changes in behavior explain FitzGibbon results, or\n",
    "# something else not accounted for in the model (e.g. a change in policy different than beta)\n",
    "# IMPORTANT: for all subjects in E1 including emotion change induced better waic and loo (see below). \n",
    "# i.e. is good to include it\n",
    "\n",
    "plt.figure(figsize=(5, 5)); \n",
    "emmmo_diff = np.linspace(-2,2,300)\n",
    "gammmma = gammaplus.mean()/(1+np.exp(-zeta.mean()*(emmmo_diff)))\n",
    "plt.plot(emmmo_diff,gammmma)\n",
    "plt.ylabel(\"$\\gamma^+$\", fontsize=16); \n",
    "plt.xlabel(\"Emotion-Change Rating\", fontsize=16);\n",
    "#plt.ylim(4.0850,4.0870)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Null model\n",
    "with pm.Model() as BART_CF_null:\n",
    "    #priors\n",
    "    kappas = pm.Uniform('kappas', \n",
    "                        lower = emo_change_scale[0], \n",
    "                        upper = emo_change_scale[1], shape = 4)\n",
    "    sigma_emo = pm.Uniform('sigma_emo', lower = 0 , upper = 50)\n",
    "    gammap = pm.Uniform('gammap', lower = 0 , upper = 10) \n",
    "    beta = pm.Normal(\"beta\", mu = 0.8, sd = 0.2) #Based on the previous BART\n",
    "    omega = pm.Deterministic(\"omega\", -gammap / np.log(1 - p))\n",
    "    \n",
    "    \n",
    "    #likelihood\n",
    "    mu_emo = (kappas[0] + kappas[1]*diff_limit)*no_info + (kappas[2] + kappas[3]*diff_limit)*info\n",
    "    delta_emoj = pm.Normal('delta_emo', mu = mu_emo, sigma = sigma_emo, \n",
    "                           observed = Data['emotion_change_rating'])\n",
    "    \n",
    "    thetaj = 1 - pm.math.invlogit(-beta * (npumps_next_trial - omega)) \n",
    "    \n",
    "    dj = pm.Binomial(\"dj\", p=thetaj, n=npump_max, observed=npumps_next_trial)\n",
    "\n",
    "    trace_null = pm.sample(tune=2000, target_accept = 0.99, cores=4, chains = 4)\n",
    "    data_null = az.from_pymc3(trace=trace_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(s)\n",
    "az.plot_trace(data_null, var_names=[\"gammap\", 'kappas', \"beta\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Model Comparison NOTE: run individual subjects for this cell (not enough ram).\n",
    "#https://discourse.pymc.io/t/calculating-waic-for-models-with-multiple-likelihood-functions/4834/5\n",
    "#The model comparison for individual subjects suggests that it is better to \n",
    "#include emotion as a modulator of risk (gamma)\n",
    "\n",
    "if s == 'all': #not enough ram!\n",
    "    print('OOOPS: due to ram limits, only individual subject models!!')    \n",
    "else:\n",
    "    data.sample_stats[\"log_likelihood\"] = data.log_likelihood['delta_emo'] + data.log_likelihood['dj']\n",
    "    data_null.sample_stats[\"log_likelihood\"] = data_null.log_likelihood['delta_emo'] + data_null.log_likelihood['dj']\n",
    "print(-2*az.waic(data)[0]) #lower values better\n",
    "print(-2*az.waic(data_null)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = az.waic(data)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "<center><img src=\"img/6_CB/FitzGibbon10.png\" width = \"250\" height = '250'></center>\n",
    "\n",
    "1) There were 5 experiments in Fitzgibbon et al, 2021 paper. We just run data of Exp. 1. Run the previous model and analyses on Exp. 2 data (counterfactual information cost money). Before starting, do you expect different results? After running the model, are the results similar? Different?\n",
    "\n",
    "2) How would you extend the base diagram to a hierarchical one for all 5 experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\" style = \"font-size: 70px\"> Prospect Theory </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Subjective value function prospect theory\n",
    "wAw = widgets.FloatSlider(min = 0, max = 1, step = 0.01, value=0.3,\n",
    "                        description = 'Alpha win')\n",
    "wAl = widgets.FloatSlider(min = 0, max = 1, step = 0.01, value=0.15,\n",
    "                        description = 'Alpha lose')\n",
    "wLA = widgets.FloatSlider(min = 0, max = 2, step = 0.01, value=2,\n",
    "                        description = 'Loss aversion')\n",
    "out = widgets.interactive_output(mf.slider_econ_beh_risk,\n",
    "                                 {'alpha_win': wAw,'alpha_lose': wAl, \n",
    "                                  'loss_aversion': wLA})\n",
    "left_widgets = VBox([wAw, wAl])\n",
    "right_widgets = VBox([wLA])\n",
    "top = HBox([left_widgets, right_widgets])\n",
    "VBox([top, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\" style = \"font-size: 70px\"> Percepción de probabilidades </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Weighting function prospect theory\n",
    "wT = widgets.FloatSlider(min = 0, max = 2, step = 0.01, value=0.5,\n",
    "                        description = 'Theta')\n",
    "out = widgets.interactive_output(mf.slider_econ_beh_prob, {'theta': wT})\n",
    "VBox([wT, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Algunos fenómenos psicológicos relacionados a probabilidades y riesgo\n",
    "* Optimismo (desmeritar riesgos negativos)\n",
    "* Gusto por el statu quo (decidir relativo a un referente)\n",
    "* Disponibilidad (prob. depende de recuerdos)\n",
    "* Hindsight (lo que ocurrió es lo probable)\n",
    "* Framing effects (la forma de presentar probabilidades importa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Los efectos se replican en varias poblaciones del mundo\n",
    "<center><img src=\"img/6_CB/Ruggeri1.svg\" width = \"700\" height = '700'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y prospect theory puede explicar alrededor del 90% de problemas DESCRITOS (problemas experimentados es otra historia)\n",
    "<center><img src=\"img/6_CB/Ruggeri2.svg\" width = \"700\" height = '700'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Medición de framing effects \n",
    "#### Situacion 1:\n",
    "Imagine que le damos 1000 dólares. Ya son suyos ¿Qué opción prefiere?\n",
    " * 50% de ganar 1000 más, 50% de ganar 0 más\n",
    " * 100% de certeza gana 500 más"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Situación 2:\n",
    "Imagine que le damos 2000 dólares. Ya son suyos ¿Qué opción prefiere?\n",
    " * 50% de perder 1000, 50% de perder 0 \n",
    " * 100% de certeza pierde 500 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Ejercicio en clase y en grupos:\n",
    "\n",
    "Expliqué Framing Effects con teoría de prospectos. Use las gráficas/formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=\"center\" style = \"font-size: 70px\"> Bayes y Prospect Theory </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"img/6_CB/Nilsson1.png\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Cuál prefiere?\n",
    "<center><img src=\"exp/6_CB/img/GP_0.png\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"exp/6_CB/img/GP_69.png\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"exp/6_CB/img/GP_138.png\" width = \"500\" height = '500'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hagamos el experimento en Psychopy (Notebooks_Slides/exp/6_CB/CPT.psyexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Intro:\n",
    "* Un acercamiento no bayesiano, como MLE, necesita muchas observaciones por individuo.\n",
    "* Un acercamiento no jerárquico asume que los individuos son independientes. Sin embargo, los humanos compartimos sesgos.\n",
    "* MLE obtiene estimativos puntuales. Con Bayes obtenemos toda la distribución. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Formulas de prospect theory\n",
    "\n",
    "Valor:\n",
    "\n",
    "$$\n",
    "v(x) = \\left\\{\n",
    "\\begin{aligned}\n",
    "    x^\\alpha \\; \\;\\; \\; &\\text{if} \\;\\; x\\ge 0 \\\\\n",
    "   -\\lambda(-x^\\beta)\\; \\;\\; \\; & \\text{if} \\;\\;  x< 0\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "<center><img src=\"img/6_CB/PT_val.svg\" width = \"250\" height = '250'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Probabilidades:\n",
    "$$ w(p_x) = \\frac{p_x^c}{(p_x^c - (1-p_x^c))^{1/c}}$$\n",
    "\n",
    "$$c = \\gamma \\text{ if gain, } c = \\delta \\text{ if loss}$$\n",
    "\n",
    "<center><img src=\"img/6_CB/PT_weight.svg\" width = \"250\" height = '250'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Valor Esperado\n",
    "$$V(x) = v(x)w(p_x)$$\n",
    "\n",
    "Decisión estocástica\n",
    "$$ p(A) = \\frac{1}{1+e^{\\phi(V(B)-V(A))}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ejercicio en clase y en grupos:\n",
    "\n",
    "1. Ponga las formulas de prospect theory en un DAG (directed acyclical graph). Haga el DAG en papel y lapiz. Más abajo está una versión jerárquica pero no lo use. Este punto todo el mundo lo va a tener bien. El objetivo es que piense cómo expresar formulas en un DAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/6_CB/model_CPT.svg\" width = \"601\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nilsson et al encontraron que los indices de aversión al riesgo ($\\alpha$, $\\beta$) podían dejarse iguales para poder estimar aversión a las perdidas (más detalles en el paper de ellos). Vamos a estimar ese modelo restringido.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<center><img src=\"img/6_CB/Nilsson_Table1.svg\" width = \"901\" height = '900'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 10 (180, 10)\n"
     ]
    }
   ],
   "source": [
    "#REAL DATA. Load data and exp. info.\n",
    "gambles_A = pd.read_table(\"data/6_CB/GambleA.txt\", header=None)\n",
    "gambles_A.columns = ['Reward_1', 'Prob_1', 'Reward_2', 'Prob_2']\n",
    "gambles_A_win = gambles_A.loc[0:59,:].copy()\n",
    "gambles_A_loss = gambles_A.loc[60:119,:].copy()\n",
    "gambles_A_mix = gambles_A.loc[120:179,:].copy()\n",
    "gambles_B = pd.read_table(\"data/6_CB/GambleB.txt\", header=None)\n",
    "gambles_B.columns = ['Reward_1', 'Prob_1', 'Reward_2', 'Prob_2']\n",
    "gambles_B_win = gambles_B.loc[0:59,:].copy()\n",
    "gambles_B_loss = gambles_B.loc[60:119,:].copy()\n",
    "gambles_B_mix = gambles_B.loc[120:179,:].copy()\n",
    "Rieskamp_data = pd.read_table('data/6_CB/Rieskamp_data.txt', header=None) \n",
    "# 0: choice gamble A\n",
    "# 1: choice gamble B\n",
    "nsubjs_to_include = 10\n",
    "subjs_to_include = np.random.choice(a = Rieskamp_data.shape[1], \n",
    "                                    size = nsubjs_to_include, replace = False) #to improve speed of sampling during class hour\n",
    "Rieskamp_data = Rieskamp_data.iloc[:,subjs_to_include]\n",
    "Rieskamp_data_win = Rieskamp_data.loc[0:59,:].copy()\n",
    "Rieskamp_data_loss = Rieskamp_data.loc[60:119,:].copy()\n",
    "Rieskamp_data_mix = Rieskamp_data.loc[120:179,:].copy()\n",
    "ntrials = Rieskamp_data.shape[0]\n",
    "ntrials_by_type = int(ntrials/3)\n",
    "nsubj = Rieskamp_data.shape[1]\n",
    "print(ntrials, nsubj, Rieskamp_data.shape)\n",
    "#Rieskamp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#SIMULATED DATA\n",
    "\n",
    "#CPT parameters\n",
    "alpha_sim = 0.88\n",
    "beta_sim = 0.88\n",
    "gamma_sim = 0.61\n",
    "delta_sim = 0.69\n",
    "lambda_sim = 2.25  \n",
    "luce_sim = 0.14 #0.04: high choice noise; 0.14: medium; 0.4: low \n",
    "\n",
    "#WIN TRIALS\n",
    "#Gamble A\n",
    "v = mf.value_fun(gambles_A_win[['Reward_1','Reward_2']], \n",
    "                 alpha_sim, beta_sim, lambda_sim)\n",
    "w = mf.weight_fun(gambles_A_win[['Reward_1','Reward_2']],\n",
    "                  gambles_A_win[['Prob_1','Prob_2']],\n",
    "                  gamma_sim, delta_sim)\n",
    "EV_A = mf.EV(v, w)\n",
    "\n",
    "#Gamble B\n",
    "v = mf.value_fun(gambles_B_win[['Reward_1','Reward_2']], \n",
    "                 alpha_sim, beta_sim, lambda_sim)\n",
    "w = mf.weight_fun(gambles_B_win[['Reward_1','Reward_2']],\n",
    "                  gambles_B_win[['Prob_1','Prob_2']],\n",
    "                  gamma_sim, delta_sim)\n",
    "EV_B = mf.EV(v, w)\n",
    "\n",
    "#Choice\n",
    "EV_both = pd.DataFrame(np.array([EV_A, EV_B]).transpose())\n",
    "choice_prob = np.tile(mf.choice_rule(EV_both,luce_sim),[nsubj,1]).transpose()\n",
    "choice_win = np.random.binomial(1,choice_prob).astype(int)\n",
    "\n",
    "\n",
    "#LOSS TRIALS\n",
    "#Gamble A\n",
    "v = mf.value_fun(gambles_A_loss[['Reward_1','Reward_2']], \n",
    "                 alpha_sim, beta_sim, lambda_sim)\n",
    "w = mf.weight_fun(gambles_A_loss[['Reward_1','Reward_2']],\n",
    "                  gambles_A_loss[['Prob_1','Prob_2']],\n",
    "                  gamma_sim, delta_sim)\n",
    "EV_A = mf.EV(v, w)\n",
    "\n",
    "#Gamble B\n",
    "v = mf.value_fun(gambles_B_loss[['Reward_1','Reward_2']], \n",
    "                 alpha_sim, beta_sim, lambda_sim)\n",
    "w = mf.weight_fun(gambles_B_loss[['Reward_1','Reward_2']],\n",
    "                  gambles_B_loss[['Prob_1','Prob_2']],\n",
    "                  gamma_sim, delta_sim)\n",
    "EV_B = mf.EV(v, w)\n",
    "\n",
    "#Choice\n",
    "EV_both = pd.DataFrame(np.array([EV_A, EV_B]).transpose())\n",
    "choice_prob = np.tile(mf.choice_rule(EV_both,luce_sim),[nsubj,1]).transpose()\n",
    "choice_loss = np.random.binomial(1,choice_prob).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#MIX TRIALS\n",
    "#Gamble A\n",
    "v = mf.value_fun(gambles_A_mix[['Reward_1','Reward_2']], \n",
    "                 alpha_sim, beta_sim, lambda_sim)\n",
    "w = mf.weight_fun(gambles_A_mix[['Reward_1','Reward_2']],\n",
    "                  gambles_A_mix[['Prob_1','Prob_2']],\n",
    "                  gamma_sim, delta_sim)\n",
    "EV_A = mf.EV(v, w)\n",
    "\n",
    "#Gamble B\n",
    "v = mf.value_fun(gambles_B_mix[['Reward_1','Reward_2']], \n",
    "                 alpha_sim, beta_sim, lambda_sim)\n",
    "w = mf.weight_fun(gambles_B_mix[['Reward_1','Reward_2']],\n",
    "                  gambles_B_mix[['Prob_1','Prob_2']],\n",
    "                  gamma_sim, delta_sim)\n",
    "EV_B = mf.EV(v, w)\n",
    "\n",
    "#Choice\n",
    "EV_both = pd.DataFrame(np.array([EV_A, EV_B]).transpose())\n",
    "choice_prob = np.tile(mf.choice_rule(EV_both,luce_sim),[nsubj,1]).transpose()\n",
    "choice_mix = np.random.binomial(1,choice_prob).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.opt): Optimization Warning: The Op erfcx does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n",
      "<ipython-input-4-bf9f4452568d>:241: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(1000, tune = 1500, init='adapt_diag', target_accept = 0.95)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [luce_N, lambda_N, delta_N, gamma_N, alpha_N, sigma_l_luce_N, mu_l_luce_N, sigma_l_lambda_N, mu_l_lambda_N, sigma_delta_N, mu_delta_N, sigma_gamma_N, mu_gamma_N, sigma_alpha_N, mu_alpha_N]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10000/10000 15:51<00:00 Sampling 4 chains, 425 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_500 tune and 1_000 draw iterations (6_000 + 4_000 draws total) took 954 seconds.\n",
      "There were 182 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8258068156882243, but should be close to 0.95. Try to increase the number of tuning steps.\n",
      "There were 12 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 95 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8771942654011975, but should be close to 0.95. Try to increase the number of tuning steps.\n",
      "There were 136 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8471710584242788, but should be close to 0.95. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "#PyMC model\n",
    "def norm_cdf(x, mean=0, std=1):\n",
    "    return (1.0 + tt.erf((x-mean) / tt.sqrt(2.0*(std**2)))) / 2.0 #cdf; (x is a normal sample)\n",
    "    #return tt.sqrt(2)*tt.erfinv(2x-1) #Probit: inv. cdf standard norm (x is a prob.).   \n",
    "\n",
    "with pm.Model() as CPT:  \n",
    "    # Here priors for the hyperdistributions are defined:\n",
    "    ### alpha (risk attitude win)\n",
    "    mu_alpha_N = pm.Normal('mu_alpha_N', 0, 1)\n",
    "    sigma_alpha_N = pm.Uniform('sigma_alpha_N', 0, 5)\n",
    "    ### beta (risk attitude lose)\n",
    "    #mu_beta_N = pm.Normal('mu_beta_N', 0, 1)\n",
    "    #sigma_beta_N = pm.Uniform('sigma_beta_N', 0, 5)\n",
    "    ### gamma (non-linearity in prob. win)\n",
    "    mu_gamma_N = pm.Normal('mu_gamma_N', 0, 1)\n",
    "    sigma_gamma_N = pm.Uniform('sigma_gamma_N', 0, 5)\n",
    "    ### delta (non-linearity in prob. lose)\n",
    "    mu_delta_N = pm.Normal('mu_delta_N', 0, 1)\n",
    "    sigma_delta_N = pm.Uniform('sigma_delta_N', 0, 5)\n",
    "    ### lambda (loss aversion)\n",
    "    mu_l_lambda_N = pm.Uniform('mu_l_lambda_N', -2.3, 1.61)\n",
    "    sigma_l_lambda_N = pm.Uniform('sigma_l_lambda_N', 0, 1.13)\n",
    "    ### luce (temperature of softmax)\n",
    "    mu_l_luce_N = pm.Uniform('mu_l_luce_N', -2.3, 1.61)\n",
    "    sigma_l_luce_N = pm.Uniform('sigma_l_luce_N', 0, 1.13)\n",
    "    \n",
    "    ## We put group-level normal's on the individual parameters.\n",
    "    ## This models alpha, beta, gamma, and delta as probitized parameters. \n",
    "    ## That is, it models parameters on the probit scale and then \n",
    "    ## puts them back to the range 0-1 with the CDF.\n",
    "    ## Lambda and luce are positive and modeled in log scale.\n",
    "    ## Each participant has unique parameter-values: \n",
    "    ## alpha, beta, gamma, delta, lambda, and luce\n",
    "    alpha_N = pm.TruncatedNormal('alpha_N', mu_alpha_N, sigma_alpha_N,\n",
    "                                 lower = -3, upper = 3,\n",
    "                                 shape = nsubj)\n",
    "    #beta_N = pm.TruncatedNormal('beta_N', mu_beta_N, sigma_beta_N,\n",
    "    #                            lower = -3, upper = 3,\n",
    "    #                            shape = nsubj)\n",
    "    gamma_N = pm.TruncatedNormal('gamma_N', mu_gamma_N, sigma_gamma_N,\n",
    "                                 lower = -3, upper = 3,\n",
    "                                 shape = nsubj)\n",
    "    delta_N = pm.TruncatedNormal('delta_N', mu_delta_N, sigma_delta_N,\n",
    "                                 lower = -3, upper = 3,\n",
    "                                 shape = nsubj)\n",
    "    lambda_N = pm.Normal('lambda_N', mu_l_lambda_N, sigma_l_lambda_N,\n",
    "                        shape = nsubj)\n",
    "    luce_N = pm.Normal('luce_N', mu_l_luce_N, sigma_l_luce_N,\n",
    "                       shape = nsubj)\n",
    "    \n",
    "    ### Put everything in the desired scale\n",
    "    ## We use cdf to bound some parameters to be in 0-1\n",
    "    alpha = pm.Deterministic('alpha', norm_cdf(alpha_N))\n",
    "    #beta = pm.Deterministic('beta', norm_cdf(beta_N))\n",
    "    beta = pm.Deterministic('beta', alpha)\n",
    "    gamma = pm.Deterministic('gamma', norm_cdf(gamma_N))\n",
    "    delta = pm.Deterministic('delta', norm_cdf(delta_N))\n",
    "    ## We exp because we assume a log. scale\n",
    "    lambd = pm.Deterministic('lambbda', tt.exp(lambda_N))\n",
    "    luce = pm.Deterministic('luce', tt.exp(luce_N))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # It is now time to define how the model should be fit to data.\n",
    "    ############ WIN TRIALS ############\n",
    "    gambless_A = gambles_A_win\n",
    "    gambless_B = gambles_B_win\n",
    "    ##GAMBLE A\n",
    "    ## subjective value of outcomes x & y in gamble A\n",
    "    reward_1 = np.tile(np.array(gambless_A['Reward_1']),(nsubj,1)).transpose()\n",
    "    reward_2 = np.tile(np.array(gambless_A['Reward_2']),(nsubj,1)).transpose()\n",
    "    v_x_a = pm.Deterministic('v_x_a', reward_1**tt.tile(alpha,(ntrials_by_type,1)))\n",
    "    v_y_a = pm.Deterministic('v_y_a', reward_2**tt.tile(alpha,(ntrials_by_type,1)))\n",
    "    \n",
    "    ## subjective prob. of outcomes x & y in gamble A\n",
    "    prob_1 = np.tile(np.array(gambless_A['Prob_1']),(nsubj,1)).transpose()\n",
    "    prob_2 = np.tile(np.array(gambless_A['Prob_2']),(nsubj,1)).transpose()\n",
    "    z_a = pm.Deterministic('z_a', prob_1**tt.tile(gamma,(ntrials_by_type,1)) + prob_2**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    den_a = pm.Deterministic('den_a', z_a**(1/tt.tile(gamma,(ntrials_by_type,1))))\n",
    "    num_x_a = pm.Deterministic('num_x_a', prob_1**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    w_x_a =  pm.Deterministic('w_x_a', num_x_a / den_a)  \n",
    "    num_y_a = pm.Deterministic('num_y_a', prob_2**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    w_y_a =  pm.Deterministic('w_y_a', num_y_a / den_a) \n",
    "       \n",
    "    ##subjective value of gamble A\n",
    "    Vf_a = pm.Deterministic('Vf_a', w_x_a * v_x_a + w_y_a * v_y_a)\n",
    "   \n",
    "\n",
    "    #GAMBLE B\n",
    "    ## subjective value of outcomes x & y in gamble B\n",
    "    reward_1 = np.tile(np.array(gambless_B['Reward_1']),(nsubj,1)).transpose()\n",
    "    reward_2 = np.tile(np.array(gambless_B['Reward_2']),(nsubj,1)).transpose()\n",
    "    v_x_b = pm.Deterministic('v_x_b', reward_1**tt.tile(alpha,(ntrials_by_type,1)))\n",
    "    v_y_b = pm.Deterministic('v_y_b', reward_2**tt.tile(alpha,(ntrials_by_type,1)))\n",
    "    \n",
    "    ## subjective prob. of outcomes x & y in gamble B\n",
    "    prob_1 = np.tile(np.array(gambless_B['Prob_1']),(nsubj,1)).transpose()\n",
    "    prob_2 = np.tile(np.array(gambless_B['Prob_2']),(nsubj,1)).transpose()\n",
    "    z_b = pm.Deterministic('z_b', prob_1**tt.tile(gamma,(ntrials_by_type,1)) + prob_2**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    den_b = pm.Deterministic('den_b', z_b**(1/tt.tile(gamma,(ntrials_by_type,1))))\n",
    "    num_x_b = pm.Deterministic('num_x_b', prob_1**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    w_x_b =  pm.Deterministic('w_x_b', num_x_b / den_b)  \n",
    "    num_y_b = pm.Deterministic('num_y_b', prob_2**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    w_y_b =  pm.Deterministic('w_y_b', num_y_b / den_b)   \n",
    "    \n",
    "    ##subjective value of gamble B\n",
    "    Vf_b = pm.Deterministic('Vf_b', w_x_b * v_x_b + w_y_b * v_y_b)\n",
    "    \n",
    "    ## Difference in value\n",
    "    #print(den)\n",
    "    dv = pm.Deterministic('D', (Vf_a - Vf_b))\n",
    "    ##LIKELIHOOD \n",
    "    ## choice for gamble-pair is a Bernoulli-distribution \n",
    "    ## with p = binval \n",
    "    ## binval is luce's choice rule (akin to a softmax) \n",
    "    binval = pm.Deterministic('binval', 1/(1+tt.exp((tt.tile(luce,(ntrials_by_type,1))) * (dv)))) #prob. of B\n",
    "    datta = pm.Data(\"data_win\", np.array(choice_win)) \n",
    "    win_obs = pm.Bernoulli('win_obs', p = binval, observed = datta)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############ LOSS TRIALS ############\n",
    "    gambless_A = gambles_A_loss\n",
    "    gambless_B = gambles_B_loss\n",
    "    ##GAMBLE A\n",
    "    ## subjective value of outcomes x & y in gamble A\n",
    "    reward_1 = np.tile(np.array(gambless_A['Reward_1']),(nsubj,1)).transpose()\n",
    "    reward_2 = np.tile(np.array(gambless_A['Reward_2']),(nsubj,1)).transpose()\n",
    "    v_x_a_l = pm.Deterministic('v_x_a_l', (-1)*((-reward_1)**tt.tile(beta,(ntrials_by_type,1))))\n",
    "    v_y_a_l = pm.Deterministic('v_y_a_l', (-1)*((-reward_2)**tt.tile(beta,(ntrials_by_type,1))))\n",
    "\n",
    "    ## subjective prob. of outcomes x & y in gamble A\n",
    "    prob_1 = np.tile(np.array(gambless_A['Prob_1']),(nsubj,1)).transpose()\n",
    "    prob_2 = np.tile(np.array(gambless_A['Prob_2']),(nsubj,1)).transpose()\n",
    "    z_a_l = pm.Deterministic('z_a_l', prob_1**tt.tile(delta,(ntrials_by_type,1)) + prob_2**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    den_a_l = pm.Deterministic('den_a_l', z_a_l**(1/tt.tile(delta,(ntrials_by_type,1))))\n",
    "    num_x_a_l = pm.Deterministic('num_x_a_l', prob_1**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    w_x_a_l =  pm.Deterministic('w_x_a_l', num_x_a_l / den_a_l)  \n",
    "    num_y_a_l = pm.Deterministic('num_y_a_l', prob_2**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    w_y_a_l =  pm.Deterministic('w_y_a_l', num_y_a_l / den_a_l) \n",
    "    \n",
    "    ##subjective value of gamble A\n",
    "    Vf_a_l = pm.Deterministic('Vf_a_l', w_x_a_l * v_x_a_l + w_y_a_l * v_y_a_l)\n",
    "    \n",
    "    \n",
    "    #GAMBLE B\n",
    "    ## subjective value of outcomes x & y in gamble B\n",
    "    reward_1 = np.tile(np.array(gambless_B['Reward_1']),(nsubj,1)).transpose()\n",
    "    reward_2 = np.tile(np.array(gambless_B['Reward_2']),(nsubj,1)).transpose()\n",
    "    v_x_b_l = pm.Deterministic('v_x_b_l', (-1)*((-reward_1)**tt.tile(beta,(ntrials_by_type,1))))\n",
    "    v_y_b_l = pm.Deterministic('v_y_b_l', (-1)*((-reward_2)**tt.tile(beta,(ntrials_by_type,1))))\n",
    "    \n",
    "    ## subjective prob. of outcomes x & y in gamble B\n",
    "    prob_1 = np.tile(np.array(gambless_B['Prob_1']),(nsubj,1)).transpose()\n",
    "    prob_2 = np.tile(np.array(gambless_B['Prob_2']),(nsubj,1)).transpose()\n",
    "    z_b_l = pm.Deterministic('z_b_l', prob_1**tt.tile(delta,(ntrials_by_type,1)) + prob_2**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    den_b_l = pm.Deterministic('den_b_l', z_b_l**(1/tt.tile(delta, (ntrials_by_type,1))))\n",
    "    num_x_b_l = pm.Deterministic('num_x_b_l', prob_1**tt.tile(delta, (ntrials_by_type,1)))\n",
    "    w_x_b_l =  pm.Deterministic('w_x_b_l', num_x_b_l / den_b_l)  \n",
    "    num_y_b_l = pm.Deterministic('num_y_b_l', prob_2**tt.tile(delta, (ntrials_by_type,1)))\n",
    "    w_y_b_l =  pm.Deterministic('w_y_b_l', num_y_b_l / den_b_l)   \n",
    "\n",
    "    ##subjective value of gamble B\n",
    "    Vf_b_l = pm.Deterministic('Vf_b_l', w_x_b_l * v_x_b_l + w_y_b_l * v_y_b_l)\n",
    "    \n",
    "    ## Difference in value\n",
    "    #print(den)\n",
    "    dv_l = pm.Deterministic('D_l', (Vf_a_l - Vf_b_l))\n",
    "    ##likelihood \n",
    "    ## choice for gamble-pair is a Bernoulli-distribution \n",
    "    ## with p = binval \n",
    "    ## binval is luce's choice rule (akin to a softmax) \n",
    "    binval_l = pm.Deterministic('binval_l', 1/(1+tt.exp((tt.tile(luce,(ntrials_by_type,1))) * (dv_l)))) #prob. of B\n",
    "    datta_l = pm.Data(\"data_loss\", np.array(choice_loss))\n",
    "    loss_obs = pm.Bernoulli('loss_obs', p = binval_l, observed = datta_l)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############ MIX TRIALS ############\n",
    "    gambless_A = gambles_A_mix\n",
    "    gambless_B = gambles_B_mix\n",
    "    ##GAMBLE A\n",
    "    ## subjective value of outcomes x & y in gamble A\n",
    "    reward_1 = np.tile(np.array(gambless_A['Reward_1']),(nsubj,1)).transpose()\n",
    "    reward_2 = np.tile(np.array(gambless_A['Reward_2']),(nsubj,1)).transpose()\n",
    "    v_x_a_m = pm.Deterministic('v_x_a_m', reward_1**tt.tile(alpha,(ntrials_by_type,1)))\n",
    "    v_y_a_m = pm.Deterministic('v_y_a_m', (-1*tt.tile(lambd,(ntrials_by_type,1)))*((-reward_2)**tt.tile(beta,(ntrials_by_type,1))))\n",
    "\n",
    "    ## subjective prob. of outcomes x & y in gamble A\n",
    "    prob_1 = np.tile(np.array(gambless_A['Prob_1']),(nsubj,1)).transpose()\n",
    "    prob_2 = np.tile(np.array(gambless_A['Prob_2']),(nsubj,1)).transpose()\n",
    "    z_a_m = pm.Deterministic('z_a_m', prob_1**tt.tile(gamma,(ntrials_by_type,1)) + prob_2**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    den_a1_m = pm.Deterministic('den_a1_m', z_a_m**(1/tt.tile(gamma,(ntrials_by_type,1))))\n",
    "    den_a2_m = pm.Deterministic('den_a2_m', z_a_m**(1/tt.tile(delta,(ntrials_by_type,1))))\n",
    "    num_x_a_m = pm.Deterministic('num_x_a_m', prob_1**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    w_x_a_m =  pm.Deterministic('w_x_a_m', num_x_a_m / den_a1_m)  \n",
    "    num_y_a_m = pm.Deterministic('num_y_a_m', prob_2**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    w_y_a_m =  pm.Deterministic('w_y_a_m', num_y_a_m / den_a2_m) \n",
    "    \n",
    "    ##subjective value of gamble A\n",
    "    Vf_a_m = pm.Deterministic('Vf_a_m', w_x_a_m * v_x_a_m + w_y_a_m * v_y_a_m)\n",
    "    \n",
    "    \n",
    "    ##GAMBLE B\n",
    "    ## subjective value of outcomes x & y in gamble B\n",
    "    reward_1 = np.tile(np.array(gambless_B['Reward_1']),(nsubj,1)).transpose()\n",
    "    reward_2 = np.tile(np.array(gambless_B['Reward_2']),(nsubj,1)).transpose()\n",
    "    v_x_b_m = pm.Deterministic('v_x_b_m', reward_1**tt.tile(alpha,(ntrials_by_type,1)))\n",
    "    v_y_b_m = pm.Deterministic('v_y_b_m', (-1*tt.tile(lambd,(ntrials_by_type,1)))*((-reward_2)**tt.tile(beta,(ntrials_by_type,1))))\n",
    "\n",
    "    ## subjective prob. of outcomes x & y in gamble B\n",
    "    prob_1 = np.tile(np.array(gambless_B['Prob_1']),(nsubj,1)).transpose()\n",
    "    prob_2 = np.tile(np.array(gambless_B['Prob_2']),(nsubj,1)).transpose()\n",
    "    z_b_m = pm.Deterministic('z_b_m', prob_1**tt.tile(gamma,(ntrials_by_type,1)) + prob_2**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    den_b1_m = pm.Deterministic('den_b1_m', z_b_m**(1/tt.tile(gamma,(ntrials_by_type,1))))\n",
    "    den_b2_m = pm.Deterministic('den_b2_m', z_b_m**(1/tt.tile(delta,(ntrials_by_type,1))))\n",
    "    num_x_b_m = pm.Deterministic('num_x_b_m', prob_1**tt.tile(gamma,(ntrials_by_type,1)))\n",
    "    w_x_b_m =  pm.Deterministic('w_x_b_m', num_x_b_m / den_b1_m)  \n",
    "    num_y_b_m = pm.Deterministic('num_y_b_m', prob_2**tt.tile(delta,(ntrials_by_type,1)))\n",
    "    w_y_b_m =  pm.Deterministic('w_y_b_m', num_y_b_m / den_b2_m) \n",
    "    \n",
    "    ##subjective value of gamble B\n",
    "    Vf_b_m = pm.Deterministic('Vf_b_m', w_x_b_m * v_x_b_m + w_y_b_m * v_y_b_m)\n",
    "    \n",
    "        \n",
    "    ## Difference in value\n",
    "    #print(den)\n",
    "    dv_m = pm.Deterministic('D_m', (Vf_a_m - Vf_b_m))\n",
    "    ##likelihood \n",
    "    ## choice for gamble-pair is a Bernoulli-distribution \n",
    "    ## with p = binval \n",
    "    ## binval is luce's choice rule (akin to a softmax) \n",
    "    binval_m = pm.Deterministic('binval_m', 1/(1+tt.exp((tt.tile(luce,(ntrials_by_type,1))) * (dv_m)))) #prob. of B\n",
    "    datta_m = pm.Data(\"data_mix\", np.array(choice_mix))\n",
    "    mix_obs = pm.Bernoulli('mix_obs', p = binval_m, observed = datta_m)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############  Sampling  ##############\n",
    "    trace = pm.sample(1000, tune = 1500, init='adapt_diag', target_accept = 0.95)\n",
    "    #step = pm.Metropolis()\n",
    "    #trace = pm.sample(50000, tune = 5000, step=step)\n",
    "    rhat = pm.rhat(trace, var_names = ['alpha', 'beta', 'gamma', 'delta', 'lambbda', 'luce'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'alpha' ()>\n",
      "array(1.02934998)\n",
      "<xarray.DataArray 'beta' ()>\n",
      "array(1.02934998)\n",
      "<xarray.DataArray 'gamma' ()>\n",
      "array(1.03022537)\n",
      "<xarray.DataArray 'delta' ()>\n",
      "array(1.02026507)\n",
      "<xarray.DataArray 'lambbda' ()>\n",
      "array(1.01714461)\n",
      "<xarray.DataArray 'luce' ()>\n",
      "array(1.02550262)\n",
      "mu_alpha_N -0.9189385332046727\n",
      "sigma_alpha_N_interval__ -1.3862943611198906\n",
      "mu_gamma_N -0.9189385332046727\n",
      "sigma_gamma_N_interval__ -1.3862943611198906\n",
      "mu_delta_N -0.9189385332046727\n",
      "sigma_delta_N_interval__ -1.3862943611198906\n",
      "mu_l_lambda_N_interval__ -1.3862943611198906\n",
      "sigma_l_lambda_N_interval__ -1.3862943611198906\n",
      "mu_l_luce_N_interval__ -1.3862943611198906\n",
      "sigma_l_luce_N_interval__ -1.3862943611198906\n",
      "alpha_N_interval__ -11.6821839978396\n",
      "gamma_N_interval__ -11.6821839978396\n",
      "delta_N_interval__ -11.6821839978396\n",
      "lambda_N -3.4800898536897638\n",
      "luce_N -3.4800898536897638\n",
      "win_obs -369.3661664274043\n",
      "loss_obs -344.06678864918297\n",
      "mix_obs -381.7723276811668\n"
     ]
    }
   ],
   "source": [
    "# Revisar convergencia. \n",
    "# Rhat <1.1 usualmente son aceptados como convergencia\n",
    "print(rhat.alpha[0:nsubj].mean())\n",
    "print(rhat.beta[0:nsubj].mean())\n",
    "print(rhat.gamma[0:nsubj].mean())\n",
    "print(rhat.delta[0:nsubj].mean())\n",
    "print(rhat.lambbda[0:nsubj].mean())\n",
    "print(rhat.luce[0:nsubj].mean())\n",
    "for RV in CPT.basic_RVs: #None should be inf or -inf\n",
    "    print(RV.name, RV.logp(CPT.test_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e7e771b7fa4a34993ef9a28bff98d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Param.: ', index=16, options=(('mu_alpha_N', 'mu_alpha_N'), ('sigma_alpha…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizaciones de convergencia\n",
    "pars = [('mu_alpha_N','mu_alpha_N'), ('sigma_alpha_N','sigma_alpha_N'), \n",
    "        #('mu_beta_N','mu_beta_N'),('sigma_beta_N','sigma_beta_N'), \n",
    "        ('mu_gamma_N','mu_gamma_N'), ('sigma_gamma_N','sigma_gamma_N'),\n",
    "        ('mu_delta_N','mu_delta_N'), ('sigma_delta_N','sigma_delta_N'), \n",
    "        ('mu_l_lambda_N','mu_l_lambda_N'),('sigma_l_lambda_N','sigma_l_lambda_N'), \n",
    "        ('mu_l_luce_N','mu_l_luce_N'), ('sigma_l_luce_N','sigma_l_luce_N'),\n",
    "       ('alpha_N','alpha_N'), ('beta_N','beta_N'), ('gamma_N','gamma_N'),\n",
    "        ('delta_N','delta_N'), ('lambda_N','lambda_N'), ('luce_N','luce_N'), \n",
    "        ('alpha','alpha'), ('beta','beta'),\n",
    "        ('gamma','gamma'), ('delta','delta'), \n",
    "        ('lambda','lambbda'), ('luce','luce')]\n",
    "wD = widgets.Dropdown(options=pars,\n",
    "                        value='alpha', description='Param.: ')\n",
    "out = widgets.interactive_output(mf.dropdown_convergence,{'param': wD, \n",
    "                                                       'trace': fixed(trace)})\n",
    "VBox([wD, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alpha', 0.9174402045389507, 0.005839885915431857, 0.88]\n",
      "['beta', 0.9174402045389507, 0.005839885915431857, 0.88]\n",
      "['gamma', 0.5455698248546599, 0.06750913421490919, 0.61]\n",
      "['delta', 0.8287657131932488, 0.012413641632317255, 0.69]\n",
      "['lambbda', 1.9572746699057362, 0.13199325930147876, 2.25]\n",
      "['luce', 0.1473973082409109, 0.009781007251952849, 0.14]\n"
     ]
    }
   ],
   "source": [
    "print(['alpha',np.median(np.median(trace['alpha'], axis = 0)),\n",
    "       np.median(trace['alpha'], axis = 0).std(), alpha_sim]) #columns in trace are subjects, rows samples\n",
    "print(['beta',np.median(np.median(trace['beta'], axis = 0)),\n",
    "       np.median(trace['beta'], axis = 0).std(), beta_sim])\n",
    "print(['gamma',np.median(np.median(trace['gamma'], axis = 0)),\n",
    "       np.median(trace['gamma'], axis = 0).std(), gamma_sim])\n",
    "print(['delta',np.median(np.median(trace['delta'], axis = 0)),\n",
    "       np.median(trace['delta'], axis = 0).std(), delta_sim])\n",
    "print(['lambbda',np.median(np.median(trace['lambbda'], axis = 0)),\n",
    "       np.median(trace['lambbda'], axis = 0).std(), lambda_sim])\n",
    "print(['luce',np.median(np.median(trace['luce'], axis = 0)),\n",
    "       np.median(trace['luce'], axis = 0).std(), luce_sim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Posterior plots of 6 CPT parameters (group-level)\n",
    "data = az.from_pymc3(trace=trace, model=CPT)\n",
    "fig, ax = plt.subplots(2,2, figsize = (8,8))\n",
    "az.plot_density([st.norm.cdf(trace['mu_alpha_N'])],\n",
    "                data_labels=['Alpha'],\n",
    "                hdi_prob=1, ax = ax[0,0]);\n",
    "az.plot_density([st.norm.cdf(trace['mu_gamma_N']),\n",
    "                st.norm.cdf(trace['mu_delta_N'])],\n",
    "                data_labels=['Gamma' , 'Delta'],\n",
    "                hdi_prob=1, ax = ax[0,1]);\n",
    "az.plot_density(np.exp(trace['mu_l_lambda_N']),\n",
    "                data_labels=['Lambda'],\n",
    "                hdi_prob=1, ax = ax[1,0]);\n",
    "az.plot_density(np.exp(trace['mu_l_luce_N']),\n",
    "                data_labels=['Luce'],\n",
    "                hdi_prob=1, ax = ax[1,1]);\n",
    "ax[0,0].set_title('Alpha \\n risk aversion')\n",
    "ax[0,1].set_title('Prob. non-linearities')\n",
    "ax[1,0].set_title('Lambda \\n loss aversion')\n",
    "ax[1,1].set_title('Luce \\n choice noise')\n",
    "plt.tight_layout()\n",
    "fig.savefig('img/6_CB/Nilsson_Fig3.svg')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-5aa55d24d33b>:10: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(1000, tune = 1500, init='adapt_diag', target_accept = 0.95)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [luce_N, lambda_N, delta_N, gamma_N, alpha_N, sigma_l_luce_N, mu_l_luce_N, sigma_l_lambda_N, mu_l_lambda_N, sigma_delta_N, mu_delta_N, sigma_gamma_N, mu_gamma_N, sigma_alpha_N, mu_alpha_N]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10000/10000 03:06<00:00 Sampling 4 chains, 5 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_500 tune and 1_000 draw iterations (6_000 + 4_000 draws total) took 188 seconds.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# Now run the model with real data\n",
    "with CPT:\n",
    "    #Change data \n",
    "    pm.set_data({\"data_win\": np.array(Rieskamp_data_win),\n",
    "                 'data_loss': np.array(Rieskamp_data_loss),\n",
    "                 'data_mix': np.array(Rieskamp_data_mix)\n",
    "                })\n",
    "    \n",
    "    ##############  Sampling  ##############\n",
    "    trace = pm.sample(1000, tune = 1500, init='adapt_diag', target_accept = 0.95)\n",
    "    rhat = pm.rhat(trace, var_names = ['alpha', 'beta', 'gamma', 'delta', 'lambbda', 'luce'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Revisar convergencia. \n",
    "# Rhat <1.1 usualmente son aceptados como convergencia\n",
    "print(rhat.alpha[0:nsubj].mean())\n",
    "print(rhat.beta[0:nsubj].mean())\n",
    "print(rhat.gamma[0:nsubj].mean())\n",
    "print(rhat.delta[0:nsubj].mean())\n",
    "print(rhat.lambbda[0:nsubj].mean())\n",
    "print(rhat.luce[0:nsubj].mean())\n",
    "for RV in CPT.basic_RVs: #None should be inf or -inf\n",
    "    print(RV.name, RV.logp(CPT.test_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(['alpha',np.median(np.median(trace['alpha'], axis = 0)),\n",
    "       np.median(trace['alpha'], axis = 0).std()]) #columns in trace are subjects, rows samples\n",
    "print(['beta',np.median(np.median(trace['beta'], axis = 0)),\n",
    "       np.median(trace['beta'], axis = 0).std()])\n",
    "print(['gamma',np.median(np.median(trace['gamma'], axis = 0)),\n",
    "       np.median(trace['gamma'], axis = 0).std()])\n",
    "print(['delta',np.median(np.median(trace['delta'], axis = 0)),\n",
    "       np.median(trace['delta'], axis = 0).std()])\n",
    "print(['lambbda',np.median(np.median(trace['lambbda'], axis = 0)),\n",
    "       np.median(trace['lambbda'], axis = 0).std()])\n",
    "print(['luce',np.median(np.median(trace['luce'], axis = 0)),\n",
    "       np.median(trace['luce'], axis = 0).std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Posterior plots of 6 CPT parameters (group-level)\n",
    "data = az.from_pymc3(trace=trace, model=CPT)\n",
    "fig, ax = plt.subplots(2,2, figsize = (8,8))\n",
    "az.plot_density([st.norm.cdf(trace['mu_alpha_N'])],\n",
    "                data_labels=['Alpha'],\n",
    "                hdi_prob=1, ax = ax[0,0]);\n",
    "az.plot_density([st.norm.cdf(trace['mu_gamma_N']),\n",
    "                st.norm.cdf(trace['mu_delta_N'])],\n",
    "                data_labels=['Gamma' , 'Delta'],\n",
    "                hdi_prob=1, ax = ax[0,1]);\n",
    "az.plot_density(np.exp(trace['mu_l_lambda_N']),\n",
    "                data_labels=['Lambda'],\n",
    "                hdi_prob=1, ax = ax[1,0]);\n",
    "az.plot_density(np.exp(trace['mu_l_luce_N']),\n",
    "                data_labels=['Luce'],\n",
    "                hdi_prob=1, ax = ax[1,1]);\n",
    "ax[0,0].set_title('Alpha \\n risk aversion')\n",
    "ax[0,1].set_title('Prob. non-linearities')\n",
    "ax[1,0].set_title('Lambda \\n loss aversion')\n",
    "ax[1,1].set_title('Luce \\n choice noise')\n",
    "plt.tight_layout()\n",
    "fig.savefig('img/6_CB/Nilsson_Fig4.svg')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n",
    "Corra el modelo con sus datos e interprete los párametros obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Conclusión\n",
    "\n",
    "* Medir riesgo en individuos con BART o loterias\n",
    "* Modelar hipótesis:\n",
    "    * FitzGibbon, et al, 2021, contrafactuales, emociones y riesgo\n",
    "    * Kahneman & Tversy, prospect theory:\n",
    "        * Dificultad en recuperar parametros (especificación de Nilsson, et al, 2011, igualaba preferencias de riesgo ($\\alpha=\\beta$) para recuperar aversión a perdidas ($\\lambda$)) \n",
    "* Jerárquico:\n",
    "    * Usa información de grupo\n",
    "* No jerárquico:\n",
    "    * Pooling (participantes son idénticos)\n",
    "    * Independence (participantes son únicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='none' --SlidesExporter.reveal_scroll=True 6_Decisiones_Riesgo.ipynb #Saves slide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Para salvar las diapositivas a PDF (en Chrome), correr nbconvert para que abra las diapositivas en un servidor local (la transition y el theme son opcionales):\n",
    "\n",
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='convex' nombre_de_mi_notebook.ipynb --post serve\n",
    "\n",
    "Luego, a la dirección añadirle ?print-pdf después del .html:\n",
    "\n",
    "http://127.0.0.1:8000/nombre_de_mi_notebook.slides.html?print-pdf\n",
    "\n",
    "Y luego, imprimir y darle salvar como pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Para salvar a pdf\n",
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='none' 6_Decisiones_Riesgo.ipynb --post serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Anexos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#BART\n",
    "dot_text = 'digraph G {rankdir=TB; compound=true; newrank=true; labelloc=\"t\";\\\n",
    "           label=\"BART\";\\\n",
    "           /* general properties*/\\\n",
    "           node [margin=0, fixedsize=true, shape=plaintext,\\\n",
    "                 height=0.7, width=0.7, lblstyle=\"font=\\\\small\"];\\\n",
    "           /* links */\\\n",
    "           burst_prob -> number_pumps;\\\n",
    "           risk_taking -> number_pumps;\\\n",
    "           number_pumps -> logistic;\\\n",
    "           beh_consist -> logistic;\\\n",
    "           logistic -> decision;\\\n",
    "           subgraph cluster0 {\\\n",
    "               margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "               style = rounded;\\\n",
    "               label = \"$Choice_k$\";\\\n",
    "               subgraph cluster1 {\\\n",
    "                   margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "                   style = rounded;\\\n",
    "                   label = \"$Trial_j$\";\\\n",
    "                   logistic;\\\n",
    "                   decision;\\\n",
    "               }\\\n",
    "           }\\\n",
    "           /* nodes */\\\n",
    "           burst_prob [label = \"$p$\", fillcolor = gray, style = filled, shape = circle];\\\n",
    "           number_pumps [label = \"$omega$\", shape = circle, peripheries = 2];\\\n",
    "           risk_taking [label = \"$gamma^{+}$\", shape = circle];\\\n",
    "           logistic [label = \"$theta_{jk}$\", shape = circle, peripheries = 2];\\\n",
    "           beh_consist [label = \"$beta$\", shape = circle];\\\n",
    "           decision [label = \"$d_{jk}$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           }' #warning: use single quote at start and end; double quotes for labels\n",
    "s = Source(dot_text, filename=\"img/6_CB/model_BART.gv\", format=\"svg\") #THIS IS NOT THE FINAL ONE\n",
    "s.view()\n",
    "\n",
    "#To typeset latex stuff on the image: \n",
    "#1) open svg in inkscape and write latex formulas. Export as pdf (click the one that says latex)\n",
    "#   to change fontsize of latex in inkscape write before the expression: \n",
    "#        \\fontsize{34pt}{1em} $latex expression$ ... change #pt for size\n",
    "#2) go to overleaf or latex editor of choice and do this (https://castel.dev/post/lecture-notes-2/):\n",
    "#   2.1) In the preamble:\n",
    "#  \\usepackage{import}\n",
    "#  \\usepackage{xifthen}\n",
    "#  \\usepackage{pdfpages}\n",
    "#  \\usepackage{transparent}\n",
    "#  \\usepackage{graphics} \n",
    "\n",
    "#  \\newcommand{\\incfig}[1]{%\n",
    "#      \\def\\svgwidth{\\columnwidth}\n",
    "#      \\import{./figures/}{#1.pdf_tex} %PUT the inkscape .pdf_tex AND .pdf in a local folder called figures\n",
    "#  }\n",
    "#   2.2)In the body:\n",
    "#  \\begin{figure}[ht]\n",
    "#      \\centering\n",
    "#      \\scalebox{.65}{\\incfig{your_inkscape.pdf_tex}} #change scalebox proportion to rescale\n",
    "#      \\caption{Riemmans theorem}\n",
    "#      \\label{fig:riemmans-theorem}\n",
    "#  \\end{figure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#BART hierarchical\n",
    "dot_text = 'digraph G {rankdir=TB; compound=true; newrank=true; labelloc=\"t\";\\\n",
    "           label=\"BART\";\\\n",
    "           /* general properties*/\\\n",
    "           node [margin=0, fixedsize=true, shape=plaintext,\\\n",
    "                 height=0.7, width=0.7, lblstyle=\"font=\\\\small\"];\\\n",
    "           /* links */\\\n",
    "           burst_prob -> number_pumps;\\\n",
    "           risk_taking -> number_pumps;\\\n",
    "           mu_risk_taking -> risk_taking;\\\n",
    "           sigma_risk_taking -> risk_taking;\\\n",
    "           number_pumps -> logistic;\\\n",
    "           beh_consist -> logistic;\\\n",
    "           mu_beh_consist -> beh_consist;\\\n",
    "           sigma_beh_consist -> beh_consist;\\\n",
    "           logistic -> decision;\\\n",
    "           subgraph cluster0 {\\\n",
    "               margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "               style = rounded;\\\n",
    "               label = \"$Conditions_i$\";\\\n",
    "               risk_taking;\\\n",
    "               beh_consist;\\\n",
    "               number_pumps;\\\n",
    "               subgraph cluster1 {\\\n",
    "                   margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "                   style = rounded;\\\n",
    "                   label = \"$Choice_k$\";\\\n",
    "                   subgraph cluster2 {\\\n",
    "                       margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "                       style = rounded;\\\n",
    "                       label = \"$Trial_j$\";\\\n",
    "                       logistic;\\\n",
    "                       decision;\\\n",
    "                   }\\\n",
    "               }\\\n",
    "           }\\\n",
    "           /* nodes */\\\n",
    "           burst_prob [label = \"$p$\", fillcolor = gray, style = filled, shape = circle];\\\n",
    "           number_pumps [label = \"$omega_i$\", shape = circle, peripheries = 2];\\\n",
    "           risk_taking [label = \"$gamma_i^{+}$\", shape = circle];\\\n",
    "           mu_risk_taking [label = \"$mu_{gamma^{+}}$\", shape = circle];\\\n",
    "           sigma_risk_taking [label = \"$sigma_{gamma^{+}}$\", shape = circle];\\\n",
    "           logistic [label = \"$theta_{ijk}$\", shape = circle, peripheries = 2];\\\n",
    "           beh_consist [label = \"$beta_i$\", shape = circle];\\\n",
    "           mu_beh_consist [label = \"$mu_{beta}$\", shape = circle];\\\n",
    "           sigma_beh_consist [label = \"$sigma_{beta}$\", shape = circle];\\\n",
    "           decision [label = \"$d_{ijk}$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           }' #warning: use single quote at start and end; double quotes for labels\n",
    "s = Source(dot_text, filename=\"img/6_CB/model_BART_hierarchical.gv\", format=\"svg\") #THIS IS NOT THE FINAL ONE\n",
    "s.view()\n",
    "\n",
    "#\\mu_{\\gamma^{+}} \\sim Uniform(0,10)\n",
    "#\\sigma_{\\gamma^{+}} \\sim Uniform(0,10)\n",
    "#\\mu_{\\beta} \\sim Uniform(0,10)\n",
    "#\\sigma_{\\beta} \\sim Uniform(0,10)\n",
    "#\\gamma_i^{+} \\sim Normal(\\mu_{\\gamma^{+}}, \\sigma_{\\gamma^{+}})\n",
    "#\\beta_i \\sim Normal(\\mu_{\\beta}, \\sigma_{\\beta})\n",
    "#\\omega_i = -frac{\\gamma_i^{+}}{log(1-p)}\n",
    "#\\theta_{ijk} = \\frac{1}{1 + e^{\\beta_i (k-\\omega_i)}}\n",
    "#\\d_{ijk} \\sim Bernoulli(\\theta_{ijk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#CPT\n",
    "dot_text = 'digraph G {rankdir=TB; compound=true; newrank=true; labelloc=\"t\";\\\n",
    "           label=\"Cumulative Prospect Theory\";\\\n",
    "           /* general properties*/\\\n",
    "           node [margin=0, fixedsize=true, shape=plaintext,\\\n",
    "                 height=0.55, width=0.55, lblstyle=\"font=\\\\small\"];\\\n",
    "           /* links */\\\n",
    "           hyper_mu_sd -> alpha_normal;\\\n",
    "           hyper_mu_sd -> beta_normal;\\\n",
    "           hyper_mu_sd -> gamma_normal;\\\n",
    "           hyper_mu_sd -> delta_normal;\\\n",
    "           hyper_mu_sd_exp -> lambda_normal;\\\n",
    "           hyper_mu_sd_exp -> phi_normal;\\\n",
    "           subgraph cluster0 {\\\n",
    "               margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "               style = rounded;\\\n",
    "               label = \" \"; texlbl = \"$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; i$ Individuo\";\\\n",
    "               alpha_normal -> alpha;\\\n",
    "               beta_normal -> beta;\\\n",
    "               gamma_normal -> gamma;\\\n",
    "               delta_normal -> delta;\\\n",
    "               phi_normal -> phi;\\\n",
    "               lambda_normal -> lambd;\\\n",
    "               alpha -> val;\\\n",
    "               lambd -> val;\\\n",
    "               beta -> val;\\\n",
    "               gamma -> w_prob;\\\n",
    "               delta -> w_prob;\\\n",
    "               phi -> choice;\\\n",
    "               subgraph cluster1 {\\\n",
    "                   margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "                   style = rounded;\\\n",
    "                   label = \" \"; texlbl = \"$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; t$ Turno\";\\\n",
    "                   x -> val;\\\n",
    "                   x -> c;\\\n",
    "                   c -> w_prob;\\\n",
    "                   p -> w_prob;\\\n",
    "                   val -> EV;\\\n",
    "                   w_prob -> EV;\\\n",
    "                   EV -> choice;\\\n",
    "                   choice -> choice_data;\\\n",
    "               }\\\n",
    "           }\\\n",
    "           choice_data -> choice_data_dist -> hyper_mu_dist -> hyper_sd_dist -> hyper_mu_dist_exp -> hyper_sd_dist_exp -> alpha_normal_dist ->  alpha_dist -> beta_normal_dist -> beta_dist -> gamma_normal_dist -> gamma_dist -> delta_normal_dist -> delta_dist -> lambda_normal_dist -> lambda_dist -> phi_normal_dist -> phi_dist -> val_dist -> c_dist -> w_prob_dist -> EV_dist -> choice_dist [style = invis];\\\n",
    "           /* nodes */\\\n",
    "           hyper_mu_sd [texlbl = \"$(\\\\mu,\\\\sigma)$\", shape = circle];\\\n",
    "           hyper_mu_dist[texlbl = \"$\\\\mu \\sim Normal(0,1)$\"];\\\n",
    "           hyper_sd_dist [texlbl = \"$\\\\sigma \\sim Uniform(0,10)$\"];\\\n",
    "           hyper_mu_sd_exp [texlbl = \"$(\\\\mu_l,\\\\sigma_l)$\", shape = circle];\\\n",
    "           hyper_mu_dist_exp [texlbl = \"$\\\\mu_l \\sim Uniform(-2.3,1.61)$\"];\\\n",
    "           hyper_sd_dist_exp  [texlbl = \"$\\\\sigma_l \\sim Uniform(0,1.13)$\"];\\\n",
    "           alpha_normal [texlbl = \"$\\\\alpha_{N_i}$\", shape = circle];\\\n",
    "           alpha_normal_dist [texlbl = \"$\\\\alpha_{N_i} \\sim Normal(\\\\mu,\\\\sigma)[-3,3]$\"];\\\n",
    "           alpha [texlbl = \"$\\\\alpha_i$\", shape = circle, peripheries = 2];\\\n",
    "           alpha_dist  [texlbl = \"$\\\\alpha_i \\sim Std-Normal_{CDF}(\\\\alpha_{N_i})$\"];\\\n",
    "           beta_normal [texlbl = \"$\\\\beta_{N_i}$\", shape = circle];\\\n",
    "           beta_normal_dist [texlbl = \"$\\\\beta_{N_i} \\sim Normal(\\\\mu,\\\\sigma)[-3,3]$\"];\\\n",
    "           beta [texlbl = \"$\\\\beta_i$\", shape = circle, peripheries = 2];\\\n",
    "           beta_dist  [texlbl = \"$\\\\beta_i \\sim Std-Normal_{CDF}(\\\\beta_{N_i})$\"];\\\n",
    "           gamma_normal [texlbl = \"$\\\\gamma_{N_i}$\", shape = circle];\\\n",
    "           gamma_normal_dist [texlbl = \"$\\\\gamma_{N_i} \\sim Normal(\\\\mu,\\\\sigma)[-3,3]$\"];\\\n",
    "           gamma [texlbl = \"$\\\\gamma_i$\", shape = circle, peripheries = 2];\\\n",
    "           gamma_dist  [texlbl = \"$\\\\gamma_i \\sim Std-Normal_{CDF}(\\\\gamma_{N_i})$\"];\\\n",
    "           delta_normal [texlbl = \"$\\\\delta_{N_i}$\", shape = circle];\\\n",
    "           delta_normal_dist [texlbl = \"$\\\\delta_{N_i} \\sim Normal(\\\\mu,\\\\sigma)[-3,3]$\"];\\\n",
    "           delta [texlbl = \"$\\\\delta_i$\", shape = circle, peripheries = 2];\\\n",
    "           delta_dist  [texlbl = \"$\\\\delta_i \\sim Std-Normal_{CDF}(\\\\delta_{N_i})$\"];\\\n",
    "           lambda_normal [texlbl = \"$\\\\lambda_{N_i}$\", shape = circle];\\\n",
    "           lambda_normal_dist [texlbl = \"$\\\\lambda_{N_i} \\sim Normal(\\\\mu_l,\\\\sigma_l)$\"];\\\n",
    "           lambd [texlbl = \"$\\\\lambda_i$\", shape = circle, peripheries = 2];\\\n",
    "           lambda_dist  [texlbl = \"$\\\\lambda_i \\sim e^{\\\\lambda_{N_i}}$\"];\\\n",
    "           phi_normal [texlbl = \"$\\\\phi_{N_i}$\", shape = circle];\\\n",
    "           phi_normal_dist [texlbl = \"$\\\\phi_{N_i} \\sim Normal(\\\\mu_l,\\\\sigma_l)$\"];\\\n",
    "           phi [texlbl = \"$\\\\phi_i$\", shape = circle, peripheries = 2];\\\n",
    "           phi_dist  [texlbl = \"$\\\\phi_i \\sim e^{\\\\phi_{N_i}}$\"];\\\n",
    "           x [texlbl = \"$x_{it}$\", shape = circle, fillcolor = gray, style = filled];\\\n",
    "           p [texlbl = \"$p_{it}$\", shape = circle, fillcolor = gray, style = filled];\\\n",
    "           c [texlbl = \"$c_{it}$\", shape = circle];\\\n",
    "           c_dist [texlbl = \"$c_{it} = \\\\left\\\\lbrace \\\\parbox{7cm}{$\\\\gamma_i \\;\\;\\;\\;\\;\\; x_{it} \\ge 0$ \\\\\\ \\\\\\ $\\\\delta_i \\;\\;\\;\\;\\;\\; x_{it} <0 $} \\\\right.$\"];\\\n",
    "           w_prob [texlbl = \"$\\\\pi(p_{it})$\", shape = circle];\\\n",
    "           w_prob_dist [texlbl = \"$\\\\pi(p_{it})= \\\\frac{p_{it}^c}{(p_{it}^c-(1-p_{it}^c))^{1/c}}$\"];\\\n",
    "           val [texlbl = \"$v(x_{it})$\", shape = circle];\\\n",
    "           val_dist [texlbl = \"$v(x_{it}) = \\\\left\\\\lbrace \\\\parbox{7cm}{$x_{it}^{\\\\alpha_i} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; x_{it} \\ge 0$ \\\\\\ \\\\\\ $-\\\\lambda_i(-x_{it})^{\\\\beta} \\;\\;\\;\\; x_{it} <0 $} \\\\right.$\"];\\\n",
    "           EV [texlbl = \"$V(O)$\", shape = circle, peripheries = 2];\\\n",
    "           EV_dist [texlbl = \"$V(O) = \\pi(p_{it_A})v(x_{it_A}) + \\pi(p_{it_B})v(x_{it_B})$\"];\\\n",
    "           choice [texlbl = \"$p_{it}(A,B)$\", shape = circle];\\\n",
    "           choice_dist [texlbl = \"$p_{it}(A,B) = \\\\frac{1}{1+e^{\\\\phi (V(B_t)-V(A_t))}}$\"];\\\n",
    "           choice_data [texlbl = \"$Choice_{it}$\", shape = square, style = filled, fillcolor = gray];\\\n",
    "           choice_data_dist [texlbl = \"$Choice_{it} \\sim Bernoulli(p_{it}(A,B))$\"];\\\n",
    "           }' #warning: use single quote at start and end; double quotes for labels\n",
    "tex = d2t.dot2tex(dot_text, format='tikz', preproc = True) #makes sure it looks good in tex\n",
    "tex = d2t.dot2tex(dot_text, texmode = 'verbatim', crop=True) #crop: the page size equal to the model\n",
    "diagram_tex = open('img/6_CB/model_CPT.tex', 'w')\n",
    "diagram_tex.write(tex) \n",
    "diagram_tex.close()\n",
    "\n",
    "# this builds a pdf-file inside a directory\n",
    "pdf = build_pdf(tex)\n",
    "pdf.save_to('img/6_CB/model_CPT.pdf') #convertir a svg y pulir/editar posiciones en inkscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# CPT images for trials\n",
    "# Gambles shown to participants. \n",
    "# A and B appeared on the left or right randomly\n",
    "gambles_A = pd.read_table(\"data/6_CB/GambleA.txt\", header=None)\n",
    "gambles_A.columns = ['Reward_1', 'Prob_1', 'Reward_2', 'Prob_2']\n",
    "gambles_B = pd.read_table(\"data/6_CB/GambleB.txt\", header=None)\n",
    "gambles_B.columns = ['Reward_1', 'Prob_1', 'Reward_2', 'Prob_2']\n",
    "ntrials = gambles_B.shape[0]\n",
    "file_address_psychopy = []\n",
    "for n in range(ntrials):\n",
    "    if n<60: #win trials\n",
    "        colors = ['#228B22','#20B2AA']\n",
    "        title = 'GANAR'\n",
    "    elif n>59 and n<120:\n",
    "        colors = [\"#8B0000\", '#FF0000']\n",
    "        title = 'PERDER'\n",
    "    else:\n",
    "        colors = [\"#228B22\", '#FF0000']\n",
    "        title = 'GANAR & PERDER'\n",
    "        \n",
    "    # Creating plot\n",
    "    fig = plt.figure(figsize=(12,5), constrained_layout=True)\n",
    "    spec = GridSpec(ncols=28, nrows=1, figure=fig)\n",
    "    ax0 = fig.add_subplot(spec[0, 0:1])\n",
    "    ax1 = fig.add_subplot(spec[0, 2:12])\n",
    "    ax2 = fig.add_subplot(spec[0, 13:14])\n",
    "    ax3 = fig.add_subplot(spec[0, 15:25])\n",
    "    ax4 = fig.add_subplot(spec[0, 26:27])\n",
    "    #fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(9,3)) #ax1,ax2 refer to your two pies\n",
    "    \n",
    "    labels = gambles_A.loc[n,['Reward_1', 'Reward_2']]*1000\n",
    "    labels = [\"${:,.0f}\".format(labels[0]), \"${:,.0f}\".format(labels[1])]\n",
    "    values = gambles_A.loc[n,['Prob_1', 'Prob_2']]\n",
    "    _, texts, autotexts = ax1.pie(values, labels = labels,\n",
    "                              colors = colors,autopct = '%1.1f%%', radius=1.5) #plot first pie\n",
    "    [ _.set_fontsize(16) for _ in texts ]\n",
    "    [ _.set_fontsize(12) for _ in autotexts ]    \n",
    "    #ax1.axis('equal')\n",
    "    ax1.set_ylim(-1,2)\n",
    "    ax1.set_title(title, fontsize = 18)\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "\n",
    "    ax0.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "    ax3.set_axis_off()\n",
    "    ax4.set_axis_off()\n",
    "\n",
    "    labels = gambles_B.loc[n,['Reward_1', 'Reward_2']]*1000\n",
    "    labels = [\"${:,.0f}\".format(labels[0]), \"${:,.0f}\".format(labels[1])]\n",
    "    values = gambles_B.loc[n,['Prob_1', 'Prob_2']]\n",
    "    _, texts, autotexts = ax3.pie(values, labels = labels, \n",
    "                              colors = colors,autopct = '%1.1f%%', radius=1.5) #plot first pie\n",
    "    [ _.set_fontsize(16) for _ in texts ]\n",
    "    [ _.set_fontsize(12) for _ in autotexts ]\n",
    "    ax3.set_ylim(-1,2)\n",
    "    #ax3.axis('equal')\n",
    "    ax3.set_title(title, fontsize = 18)\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "    file_address_psychopy.append('img/GP_' + str(n) + '.png')\n",
    "    fig.savefig('exp/6_CB/img/GP_' + str(n) + '.png')\n",
    "    plt.close()     \n",
    "#bbox_inches= \"tight\"\n",
    "f.to_csv('exp/6_CB/img_links.csv')\n",
    "      \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Hierarchical BART (FitzGibbon, et al, 2021)\n",
    "p = 0.5\n",
    "npump_max = 12 #from the Fitzgibbon experimental design\n",
    "#emo_change_scale = [-200,200] #from the Fitzgibbon paper\n",
    "emo_change_scale = [-3,3] #standardized (zscore; see cell above)\n",
    "delta_emo_data = np.array(Data['emotion_change_rating'])\n",
    "info = np.array(Data['information_sought'])\n",
    "info_boolean = np.array(info, dtype = 'bool')\n",
    "diff_limit = np.array(Data['diff_pumps_limit'])\n",
    "npumps_next_trial = np.array(Data['next_trial_n_pumps'])\n",
    "k = 2; #info and no info\n",
    "chains = 4\n",
    "with pm.Model() as BART_CF:\n",
    "    #priors\n",
    "    mu_g = pm.Uniform(\"mu_g\", lower = 0, upper = 10)\n",
    "    sigma_g = pm.Uniform(\"sigma_g\", lower = 0, upper = 10)\n",
    "    mu_b = pm.Uniform(\"mu_b\", lower = 0, upper = 1)\n",
    "    sigma_b = pm.Uniform(\"sigma_b\", lower = 0, upper = 3)\n",
    "    mu_intercept = pm.Uniform(\"mu_i\", lower = -3, upper = 3, shape = 2)\n",
    "    mu_slope = pm.Uniform(\"mu_s\", lower = -2, upper = 2, shape = 2)\n",
    "    sigma_intercept = pm.Uniform(\"sigma_i\", lower = 0, upper = 3, shape = 2)\n",
    "    sigma_slope = pm.Uniform(\"sigma_s\", lower = 0, upper = 3, shape = 2)\n",
    "    sigma_emo = pm.Uniform('sigma_emo', lower = 0 , upper = 3, shape = 2)\n",
    "\n",
    "    gammap = pm.Normal(\"gammap\", mu=mu_g, sd=sigma_g, shape=k)\n",
    "    beta = pm.Normal(\"beta\", mu=mu_b, sd=sigma_b, shape=k)\n",
    "\n",
    "    omega = -gammap[info] / np.log(1 - p)\n",
    "    \n",
    "    thetajk = 1 - pm.math.invlogit(-beta[info] * (npumps_next_trial - omega))\n",
    "    \n",
    "    intercept = pm.Normal('intercept', \n",
    "                          mu = mu_intercept, \n",
    "                          sd = sigma_intercept, shape = 2)\n",
    "    slope = pm.Normal('slope', \n",
    "                      mu = mu_slope, \n",
    "                      sd = sigma_slope, shape = 2)\n",
    "    \n",
    "    #likelihood\n",
    "    mu_emo = intercept[0] + slope[0]*diff_limit[~info_boolean]\n",
    "    delta_emo_no_info = pm.Normal('delta_emo_no_info', mu = mu_emo, sigma = sigma_emo[0], \n",
    "                                  observed = delta_emo_data[~info_boolean])\n",
    "    \n",
    "    mu_emo = intercept[1] + slope[1]*diff_limit[info_boolean]\n",
    "    delta_emo_info = pm.Normal('delta_emo_info', mu = mu_emo, sigma = sigma_emo[1], \n",
    "                           observed = delta_emo_data[info_boolean])\n",
    "    \n",
    "    dj = pm.Binomial(\"dj\", p=thetajk, n=npump_max, observed=npumps_next_trial)\n",
    "    \n",
    "    #get starting values with variational inference\n",
    "    approx = pm.fit(\n",
    "        n=10000, method=\"advi\", obj_optimizer=pm.adagrad_window\n",
    "    )  # type: pm.MeanField\n",
    "    start = approx.sample(draws=chains, include_transformed=True)\n",
    "    #sample\n",
    "    trace = pm.sample(\n",
    "         tune=2000, target_accept=0.99, chains=chains, cores = 4, \n",
    "        init=\"adapt_diag\", start=list(start)\n",
    "    )\n",
    "\n",
    "    data = az.from_pymc3(trace=trace)\n",
    "    ppc = pm.sample_posterior_predictive(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(s)\n",
    "az.plot_trace(data, var_names=[\"gammap\", \"beta\", 'intercept', 'slope']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_ppc(az.from_pymc3(posterior_predictive=ppc, model=BART_CF));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#The model seems to qualitatively predict the data fairly well\n",
    "plt.figure(figsize=(5, 5)); \n",
    "idx = Data['information_sought']==1\n",
    "plt.plot(diff_limit[idx], delta_emo_data[idx], '.b',  label = 'Info')\n",
    "hdi_intercept = az.hdi(trace['intercept'][:,1]) #high density interval\n",
    "hdi_slope = az.hdi(trace['slope'][:,1])\n",
    "x = np.linspace(-1,12)\n",
    "y = trace['slope'][:,1].mean()*x + trace['intercept'][:,1].mean()\n",
    "plt.plot(x,y, color='blue')\n",
    "plt.fill_between(y1=hdi_slope[0]*x + hdi_intercept[0], \n",
    "                 y2= hdi_slope[1]*x + hdi_intercept[1],\n",
    "                 x=x, alpha=0.15, color='blue');\n",
    "plt.ylabel(\"Emotion-Change Rating\", fontsize=16); \n",
    "plt.xlabel(\"Missed Oppotunity\", fontsize=16);\n",
    "\n",
    "\n",
    "idx = Data['information_sought']==0\n",
    "plt.plot(diff_limit[idx], delta_emo_data[idx], '.r',  label = 'No info')\n",
    "hdi_intercept = az.hdi(trace['intercept'][:,0]) #high density interval\n",
    "hdi_slope = az.hdi(trace['slope'][:,0])\n",
    "x = np.linspace(-1,12)\n",
    "y = trace['slope'][:,0].mean()*x + trace['intercept'][:,0].mean()\n",
    "plt.plot(x,y, color='red')\n",
    "plt.fill_between(y1=hdi_slope[0]*x + hdi_intercept[0], \n",
    "                 y2= hdi_slope[1]*x + hdi_intercept[1],\n",
    "                 x=x, alpha=0.15, color='red');\n",
    "#plt.ylim(-250,250)\n",
    "plt.ylabel(\"Emotion-Change Rating\", fontsize=16); \n",
    "plt.xlabel(\"Missed Oppotunity\", fontsize=16);\n",
    "plt.legend(loc = 'upper left');"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "chalkboard": {
    "color": [
     "rgb(250, 0, 0)",
     "rgb(0, 250, 250)"
    ]
   },
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
