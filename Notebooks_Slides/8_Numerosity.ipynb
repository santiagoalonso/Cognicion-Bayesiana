{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.9.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "from __future__ import print_function\n",
    "\n",
    "#Manejo de matrices y tablas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Estadistica y funciones matemáticas\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import fmin\n",
    "from scipy import integrate\n",
    "from scipy.stats.mstats import mquantiles\n",
    "import statistics \n",
    "import pyreadr\n",
    "import scipy.io as sio\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Probabilistic programs\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt #NOTA: theano va a cambiar a tensorflow en PyMC4\n",
    "import theano\n",
    "from theano.compile.ops import as_op\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "\n",
    "#Graficas\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import altair as alt\n",
    "from altair_saver import save #ademas instalar en terminal: brew cask install chromedriver\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, HBox, VBox, Layout\n",
    "from graphviz import Source, Digraph\n",
    "import dot2tex as d2t\n",
    "from latex import build_pdf\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import arviz as az\n",
    "import colorsys\n",
    "\n",
    "# Image processing stuff\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "#Funciones propias (tienen que estar en el mismo directorio)\n",
    "import my_fun as mf\n",
    "import my_fun_acta_psy as mf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numerosidad\n",
    "Santiago Alonso-Díaz, PhD <br>\n",
    "Universidad Javeriana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilidades y Numerosidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Imagine que alguien tiene al frente dos urnas con tiquetes doblados. La urna uno tiene 1 tiquete ganador y 9 en blanco. La urna dos tiene 10 tiquetes ganadores y 90 en blanco. La persona debe escoger una de las urnas para jugar.\n",
    "\n",
    "Es claro que las probabilidades son iguales. Sin embargo, investigación previa demuestra que la mayoría prefiere una. ¿Cuál cree que la mayoria escoje? ¿Urna 1 o Urna 2?\n",
    "\n",
    "Kirkpatrick & Epstein (1992)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Va a ver la probabilidad de dos eventos en formato de fracciones. Conteste con su intuición, es decir, sea rápido. ¿cuál es más probable?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\frac{211}{617} \\text{ vs.} \\frac{227}{691}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En diferentes versiones (simbolicas S, con imagenes NS, one-shot S,NS, many-shots PPP), alrededor de 2/3 de personas prefiere loterias con mayor número de ganadores \n",
    "<br> <br><br>\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso1.jpg\" width = \"401\" height = '400'></center>\n",
    "\n",
    "Alonso-Diaz, Piantadosi, Hayden, & Cantlon (2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Qué procesos cognitivos explican el sesgo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Pensamiento rápido**\n",
    "<center><img src=\"img/8_CB/FastSlow.png\" width = \"201\" height = '200'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Baja numerosidad/educación**\n",
    "<center><img src=\"img/8_CB/OECD.png\" width = \"251\" height = '250'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Desarrollo conceptual indebido**\n",
    "\n",
    "$$\\frac{1}{2} + \\frac{1}{4} = \\frac{2}{6}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Notación deficiente**\n",
    "\n",
    "Mismo valor diferentes simbolos\n",
    "$$\\frac{1}{2} = \\frac{33}{66}$$\n",
    "\n",
    "Mismo valor iguales simbolos\n",
    "$$\\frac{3}{3} = \\frac{3}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Costos metabólicos de computar ratios**\n",
    "\n",
    "$$Posterior = \\frac{Likelihood \\times Prior}{Marginal}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> Una Hipótesis Bayesiana </center>\n",
    "\n",
    "Los humanos deciden con toda la información (numeradores y ratios). Esto es adaptativo, depronto óptimo, si hay una probabilidad a priori considerable de que las fracciones grandes tengan numeradores grandes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Hay evidencia de la primera parte?\n",
    "\n",
    "**Los humanos deciden con toda la información (numeradores y ratios)**. Esto es adaptativo, depronto óptimo, si hay una probabilidad a priori considerable de que las fracciones grandes tengan numeradores grandes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>Los humanos deciden con toda la información (numeradores y ratios)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Si escojen la de blanco y negro es necesariamente cierto que ustedes no usan color en su decisión?\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso3.png\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Si escojen la de la derecha es necesariamente cierto que ustedes no usan ratio en su decisión?\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso2.jpg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/alonso5.png\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Experimento 2\n",
    "\n",
    "* Contenido de dos bolsas. Naranja gana. ¿Cuál prefiere?\n",
    "* 10 distancias de probabilidad entre las bolsas\n",
    "* 816 turnos\n",
    "* 21 participantes (el efecto aparece en todos, por eso el n no tiene que ser grande)\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso4.jpg\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/alonso7.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Prob. distance effects sugieren representación de ratios\n",
    "* Congruency effects confirman whole-number bias\n",
    "<center><img src=\"img/8_CB/alonso6.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ahora el modelo descriptivo Bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/model_WNB.svg\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supuesto 1:\n",
    "La decisión depende de una combinación lineal de perceptos de numerosidad ($W_{ir}$:winners, $L_{ir}$: losers) y ratios ($\\frac{W_{ir}}{W_{ir}+L_{ir}}$).\n",
    "\n",
    "$$\\beta_1 \\Phi(W_{ir}) + \\beta_2 \\Phi(L_{ir}) + \\beta_3 Ratio_{ir}$$\n",
    "\n",
    "Hipótesis Nula: Si posterior de $\\beta_3$ centrado en cero, la gente en promedio no usa/computa ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supuesto 2:\n",
    "La percepción de numerosidad sigue la ley de Weber\n",
    "\n",
    "$$ \\Phi(\\#_{ir}) \\sim N(\\#_{ir}, Weber \\times \\#_{ir})$$\n",
    "\n",
    "\n",
    "<center><img src=\"img/8_CB/Whalen.png\" width = \"651\" height = '650'></center>\n",
    "Whalen, et al, (1999)\n",
    "\n",
    "Video de [Weber's law](https://www.youtube.com/watch?v=hHG8io5qIU8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supuesto 3:\n",
    "La decisión es estocástica con probabilidad softmax:\n",
    "\n",
    "$$\\frac{e^A}{e^A+e^B}$$\n",
    "\n",
    "Donde A es la combinación lineal de perceptos para opción correcta y B para la opción incorrecta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ahora implementemos en PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = WNB_all['ProbSide1']>=WNB_all['ProbSide2']\n",
    "WNB_all['WinSmallRatio'] = float('nan')\n",
    "WNB_all['DenSmallRatio'] = float('nan')\n",
    "WNB_all['WinBigRatio'] = float('nan')\n",
    "WNB_all['DenBigRatio'] = float('nan')\n",
    "for i in range(WNB_all.shape[0]):\n",
    "    if idx1[i]:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "    else:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "        \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "#Performance: 0 wrong, 1 correct\n",
    "#RT: response time in secs\n",
    "#ProbRatio: small ratio / large ratio\n",
    "#NumRatio: small numerator / large numerator\n",
    "#DenRatio: small denominator / large denominator\n",
    "#AreaCtl: dots across bags have 1: equal dot size, 2: equal cumulative area\n",
    "#WinSide1: number of winners left bag\n",
    "#WinSide2: number of winners right bag\n",
    "#DenSide1: total balls left bag\n",
    "#DenSide2: total balls right bag\n",
    "#ProbSide1: probability of win left bag\n",
    "#ProbSide2: probability of win right bag\n",
    "#sideR: side of response; 1 left, 2 right, 0 no response.\n",
    "#subID: subject identifier\n",
    "\n",
    "WNB_all = pd.read_csv('data/8_CB/WNB.csv')\n",
    "WNB_all['ProbDistance'] = np.abs(WNB_all['ProbSide1']-WNB_all['ProbSide2'])\n",
    "WNB_all = WNB_all.loc[WNB_all['sideR']>0,:].reset_index(drop=True)\n",
    "\n",
    "idx1 = WNB_all['ProbSide1']>=WNB_all['ProbSide2']\n",
    "WNB_all['WinSmallRatio'] = int(0)\n",
    "WNB_all['DenSmallRatio'] = int(0)\n",
    "WNB_all['WinBigRatio'] = int(0)\n",
    "WNB_all['DenBigRatio'] = int(0)\n",
    "for i in range(WNB_all.shape[0]):\n",
    "    if idx1[i]:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "    else:\n",
    "        WNB_all.loc[i,'WinSmallRatio'] = WNB_all.loc[i,'WinSide1']\n",
    "        WNB_all.loc[i,'DenSmallRatio'] = WNB_all.loc[i,'DenSide1']\n",
    "        WNB_all.loc[i,'WinBigRatio'] = WNB_all.loc[i,'WinSide2']\n",
    "        WNB_all.loc[i,'DenBigRatio'] = WNB_all.loc[i,'DenSide2']\n",
    "sID = WNB_all['subID'].unique()\n",
    "subj_to_model = -1 #0 to 20; -1 for all\n",
    "WNB = WNB_all\n",
    "if subj_to_model>=0:\n",
    "    WNB = WNB_all.loc[WNB_all['subID']==sID[subj_to_model],:].reset_index(drop=True) \n",
    "weber = 0.286679553540291 #mean value of participants (see paper)\n",
    "winners_s = np.sort(WNB['WinSmallRatio'].unique())\n",
    "winners_b = np.sort(WNB['WinBigRatio'].unique())\n",
    "winners = np.sort(pd.concat([pd.Series(winners_s), pd.Series(winners_b)]).unique())\n",
    "losers_s = np.sort((WNB['DenSmallRatio']-WNB['WinSmallRatio']).unique())\n",
    "losers_b = np.sort((WNB['DenBigRatio']-WNB['WinBigRatio']).unique())\n",
    "losers = np.sort(pd.concat([pd.Series(losers_s), pd.Series(losers_b)]).unique())\n",
    "sn = np.array(WNB['WinSmallRatio'], dtype = str)\n",
    "sd = np.array(WNB['DenSmallRatio'], dtype = str)\n",
    "r = []\n",
    "for idx, ele in enumerate(sn):\n",
    "    r.append(ele + \"_\" + sd[idx])\n",
    "bn = np.array(WNB['WinBigRatio'], dtype = str)\n",
    "bd = np.array(WNB['DenBigRatio'], dtype = str)\n",
    "for idx, ele in enumerate(bn):\n",
    "    r.append(ele + \"_\" + bd[idx])\n",
    "r = pd.Series(r).unique()\n",
    "ratios = np.zeros((r.shape[0],3))\n",
    "for idx, ele in enumerate(r):\n",
    "    temp = np.array(ele.split(\"_\"), dtype = int)\n",
    "    ratios[idx,0] = temp[0] #num\n",
    "    ratios[idx,1] = temp[1] #den\n",
    "    ratios[idx,2] = temp[0]/temp[1] #ratio\n",
    "print(winners.shape, losers.shape, ratios.shape)\n",
    "\n",
    "#Indices (for vectors with unique values)\n",
    "side1 = np.zeros((WNB.shape[0],3)) #column order: index for winners, losers, ratios\n",
    "side2 = np.zeros((WNB.shape[0],3))\n",
    "for i in range(WNB.shape[0]):\n",
    "    #side 1\n",
    "    w = WNB.loc[i, 'WinSmallRatio'] \n",
    "    den = WNB.loc[i, 'DenSmallRatio'] \n",
    "    l = den - w\n",
    "    side1[i,0] = np.where(winners == w)[0][0]\n",
    "    side1[i,1] = np.where(losers == l)[0][0]\n",
    "    side1[i,2] = np.where((ratios[:,0] == w) & (ratios[:,1] == den))[0][0]\n",
    "    \n",
    "    #side 2\n",
    "    w = WNB.loc[i, 'WinBigRatio'] \n",
    "    den = WNB.loc[i, 'DenBigRatio'] \n",
    "    l = den - w\n",
    "    side2[i,0] = np.where(winners == w)[0][0]\n",
    "    side2[i,1] = np.where(losers == l)[0][0]\n",
    "    side2[i,2] = np.where((ratios[:,0] == w) & (ratios[:,1] == den))[0][0]\n",
    "side1 = side1.astype(int)\n",
    "side2 = side2.astype(int)\n",
    "\n",
    "#choice data\n",
    "idx1 = WNB['ProbSide1']>=WNB_all['ProbSide2']\n",
    "idx2 = WNB['sideR'] == 1\n",
    "WNB['correct'] = np.array((idx1 & idx2) | (~idx1 & ~idx2), dtype = int)\n",
    "choice = WNB['correct'] #0: incorrect; 1: correct\n",
    "#WNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as WNB_model:\n",
    "    \n",
    "    #priors\n",
    "    #percepts of winners and losers assumed different e.g. due to lose aversion\n",
    "    Winners = pm.Normal('percept_winners', \n",
    "                        mu = winners, sd = weber*winners, shape = winners.shape)\n",
    "    Losers = pm.Normal('percept_losers', \n",
    "                       mu = losers, sd = weber*losers, shape = losers.shape) \n",
    "    Ratios = pm.Beta('percept_ratios', \n",
    "                     alpha = ratios[:,0] + 1, \n",
    "                     beta = ratios[:,1] - ratios[:,0] + 1, shape = ratios.shape[0])\n",
    "    Weight_win = pm.Uniform('weight_win', lower = -5, upper = 5)\n",
    "    Weight_lose = pm.Uniform('weight_lose', lower = -5, upper = 5)\n",
    "    Weight_ratio = pm.Uniform('weight_ratio', lower = 0, upper = 5)\n",
    "    \n",
    "    print(Winners.tag.test_value.shape, \n",
    "          Losers.tag.test_value.shape,\n",
    "          Ratios.tag.test_value.shape)\n",
    "\n",
    "    \n",
    "    #likelihood\n",
    "    f_side1 = Weight_ratio*Ratios[side1[:,2]] + Weight_win*Winners[side1[:,0]] + Weight_lose*Losers[side1[:,1]]\n",
    "    f_side2 = Weight_ratio*Ratios[side2[:,2]] + Weight_win*Winners[side2[:,0]] + Weight_lose*Losers[side2[:,1]]\n",
    "    #f_side1 = Weight_win*Winners[side1[:,0]] \n",
    "    #f_side2 = Weight_win*Winners[side2[:,0]]\n",
    "    softmax = tt.exp(f_side2)/(tt.exp(f_side1) + tt.exp(f_side2)) #prob. of picking side 2\n",
    "    #a = tt.exp(np.random.rand(side1.shape[0]))\n",
    "    #b = tt.exp(np.random.rand(side2.shape[0]))\n",
    "    #softmax = a/(a + b) #prob. of picking side 2\n",
    "    choice_LH = pm.Bernoulli('choice', p = softmax, observed = choice)\n",
    "\n",
    "    print(f_side1.tag.test_value.shape, f_side2.tag.test_value.shape,\n",
    "          softmax.tag.test_value.shape, choice_LH.tag.test_value.shape)\n",
    "    \n",
    "    #sampling\n",
    "    trace = pm.sample(1000, init = 'adapt_diag', tune=1500)\n",
    "    ppc = pm.sample_posterior_predictive(trace, samples=5000)\n",
    "    data = az.from_pymc3(trace=trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_trace(data, var_names=['weight_win', 'weight_lose', 'weight_ratio', \n",
    "                               'percept_winners', 'percept_losers', 'percept_ratios'], compact=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = [15,6])\n",
    "az.plot_density(\n",
    "    [trace['weight_win'], trace['weight_lose']],\n",
    "    data_labels=[\"$winners$\", \n",
    "                 \"$losers$\"],\n",
    "    shade=.1, ax = ax[0], hdi_prob=.95, \n",
    ")\n",
    "az.plot_density(\n",
    "    [trace['weight_ratio']], hdi_prob=.95,\n",
    "    data_labels=[\"$\\\\beta_{ratio}$\"], outline=True,\n",
    "    shade=.25, ax = ax[1], colors = 'purple', \n",
    ")\n",
    "ax[0].set_title('$\\\\beta$', fontsize = 20)\n",
    "ax[1].set_title('$\\\\beta_{ratios}$', fontsize = 20)\n",
    "ax[0].legend(loc='upper right');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "idx_cong = WNB['WinBigRatio']>WNB['WinSmallRatio'] #Congruent trial\n",
    "idx_incong = ~idx_cong #Incongruent trial\n",
    "ppc_cong = pd.concat([pd.DataFrame(ppc['choice'].mean(axis=0)[idx_cong], columns = ['choice_model']), \n",
    "                      WNB.loc[idx_cong,:].reset_index(drop=True)], axis = 1)\n",
    "ppc_incong = pd.concat([pd.DataFrame(ppc['choice'].mean(axis=0)[idx_incong], columns = ['choice_model']), \n",
    "                        WNB.loc[idx_incong,:].reset_index(drop=True)], axis = 1)\n",
    "\n",
    "toplot_cong = ppc_cong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "toplot_incong = ppc_incong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "idx1 = toplot_cong['ProbDistance']==0\n",
    "idx2 = toplot_incong['ProbDistance']==0\n",
    "mean0 = (toplot_cong.loc[idx1,'correct'] + toplot_incong.loc[idx2,'correct'])/2\n",
    "toplot_cong.loc[idx1,'correct'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'correct'] = mean0\n",
    "mean0 = (toplot_cong.loc[idx1,'choice_model'] + toplot_incong.loc[idx2,'choice_model'])/2\n",
    "toplot_cong.loc[idx1,'choice_model'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'choice_model'] = mean0\n",
    "\n",
    "fig = plt.figure(figsize=[9,7])\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red');\n",
    "\n",
    "plt.ylim([0.25,1])\n",
    "plt.xlabel('Prob. distance between the bags', fontsize = 20)\n",
    "plt.ylabel('Accuracy\\n%correct ', fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ejercicio\n",
    "\n",
    "* Haga el diagrama de un modelo con un prior uniforme entre 0 y 1 para la fracción Weber por sujeto. \n",
    "    * Implemente el modelo en PyMC y compare el posterior del Weber con el valor fijo de 0.28. ¿Es mayor o menor? ¿Qué significa la diferencia?\n",
    "* Haga el diagrama de un modelo jerárquico con un prior Normal para la fracción de Weber por sujeto. Haga el prior con hiperparametros mu y sigma uniforme entre 0 y 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una hipótesis alternativa es que la gente es estratégica. \n",
    "\n",
    "Si el denominador es igual (o casi igual), se comparan los numeradores. De lo contrario, se comparan los ratios.\n",
    "\n",
    "Implementemos esta idea en PyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usemos un soft threshold para usar o no ratio\n",
    "\n",
    "$$pUseRatio_i = \\frac{1}{1+e^{-k(Thr-rDen_i)}}$$\n",
    "\n",
    "$pUseRatio_i$: Probabilidad de usar ratio en el turno i <br>\n",
    "$k, \\ Thr$: Sensibilidad y umbral, respectivamente. Parametros libres de la sigmoide <br>\n",
    "$rDen_i$: ratio entre los denominadores de ambas bolsa ($Small_{ratio}/Big_{ratio}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "k = 3.2\n",
    "Thr = 0.99\n",
    "rDen = np.linspace(0,1,100)\n",
    "pUseRatio = 1/(1+np.exp(-k*(Thr - rDen)))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(rDen, pUseRatio);\n",
    "plt.ylabel('Prob. use ratio', fontsize = 20)\n",
    "plt.xlabel('Ratio between denominators (S/B)', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as WNB_strategic_model:\n",
    "    \n",
    "    #priors\n",
    "    k = pm.Uniform('k', lower=0, upper=20)\n",
    "    Thr = pm.Uniform('Thr', lower=0, upper=1)\n",
    "    #percepts of winners and losers assumed different e.g. due to lose aversion\n",
    "    Winners = pm.Normal('percept_winners', \n",
    "                        mu = winners, sd = weber*winners, shape = winners.shape)\n",
    "    Losers = pm.Normal('percept_losers', \n",
    "                       mu = losers, sd = weber*losers, shape = losers.shape) \n",
    "    Ratios = pm.Beta('percept_ratios', \n",
    "                     alpha = ratios[:,0] + 1, \n",
    "                     beta = ratios[:,1] - ratios[:,0] + 1, shape = ratios.shape[0])\n",
    "    \n",
    "    #likelihood \n",
    "    w_1 = Winners[side1[:,0]]\n",
    "    w_2 = Winners[side2[:,0]]\n",
    "    l_1 = Losers[side1[:,0]]\n",
    "    l_2 = Losers[side2[:,0]]\n",
    "    d_1 = w_1 + l_1\n",
    "    d_2 = w_2 + l_2\n",
    "    rDen = tt.switch( d_1>=d_2, d_2/d_1, d_1/d_2)\n",
    "    pUseRatio = 1/(1+tt.exp(-k*(Thr-rDen)))  \n",
    "    f_side1 = pUseRatio*Ratios[side1[:,2]] + (1-pUseRatio)*Winners[side1[:,0]] \n",
    "    f_side2 = pUseRatio*Ratios[side2[:,2]] + (1-pUseRatio)*Winners[side2[:,0]] \n",
    "    softmax = tt.exp(f_side2)/(tt.exp(f_side1) + tt.exp(f_side2)) #prob. of picking side 2\n",
    "   \n",
    "    choice_LH = pm.Bernoulli( 'choice', p = softmax, observed=choice)\n",
    "    \n",
    "    \n",
    "    print(f_side1.tag.test_value.shape, f_side2.tag.test_value.shape,\n",
    "          softmax.tag.test_value.shape, choice_LH.tag.test_value.shape)\n",
    "    \n",
    "    #sampling\n",
    "    trace_s = pm.sample(1000, init = 'adapt_diag', tune=1500, target_accept = 0.9)\n",
    "    ppc_s = pm.sample_posterior_predictive(trace_s, samples=5000)\n",
    "    data_s = az.from_pymc3(trace=trace_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_trace(data_s, var_names=['k', 'Thr', \n",
    "                               'percept_winners', 'percept_losers', 'percept_ratios'], compact=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y = trace['percept_winners'].mean(axis=0)\n",
    "x = winners\n",
    "plt.plot(x,y, label = 'intrinsic WNB')\n",
    "\n",
    "y = trace_s['percept_winners'].mean(axis=0)\n",
    "plt.plot(x,y, label = 'strategic')\n",
    "plt.legend()\n",
    "plt.title('Mean Percept Winners')\n",
    "\n",
    "plt.figure()\n",
    "y = trace['percept_losers'].mean(axis=0)\n",
    "x = losers\n",
    "plt.plot(x,y, label = 'intrinsic WNB')\n",
    "\n",
    "y = trace_s['percept_losers'].mean(axis=0)\n",
    "plt.plot(x,y, label = 'strategic')\n",
    "plt.title('Mean Percept Losers')\n",
    "plt.legend();\n",
    "\n",
    "plt.figure()\n",
    "y = trace['percept_ratios'].mean(axis=0)\n",
    "x = ratios[:,2]\n",
    "plt.scatter(x,y, label = 'intrinsic WNB')\n",
    "\n",
    "y = trace_s['percept_ratios'].mean(axis=0)\n",
    "plt.scatter(x,y, label = 'strategic')\n",
    "plt.title('Mean Percept Ratios')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "idx_cong = WNB['WinBigRatio']>WNB['WinSmallRatio'] #Congruent trial\n",
    "idx_incong = ~idx_cong #Incongruent trial\n",
    "ppc_cong = pd.concat([pd.DataFrame(ppc_s['choice'].mean(axis=0)[idx_cong], \n",
    "                                   columns = ['choice_model']), \n",
    "                      WNB.loc[idx_cong,:].reset_index(drop=True)], axis = 1)\n",
    "ppc_incong = pd.concat([pd.DataFrame(ppc_s['choice'].mean(axis=0)[idx_incong], columns = ['choice_model']), \n",
    "                        WNB.loc[idx_incong,:].reset_index(drop=True)], axis = 1)\n",
    "\n",
    "toplot_cong = ppc_cong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "toplot_incong = ppc_incong.groupby(['ProbDistance']).mean()[['choice_model','correct']].reset_index()\n",
    "idx1 = toplot_cong['ProbDistance']==0\n",
    "idx2 = toplot_incong['ProbDistance']==0\n",
    "mean0 = (toplot_cong.loc[idx1,'correct'] + toplot_incong.loc[idx2,'correct'])/2\n",
    "toplot_cong.loc[idx1,'correct'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'correct'] = mean0\n",
    "mean0 = (toplot_cong.loc[idx1,'choice_model'] + toplot_incong.loc[idx2,'choice_model'])/2\n",
    "toplot_cong.loc[idx1,'choice_model'] = mean0 #In prob. distance 0 congruent, incongruente doesn't apply\n",
    "toplot_incong.loc[idx2,'choice_model'] = mean0\n",
    "\n",
    "fig = plt.figure(figsize=[9,7])\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['correct'], color = 'forestgreen', linestyle = ':')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['correct'], color = 'red', linestyle = ':')\n",
    "\n",
    "plt.plot(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.scatter(toplot_cong['ProbDistance'], toplot_cong['choice_model'], color = 'forestgreen')\n",
    "plt.plot(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red')\n",
    "plt.scatter(toplot_incong['ProbDistance'], toplot_incong['choice_model'], color = 'red');\n",
    "\n",
    "plt.ylim([0.25,1])\n",
    "plt.xlabel('Prob. distance between the bags', fontsize = 20)\n",
    "plt.ylabel('Accuracy\\n%correct ', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Model comparison \n",
    "with WNB_strategic_model:\n",
    "    strategic_waic = pm.waic(trace_s) #, var_name = 'choice')\n",
    "with WNB_model:\n",
    "    intrinsic_waic = pm.waic(trace) #This calculates the elpd_waic (-2 times is the waic in deviance scale) \n",
    "\n",
    "#lower is better\n",
    "print('Strategy WAIC (deviance scale):      ', -2*strategic_waic.waic) \n",
    "print('Intrinsic WNB WAIC (deviance scale): ', -2*intrinsic_waic.waic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ejercicios\n",
    "\n",
    "* Haga el diagrama del modelo estratégico\n",
    "* Modifique el modelo WNB_model para simular otras tres hipótesis:\n",
    "    * La gente solo compara ganadores (denominator neglect)\n",
    "    * La gente compara ganadores y perdedores (just number)\n",
    "    * La gente solo compara ratios (holistic ratios)\n",
    "* Compare con WAIC los 5 modelos (intrinsic WNB, Strategic, Denominator neglect, Just number, Holistic ratios). Comente que aprendimos del comportamiento humano (e.g. por qué piensa que el peor lo es; o por que el mejor quedo de primero; por qué los humanos nos comportamos así).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos estimar perceptos de numerosidad y ratio latentes con técnicas bayesianas ... \n",
    "\n",
    "... pero ¿es cognición de fracciones Bayesiana? Depronto. Dos argumentos y datos:\n",
    "\n",
    "* Confianza sigue un sesgo bayesiano\n",
    "* Hay un prior de fracciones altas con numeradores altas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Confianza sigue un sesgo bayesiano\n",
    "<center><img src=\"img/8_CB/alonso15.png\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una percepción de ratios tipo Beta es más precisa con números mayores. \n",
    "\n",
    "Hipótesis (Beta) Bayesiana: la gente debe tener mayor confianza en el mismo ratio pero con números grandes.\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso9.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Experimento: \n",
    "* Escoja la bolsa con mejor probabilidad de sacar una bola naranja. 232 turnos\n",
    "* 100 mTurkers (final n = 82)\n",
    "* 3 distancias de prob. entre las bolsas\n",
    "* 2 condiciones: cardinalidad (alta y baja) y congruencia (cong. e incong)\n",
    "* Confianza post decision \n",
    "\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso10.png\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/8_CB/alonso11.png\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bolsas con alta cardinalidad reducian calificaciones bajas de confianza (2)\n",
    "\n",
    "Bolsas con baja cardinalidad aumentaban calificaciones bajas de confianza (2)\n",
    "\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso12.png\" width = \"400\" height = '400'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Podrá ser un artefacto de preguntar explícitamente? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La misma tarea pero ahora se escoge moviendo el dedo a una pantalla (grabación de infrarojos en la punta del dedo).   \n",
    "\n",
    "Supuesto: trayectoria como proxy de confianza implícita (i.e. el sujeto luego de varios turnos se mueve rápido)\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso13.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La trayectoria era más confiada con ratios con numeros altos (dificultad constante de 0.1)\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso14.svg\" width = \"451\" height = '450'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Los datos son consistentes con la hipótesis bayesiana para fracciones.\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso9.png\" width = \"351\" height = '350'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Otra pista bayesiana es la existencia de un prior fuerte en la realidad.\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso16.svg\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Por qué el gap? ¿Óptimo? Sí, si comparo más rápido numeradores y estos son un proxi del valor fraccional.\n",
    "\n",
    "<center><img src=\"img/8_CB/alonso6.png\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Segun Bayes,\n",
    "\n",
    "$$p(RL|NL) = \\frac{p(NL|RL)p(RL)}{p(NL)}$$\n",
    "\n",
    "donde R: ratio, N: numerador, D: denominador, L: larger, S: smaller.\n",
    "\n",
    "Para sugerir pseudo-optimalidad bayesiana, p(RL|NL) deber ser mayor a todos los demás posteriors\n",
    "\n",
    "$$p(RL|NL) > p(RL|NS) > p(RL|DL) > p(RL|DS)$$\n",
    "\n",
    "De hecho, si la magnitud del ratio y el denominador son independientes se puede mostrar que es muy probable ese ordenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Generate counts for a specific category\n",
    "folder_name = 'Warhol' #We included 4 folders as examples (go to Kaggle or Caltech256 website for others)\n",
    "dirr = 'data/8_CB/Distribution-of-fractions/Example_Images/' + folder_name + '/'\n",
    "name_files = [name for name in os.listdir(dirr) if (os.path.isfile(dirr+name)) & (name != '.DS_Store')]\n",
    "n_files = len(name_files)\n",
    "\n",
    "# Counts\n",
    "results = mf2.img_counts(dirr, name_files, progress = False) #This takes a while\n",
    "hue_bands = 4 #total number of hue bands (see img_counts)\n",
    "NUM = [[], [], [], []]  # pixels of hue\n",
    "DEN = [[], [], [], []]\n",
    "NUM_B = [[], [], [], []]  # brightness of hue\n",
    "DEN_B = [[], [], [], []]\n",
    "NUM_S = [[], [], [], []]  # saturation of hue\n",
    "DEN_S = [[], [], [], []]\n",
    "for hb in range(hue_bands):\n",
    "    NUM[hb].append(results[0][hb])\n",
    "    DEN[hb].append(results[1][hb])\n",
    "    \n",
    "    NUM_B[hb].append(results[2][hb])\n",
    "    DEN_B[hb].append(results[3][hb])\n",
    "    \n",
    "    NUM_S[hb].append(results[4][hb])\n",
    "    DEN_S[hb].append(results[5][hb])\n",
    "\n",
    "\n",
    "# Posteriors for all categories by HSV dimensions. \n",
    "# In \"Example of one image category\"  we show how we calculated\n",
    "# posteriors. Specifically, see the function dropdown_callback \n",
    "# and the call to my_posterior in my_fun.py.\n",
    "\n",
    "caltech256_h = pd.read_csv('data/8_CB/Distribution-of-fractions/tableCaltech_hue.csv')\n",
    "caltech256_s = pd.read_csv('data/8_CB/Distribution-of-fractions/tableCaltech_sat.csv')\n",
    "caltech256_v = pd.read_csv('data/8_CB/Distribution-of-fractions/tableCaltech_bright.csv')\n",
    "paints_h = pd.read_csv('data/8_CB/Distribution-of-fractions/tablePaints_hue.csv')\n",
    "paints_s = pd.read_csv('data/8_CB/Distribution-of-fractions/tablePaints_sat.csv')\n",
    "paints_v = pd.read_csv('data/8_CB/Distribution-of-fractions/tablePaints_bright.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Random images to initialize (changeable in the widget below)\n",
    "rnd1 = np.random.randint(n_files)\n",
    "rnd2 = np.random.randint(n_files)\n",
    "name_files.sort()\n",
    "NUMS = [NUM, NUM_B, NUM_S]\n",
    "DENS = [DEN, DEN_B, DEN_S]\n",
    "\n",
    "wHue = widgets.Dropdown(options=[('Red-yellow', 0), ('Yellow-green', 1), ('Green-blue', 2), ('Blue-purple',3)],\n",
    "                        value=3,\n",
    "                        description='Hue band: ')\n",
    "wDim = widgets.Dropdown(options=[('Hue', 'hue'), ('Saturation', 'saturation'), ('Brightness', 'brightness')],\n",
    "                        value='hue',\n",
    "                        description='HSV dimension: ')\n",
    "wImg1 = widgets.Dropdown(options= name_files, value=name_files[rnd1], description='Image 1: ')\n",
    "wImg2 = widgets.Dropdown(options= name_files,value=name_files[rnd2],description='Image 2: ')\n",
    "\n",
    "out = widgets.interactive_output(mf2.dropdown_callback, \n",
    "                                 {'hue': wHue, 'hsv_dim': wDim, \n",
    "                                  'img1': wImg1, 'img2': wImg2, \n",
    "                                  'dirr': fixed(dirr), 'NUMS': fixed(NUMS), 'DENS': fixed(DENS)})\n",
    "\n",
    "left_widgets = VBox([wHue, wDim])\n",
    "right_widgets = VBox([wImg1, wImg2])\n",
    "top = HBox([left_widgets, right_widgets])\n",
    "VBox([top, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En imagenes ratio y denominador son independientes ($p(RL|DL=p(RL|DS)=0.5$). \n",
    "\n",
    "Dada esta condición, p(RL|NL) es muy alto en millones de comparaciones binarias de imagenes naturales y pinturas.\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso17.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sólo en imagenes, también en muchos dominios p(RL|NL) es mayor (aunque la razón no es 100% clara pues $p(RL|DL\\ne p(RL|DS)\\ne 0.5$)\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/alonso18.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Con herramientas y conceptos bayesianos pudimos demostrar:\n",
    "\n",
    "* Usar numeradores no implica no usar ratios.\n",
    "* Sesgo bayesiano en confiar en ratios con cardinalidad alta.\n",
    "* Prior p(RL|NL) alto en imagenes y otros dominios como libros de texto, videojuegos, economía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cambiemos de tema un poco\n",
    "\n",
    "<center><img src=\"img/8_CB/LeeSarnecka1.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Teoría de number-knower. Los primeros numerales (1 a aprox. 4) se aprenden por ensayo y error (N-knower). Si se le pide un número mayor al nivel number-knower, el niño/niña es aleatorio.  \n",
    "\n",
    "A partir de cierta edad se pasa a ser cardinal-principle knower (CP-knower) donde numerales sucesivos indican mayor numerosidad. Hay un salto/inferencia en la mente de la niña/niño. \n",
    "\n",
    "<center><img src=\"img/8_CB/LeeSarnecka2.svg\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\pi$: base rate prob. of giving/reporting k objects back witout any demand e.g. \"take 4 just because\" (max: 15) <br>\n",
    "$z_i$: N-knower level (PN-knower, one-knower, two-knower, three-knower, four-knower, and CP-knower) <br>\n",
    "$q_{ij}^g, \\ a_{ij}^g $: question and answer of child i in trial j <br>\n",
    "$\\pi_{jik}^{'}$: updated rate prob. of giving/reporting k objects back after the question <br>\n",
    ">\"... if three-knower is asked to give five, they become much less likely to give 1, 2, or 3, but equally relatively likely to give 4 and above.\" Lee & Wagenmakers, 2013 (pp. 238)\n",
    "\n",
    "$\\nu$: strength of the updating\n",
    "\n",
    "<center><img src=\"img/8_CB/LeeSarnecka3.svg\" width = \"751\" height = '750'></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Modelos basados en https://github.com/junpenglao/Bayesian-Cognitive-Modeling-in-Pymc3\n",
    "#load data\n",
    "fa = pd.read_csv(\"data/8_CB/fa.csv\") #answers (for fast-cards task) (rows: children; columns: trial)\n",
    "fq = pd.read_csv(\"data/8_CB/fq.csv\") #questions (for fast-cards task)\n",
    "ga = np.array(pd.read_csv(\"data/8_CB/ga.csv\")) #answers (for give-n task)\n",
    "gq = np.array(pd.read_csv(\"data/8_CB/gq.csv\")) #questions (for give-n task)\n",
    "fnq = pd.read_csv(\"data/8_CB/fnq.csv\")\n",
    "gn = int(pd.read_csv(\"data/8_CB/gn.csv\").iloc[0]) #max number of toys considered by the child (give-n task)\n",
    "fn = 50 #max number of toys considered by the child (fast-cards task)\n",
    "gnq = pd.read_csv(\"data/8_CB/gnq.csv\")\n",
    "ns = int(pd.read_csv(\"data/8_CB/ns.csv\").iloc[0]) #number of subjects\n",
    "nz = int(pd.read_csv(\"data/8_CB/nz.csv\").iloc[0]) #proposed number-knower levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ind5 = np.zeros((nz, gn, gn), dtype=int) \n",
    "#cells in ind5 have: three levels/indices of situations (see comment in ind5r below) by knower-level, number asked, number responded\n",
    "for i in range(nz): #number-knower levels (z in the graphical model)\n",
    "    i1 = i + 1\n",
    "    for j in range(gn): #These loops creates a 3D array ind5 to implement pi_{ijk}\n",
    "        j1 = j + 1\n",
    "        for k in range(gn): \n",
    "            k1 = k + 1\n",
    "            # Will be 1 if Knower-Level is Same or Greater than Answer\n",
    "            ind1 = int(i1 - 1 >= k1)\n",
    "            # Will be 1 for the Possible Answer that Matches the Question\n",
    "            ind2 = int(k1 == j1)\n",
    "            # Will be 1 for 0-Knowers\n",
    "            ind3 = int(i1 == 1)\n",
    "            # Will be 1 for CP-Knowers\n",
    "            ind4 = int(i1 == nz)\n",
    "            ind5[i, j, k] = (\n",
    "                ind3\n",
    "                + ind4 * (2 + ind2)\n",
    "                + (1 - ind4) * (1 - ind3) * (ind1 * ind2 + ind1 + 1)\n",
    "            )\n",
    "            #for a zero-knower: 1\n",
    "            #for a CP-knower for a k that matches question: 1*(2+1) = 3 \n",
    "            #for a CP-knower for a k that doesn't matches question: 1*(2) = 2\n",
    "            #for a N-knower for a k that matches question and knower level is enough: (1*1 + 1 + 1) = 3\n",
    "            #for a N-knower for a k that doesn't matches question and knower level is enough:: (1+1) = 2 \n",
    "            #for a N-knower for a k that matches question and knower level is not enough: (1) = 1\n",
    "            #for a N-knower for a k that doesn't matches question and knower level is not enough: (1) = 1\n",
    "            \n",
    "ind5r = ind5 - 1 \n",
    "#0: impossible number demand (first condition of pi_{ijk}) \n",
    "#1 too easy or number wasn't asked (third condition of pi_{ijk})\n",
    "#2 just perfect, at limit of knower-level (second condition of pi_{ijk})\n",
    "ga_obs = np.asarray(ga.flatten() - 1, dtype=int)\n",
    "gq_obs = np.asarray(gq.flatten() - 1, dtype=int)\n",
    "valid_ind = np.where(gq_obs != -1)[0] #to clean data, my guess is that 0 means children didn't respond?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model1:\n",
    "    #priors\n",
    "    pi = pm.Dirichlet(\"pi\", a=np.ones(gn), shape=gn)\n",
    "\n",
    "    nu = pm.Uniform(\"nu\", lower=1, upper=1000)\n",
    "    nu_vec = tt.stack([1.0, #first condition of pi_{ijk} (before nu multiplication)\n",
    "                       1.0 / nu, #third condition of pi_{ijk} (before nu multiplication)\n",
    "                       nu]) #second condition of pi_{ijk} (before nu multiplication)\n",
    "\n",
    "    piprime = tt.mul(nu_vec[ind5r], pi) #multiplication by nu\n",
    "    npiprime = piprime / tt.sum(piprime, axis=-1, keepdims=True) #normalized pi prime for categorical likelihood\n",
    "\n",
    "    zi = pm.Categorical(\"zi\", p=np.ones(nz) / nz, shape=ns) #knower level z per children s in dataset\n",
    "    zi_vec = tt.repeat(zi, gq.shape[1]) #nz x number of questions \n",
    "    #print(zi_vec.tag.test_value.shape)\n",
    "    \n",
    "    #likelihoods\n",
    "    pi_ij = npiprime[zi_vec[valid_ind], gq_obs[valid_ind], :]\n",
    "    aij = pm.Categorical(\"aij\", p=pi_ij, observed=ga_obs[valid_ind])\n",
    "    \n",
    "    #sampling\n",
    "    trace1 = pm.sample()\n",
    "    ppc1 = pm.sample_posterior_predictive(trace1, samples=5000)\n",
    "    data1 = az.from_pymc3(trace=trace1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(data1,  var_names=[\"pi\", \"nu\", \"zi\"], compact=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La posterior promedio para pi, es decir la probabilidad base promedio de dar un número está sesgada a 1 y cae rápidamente con un incremento al final en dar todos los objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pitr = trace1[\"pi\"]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "plt.bar(np.arange(15) + 1, np.mean(pitr, axis=0), align=\"center\")\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xticks(np.arange(16))\n",
    "plt.xlim([0, 16]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La posterior esta centrada alrededor de solo un knower-level en todos los niños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(20, 12))\n",
    "gs = axes.flatten()\n",
    "zitr = trace1[\"zi\"]\n",
    "\n",
    "for i in range(ns):\n",
    "    ax = gs[i]\n",
    "    bartmp = np.unique(zitr[:, i], return_counts=True)\n",
    "    ax.bar(bartmp[0], bartmp[1])\n",
    "    ax.set_title(\"Child %s\" % (i + 1))\n",
    "    ax.set_xlim([-0.9, 5.9])\n",
    "    ax.set_xticks(np.arange(6))\n",
    "    ax.set_xticklabels([\"P\", \"1\", \"2\", \"3\", \"4\", \"C\"])\n",
    "\n",
    "plt.subplot(gs[15])\n",
    "plt.xlabel(\"Knower Level\")\n",
    "plt.ylabel(\"Posterior Mass\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Generate posterior prediction for each subject\n",
    "gqpred = np.tile(np.arange(gn)[np.newaxis, :], (ns, 1)).flatten()\n",
    "\n",
    "# Generate posterior prediction for each knower level\n",
    "zpred = np.tile(np.arange(gn)[np.newaxis, :], (nz, 1)).flatten()\n",
    "z_vect = np.tile(np.arange(nz)[:, np.newaxis], (1, gn)).flatten()\n",
    "\n",
    "nutr = trace1[\"nu\"]\n",
    "tracelen = nutr.shape[0]\n",
    "nsample = 500\n",
    "predga = np.zeros((nsample, len(gqpred)))\n",
    "predz = np.zeros((nsample, len(zpred)))\n",
    "randlist = np.random.choice(tracelen, nsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def caterandom(p):\n",
    "    return np.asarray([np.random.choice(len(p1), p=p1) for p1 in p])\n",
    "\n",
    "\n",
    "for i, idx in enumerate(randlist):\n",
    "    pi1, nu1, zi1 = pitr[idx], nutr[idx], zitr[idx] #tr stands for trace from the model\n",
    "\n",
    "    nu_vec1 = np.stack([1.0, 1.0 / nu1, nu1])\n",
    "    piprime1 = np.multiply(nu_vec1[ind5r], pi1)\n",
    "    npiprime1 = piprime1 / np.sum(piprime1, axis=-1, keepdims=True)\n",
    "\n",
    "    zi_vec2 = np.repeat(zi1, gn)\n",
    "    pi_ij_pred = npiprime1[zi_vec2, gqpred, :]\n",
    "    predga[i, :] = caterandom(pi_ij_pred)\n",
    "\n",
    "    zi_ij_pred = npiprime1[z_vect, zpred, :]\n",
    "    predz[i, :] = caterandom(zi_ij_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos predecir cuantos objetos un niño va a dar. Por ejemplo, el niño 20 es un CP-knower y el model predice que siempre va a dar la respuesta correcta (circulos rojos es la data, y colores calidos indican probabilidades más fuertes para el modelo).\n",
    "\n",
    "Child 15 is a 0-knower, child 2 is a 1-knower, child 4 is a 2-knower, child 3 is a 3-knower, child 10 is a 4-knower (see previous plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predga = np.reshape(predga, newshape=(nsample, ns, gn)).astype(int)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "gs = axes.flatten()\n",
    "subjlist = np.asarray([15, 2, 4, 3, 10, 20]) - 1\n",
    "\n",
    "for i, isbj in enumerate(subjlist):\n",
    "    mattmp = np.squeeze(predga[:, isbj, :])\n",
    "    obs = ga[isbj] - 1\n",
    "    qus = gq[isbj] - 1\n",
    "    msk = qus != -1\n",
    "    img_ = np.zeros((gn, gn))\n",
    "    for j in range(gn):\n",
    "        bartmp = np.unique(mattmp[:, j], return_counts=True)\n",
    "        img_[j, bartmp[0]] = bartmp[1]\n",
    "    ax = gs[i]\n",
    "    ax.imshow(img_.T, cmap=\"viridis\", origin=\"lower\")\n",
    "    ax.plot(qus[msk], obs[msk], \"o\", ms=15, color=\"r\", alpha=0.5)\n",
    "    ax.grid(\"off\")\n",
    "    ax.set_title(\"Child %s\" % (isbj + 1))\n",
    "\n",
    "plt.subplot(gs[3])\n",
    "plt.xlabel(\"Question\")\n",
    "plt.ylabel(\"Answer\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En general, la imagen siguiente muestra las predicciones del modelo por knower-level. Sigue la intuición: e.g. los cuadros amarillos para un 3 knower van hasta 3, luego los colores azules se ponen más frios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predz = np.reshape(predz, newshape=(nsample, nz, gn)).astype(int)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "gs = axes.flatten()\n",
    "knowertype = (\n",
    "    \"PN-Knower\",\n",
    "    \"One-Knower\",\n",
    "    \"Two-Knower\",\n",
    "    \"Three-Knower\",\n",
    "    \"Four-Knower\",\n",
    "    \"CP-Knower\",\n",
    ")\n",
    "\n",
    "for i in range(nz):\n",
    "    mattmp = np.squeeze(predz[:, i, :])\n",
    "    img_ = np.zeros((gn, gn))\n",
    "    for j in range(gn):\n",
    "        bartmp = np.unique(mattmp[:, j], return_counts=True)\n",
    "        img_[j, bartmp[0]] = bartmp[1]\n",
    "    ax = gs[i]\n",
    "    ax.imshow(img_.T, cmap=\"viridis\", origin=\"lower\")\n",
    "    ax.grid(\"off\")\n",
    "    ax.set_title(knowertype[i])\n",
    "\n",
    "plt.subplot(gs[3])\n",
    "plt.xlabel(\"Question\")\n",
    "plt.ylabel(\"Answer\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ejercicios\n",
    "\n",
    "* Haga un gráfico que represente mejor el posterior de $pi$. Arriba solo se gráfico el promedio. \n",
    "* ¿Qué opina si clasificamos el knower-level de niños/niñas usando el máximo a posteriori (MAP) del parámetro zi? Por ejemplo, ¿qué opina de clasificar al niño 8 cómo 1-knower? Piense en alguna alternativa al MAP\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos describir/medir etapas de desarrollo numérico de niños y niñas con técnicas bayesianas ... pero ¿un modelo Bayesiano puede *explicar* por qué va por etapas? Si. \n",
    "\n",
    "<center><img src=\"img/8_CB/Piantadosi1.svg\" width = \"651\" height = '650'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suponga que el cerebro tiene primitivos \n",
    "<br><br>\n",
    "\n",
    "<center><img src=\"img/8_CB/Piantadosi2.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suponga que la labor durante el desarrollo es encontrar como se combinan esos primitivos. El niño tiene que inferir cuál combinación es la apropiada. Tiene que explorar un espacio de hipótesis enorme. Acá algunas.\n",
    "<br><br>\n",
    "\n",
    "<center><img src=\"img/8_CB/Piantadosi3.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A medida que hay más datos (exposición a expresiones númericas) el posterior va evolucionando por las etapas que vemos en niños y niñas: de 1-knower a CP-Knower. \n",
    "\n",
    "Los datos vuelven algunas hipótesis más probables.\n",
    "\n",
    "<center><img src=\"img/8_CB/Piantadosi4.svg\" width = \"751\" height = '750'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Depende de la data para evolucionar en el espacio de hipótesis. Esto se ve en diferentes culturas. Los Tsimane en particular van más lento (menos exposición a números) pero la misma progresión (Piantadosi, et al, 2014).\n",
    "<br><br>\n",
    "<center><img src=\"img/8_CB/Piantadosi5.svg\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Conclusión\n",
    "\n",
    "* Con Bayes se puede describir comportamiento numérico (adultos y menores).\n",
    "* Con Bayes también se puede testear comportamiento numérico Bayesiano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Intrinsic whole number bias\n",
    "dot_text = 'digraph G {rankdir=TB; compound=true; newrank=true; labelloc=\"t\";\\\n",
    "           label=\"Whole Number Bias\";\\\n",
    "           /* general properties*/\\\n",
    "           node [margin=0, fixedsize=true, shape=plaintext,\\\n",
    "                 height=0.25, width=0.25, lblstyle=\"font=\\\\small\"];\\\n",
    "           /* links */\\\n",
    "           w -> pw;\\\n",
    "           l -> pl;\\\n",
    "           w -> pratio;\\\n",
    "           l -> pratio;\\\n",
    "           pw -> choice;\\\n",
    "           pl -> choice;\\\n",
    "           pratio -> choice;\\\n",
    "           subgraph cluster0 {\\\n",
    "               margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "               style = rounded;\\\n",
    "               label = \"$i trial$\";\\\n",
    "               choice;\\\n",
    "               subgraph cluster1 {\\\n",
    "                   margin = 10; labeljust=l; lblstyle=\"font=\\\\small\";\\\n",
    "                   style = rounded;\\\n",
    "                   label = \"$r ratio = [Small, Big]$\";\\\n",
    "                   w;\\\n",
    "                   pw;\\\n",
    "                   l;\\\n",
    "                   pl;\\\n",
    "                   pratio;\\\n",
    "               }\\\n",
    "           }\\\n",
    "           /* nodes */\\\n",
    "           w [label = \"$W_{ir}$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           l [label = \"$L_{ir}$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           pw [label = \"$\\Phi(W_{ir})$\", shape = circle];\\\n",
    "           pl [label = \"$\\Phi(L_{ir})$\", shape = circle];\\\n",
    "           pratio [label = \"$Ratio_{ir}$\", shape = circle];\\\n",
    "           choice [label = \"$Choice_i$\", fillcolor = gray, style = filled, shape = square];\\\n",
    "           }' #warning: use single quote at start and end; double quotes for labels\n",
    "s = Source(dot_text, filename=\"img/8_CB/model_WNB.gv\", format=\"svg\") #THIS IS NOT THE FINAL ONE\n",
    "s.view()\n",
    "\n",
    "#distributions:\n",
    "# \\Phi(W_{ir}) \\sim N(W_{ir}, Weber \\times W_{ir})\n",
    "# \\Phi(L_{ir}) \\sim N(L_{ir}, Weber \\times L_{ir})\n",
    "# Ratio_{ir} \\sim Beta(W_{ir} + 1, L_{ir} + 1)\n",
    "# Choice_i \\sim Bernoulli(pSM_i)\n",
    "# pSM_i = \\frac{e^{f_{iB}}}{e^{f_{iB}}+e^{f_{iS}}}\n",
    "# f_{ir} = \\beta_1 \\Phi(W_{ir}) + \\beta_2 \\Phi(L_{ir}) + \\beta_3 Ratio_{ir}\n",
    "# \\beta_{num cues} \\Uniform(-5,5)\n",
    "# \\beta_{ratio cue} \\Uniform(0,5)\n",
    "\n",
    "#To typeset latex stuff on the image: \n",
    "#1) open svg in inkscape and write latex formulas. Export as pdf (click the one that says latex)\n",
    "#   to change fontsize of latex in inkscape write before the expression: \n",
    "#        \\fontsize{34pt}{1em} $latex expression$ ... change #pt for size\n",
    "#2) go to overleaf or latex editor of choice and do this (https://castel.dev/post/lecture-notes-2/):\n",
    "#   2.1) In the preamble:\n",
    "#  \\usepackage{import}\n",
    "#  \\usepackage{xifthen}\n",
    "#  \\usepackage{pdfpages}\n",
    "#  \\usepackage{transparent}\n",
    "#  \\usepackage{graphics} \n",
    "\n",
    "#  \\newcommand{\\incfig}[1]{%\n",
    "#      \\def\\svgwidth{\\columnwidth}\n",
    "#      \\import{./figures/}{#1.pdf_tex} %PUT the inkscape .pdf_tex AND .pdf in a local folder called figures\n",
    "#  }\n",
    "#   2.2)In the body:\n",
    "#  \\begin{figure}[ht]\n",
    "#      \\centering\n",
    "#      \\scalebox{.65}{\\incfig{your_inkscape.pdf_tex}} #change scalebox proportion to rescale\n",
    "#      \\caption{Riemmans theorem}\n",
    "#      \\label{fig:riemmans-theorem}\n",
    "#  \\end{figure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "chalkboard": {
    "color": [
     "rgb(250, 0, 0)",
     "rgb(0, 250, 250)"
    ]
   },
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
